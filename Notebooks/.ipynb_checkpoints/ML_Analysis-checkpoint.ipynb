{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # for visualizations\n",
    "import seaborn as sns # for visualizations\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "#model packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "import statsmodels.api as sm #linear regression tool\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Pre-processing and metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing #for normalizing values\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Spark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, DoubleType, IntegerType, DateType\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spark session and context.\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema with the column names, type, and nullable as true or false\n",
    "schema = StructType([ \\\n",
    "    StructField(\"index\", IntegerType(), True), \\\n",
    "    StructField(\"MLSNumber\", StringType(), True), \\\n",
    "    StructField(\"DOM\", IntegerType(), True), \\\n",
    "    StructField(\"CDOM\", IntegerType(), True), \\\n",
    "    StructField(\"ListDate\", StringType(), True), \\\n",
    "    StructField(\"AgreementOfSaleSignedLeaseDate\", StringType(), True), \\\n",
    "    StructField(\"OffMarketDate\", StringType(), True), \\\n",
    "    StructField(\"SettledDate\", StringType(), True), \\\n",
    "    StructField(\"OriginalPrice\", StringType(), True), \\\n",
    "    StructField(\"ListPrice\", StringType(), True), \\\n",
    "    StructField(\"SoldPrice\", StringType(), True), \\\n",
    "    StructField(\"StreetNumber\", StringType(), True), \\\n",
    "    StructField(\"StreetDirection\", StringType(), True), \\\n",
    "    StructField(\"StreetName\", StringType(), True), \\\n",
    "    StructField(\"UnitNumber\", StringType(), False), \\\n",
    "    StructField(\"City\", StringType(), True), \\\n",
    "    StructField(\"ZipCode\", IntegerType(), True), \\\n",
    "    StructField(\"County\", StringType(), True), \\\n",
    "    StructField(\"Subdivision\", StringType(), True), \\\n",
    "    StructField(\"ListAgentName\", StringType(), True), \\\n",
    "    StructField(\"ListAgentCode\", IntegerType(), True), \\\n",
    "    StructField(\"ListOfficeName\", StringType(), True), \\\n",
    "    StructField(\"ListOfficeCode\", StringType(), True), \\\n",
    "    StructField(\"SellingAgent\", StringType(), True), \\\n",
    "    StructField(\"SellingAgentCode\", StringType(), True), \\\n",
    "    StructField(\"SellingOfficeName\", StringType(), True), \\\n",
    "    StructField(\"SellingOfficeCode\", StringType(), True), \\\n",
    "    StructField(\"SellerConcessionsAmount\", StringType(), True), \\\n",
    "    StructField(\"FinalFinancing\", StringType(), True), \\\n",
    "    StructField(\"FinalShortSale\", StringType(), True), \\\n",
    "    StructField(\"FinalThirdPartyApproval\", StringType(), True), \\\n",
    "    StructField(\"FinalBankOwned\", StringType(), True), \\\n",
    "    StructField(\"TaxAnnualTotal\", StringType(), True), \\\n",
    "    StructField(\"TaxYear\", StringType(), True), \\\n",
    "    StructField(\"AcresTotal\", DoubleType(), True), \\\n",
    "    StructField(\"LandUseCode\", StringType(), True), \\\n",
    "    StructField(\"Ownership\", StringType(), True), \\\n",
    "    StructField(\"SeniorCommunity\", StringType(), False), \\\n",
    "    StructField(\"CondoCoopAssoc\", StringType(), True), \\\n",
    "    StructField(\"HOA\", StringType(), True), \\\n",
    "    StructField(\"OneTimeAssociationFee\", StringType(), True), \\\n",
    "    StructField(\"AssociationFee\", StringType(), True), \\\n",
    "    StructField(\"AssociationFeeFrequency\", StringType(), True), \\\n",
    "    StructField(\"Age\", StringType(), True), \\\n",
    "    StructField(\"InteriorSqFt\", StringType(), True), \\\n",
    "    StructField(\"PropertyCondition\", StringType(), True), \\\n",
    "    StructField(\"Bedrooms\", StringType(), True), \\\n",
    "    StructField(\"BathsFull\", StringType(), True), \\\n",
    "    StructField(\"BathsHalf\", StringType(), True), \\\n",
    "    StructField(\"Design\", StringType(), True), \\\n",
    "    StructField(\"Style\", StringType(), True), \\\n",
    "    StructField(\"NumberofStories\", StringType(), True), \\\n",
    "    StructField(\"FloorNumber\", StringType(), True), \\\n",
    "    StructField(\"Basement\", StringType(), True), \\\n",
    "    StructField(\"GarageSpaces\", StringType(), True), \\\n",
    "    StructField(\"Fireplace\", StringType(), True), \\\n",
    "    StructField(\"Laundry\", StringType(), True), \\\n",
    "    StructField(\"OtherRooms\", StringType(), True), \\\n",
    "    StructField(\"RoomCount\", StringType(), True), \\\n",
    "    StructField(\"CentralAir\", StringType(), True), \\\n",
    "    StructField(\"Waterfront\", StringType(), True), \\\n",
    "    StructField(\"NewConstruction\", StringType(), True), \\\n",
    "    StructField(\"ModelName\", StringType(), True), \\\n",
    "    StructField(\"BuyerBrokerCompensation\", DoubleType(), True), \\\n",
    "    StructField(\"SubAgentCompensation\", DoubleType(), True), \\\n",
    "    StructField(\"TransactionBrokerCompensation\", DoubleType(), True), \\\n",
    "    StructField(\"OriginatingMLS\", StringType(), True), \\\n",
    "    StructField(\"AboveGradeSqFt\", StringType(), True), \\\n",
    "    StructField(\"BelowGradeSqFt\", StringType(), True), \\\n",
    "    StructField(\"HomeBuilt\", StringType(), True), \\\n",
    "    StructField(\"BasementFootprintPct\", StringType(), True), \\\n",
    "    StructField(\"BasementFinishedPct\", StringType(), True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the appended data\n",
    "df = spark.read.csv(\"../CleanedData/cleaned_data.csv\", sep=\",\", schema=schema, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns that came in as strings using dollars to integers\n",
    "df = df.withColumn('OriginalPrice', f.regexp_replace('OriginalPrice', '[$,]', '').cast('integer'))\n",
    "df = df.withColumn('ListPrice', f.regexp_replace('ListPrice', '[$,]', '').cast('integer'))\n",
    "df = df.withColumn('SoldPrice', f.regexp_replace('SoldPrice', '[$,]', '').cast('integer'))\n",
    "df = df.withColumn('SellerConcessionsAmount', f.regexp_replace('SellerConcessionsAmount', '[$,]', '').cast('integer'))\n",
    "df = df.withColumn('StreetNumber', df['StreetNumber'].cast('integer'))\n",
    "df = df.withColumn('UnitNumber', df['UnitNumber'].cast('integer'))\n",
    "df = df.withColumn('SellingAgentCode', df['SellingAgentCode'].cast('integer'))\n",
    "df = df.withColumn('TaxAnnualTotal', df['TaxAnnualTotal'].cast('integer'))\n",
    "df = df.withColumn('TaxYear', df['TaxYear'].cast('integer'))\n",
    "df = df.withColumn('LandUseCode', df['LandUseCode'].cast('integer'))\n",
    "df = df.withColumn('AssociationFee', df['AssociationFee'].cast('integer'))\n",
    "df = df.withColumn('Age', df['Age'].cast('integer'))\n",
    "df = df.withColumn('InteriorSqFt', df['InteriorSqFt'].cast('integer'))\n",
    "df = df.withColumn('Bedrooms', df['Bedrooms'].cast('integer'))\n",
    "df = df.withColumn('BathsFull', df['BathsFull'].cast('integer'))\n",
    "df = df.withColumn('BathsHalf', df['BathsHalf'].cast('integer'))\n",
    "df = df.withColumn('GarageSpaces', df['GarageSpaces'].cast('integer'))\n",
    "df = df.withColumn('RoomCount', df['RoomCount'].cast('integer'))\n",
    "df = df.withColumn('AboveGradeSqFt', df['AboveGradeSqFt'].cast('integer'))\n",
    "df = df.withColumn('BelowGradeSqFt', df['BelowGradeSqFt'].cast('integer'))\n",
    "df = df.withColumn('BasementFootprintPct', df['BasementFootprintPct'].cast('integer'))\n",
    "df = df.withColumn('BasementFinishedPct', df['BasementFinishedPct'].cast('integer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90758"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the count\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the dataframe\n",
    "dfCache = df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpdForLinearRegression = dfCache.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def oneHotEncode(dfToEncode, columnToEncode):\n",
    "    # Get one hot encoding of columns provided\n",
    "    one_hot = pd.get_dummies(dfToEncode[columnToEncode])\n",
    "    # Drop column provided as it is now encoded\n",
    "    dfToEncode = dfToEncode.drop(columnToEncode, axis = 1)\n",
    "    # Join the encoded df\n",
    "    return dfToEncode.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step will be to clean the categorical data into usable fields for regression - needs to be quantitative\n",
    "\n",
    "dfpdForLinearRegression = dfpdForLinearRegression[['SoldPrice', 'SettledDate', 'ZipCode', 'County', 'AcresTotal', \n",
    "                                                   'Age', 'InteriorSqFt', 'Bedrooms', \n",
    "                                                   'BathsFull', 'BathsHalf', 'Style', 'Basement', 'GarageSpaces', \n",
    "                                                   'Fireplace', 'CentralAir', 'Waterfront', 'NewConstruction']]\n",
    "\n",
    "dfpdForLinearRegression['SettledDate'] = pd.to_datetime(dfpdForLinearRegression['SettledDate'])\n",
    "dfpdForLinearRegression['SettledDate'] = dfpdForLinearRegression['SettledDate'].map(dt.datetime.toordinal)\n",
    "\n",
    "dfpdForLinearRegression = oneHotEncode(dfpdForLinearRegression, 'County')\n",
    "dfpdForLinearRegression = oneHotEncode(dfpdForLinearRegression, 'Style')\n",
    "\n",
    "# Get one hot encoding of columns Basement\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegression['Basement'])\n",
    "one_hot.rename(columns = {'No':'NoBasement', 'Yes':'HasBasement'}, inplace = True)\n",
    "# Drop column Basement as it is now encoded\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.drop('Basement', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns Fireplace\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegression['Fireplace'])\n",
    "one_hot.rename(columns = {'No':'NoFireplace', 'Yes':'HasFireplace'}, inplace = True)\n",
    "# Drop column Fireplace as it is now encoded\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.drop('Fireplace', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns CentralAir\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegression['CentralAir'])\n",
    "one_hot.rename(columns = {'No':'NoCentralAir', 'Yes':'HasCentralAir'}, inplace = True)\n",
    "# Drop column CentralAir as it is now encoded\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.drop('CentralAir', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns Waterfront\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegression['Waterfront'])\n",
    "one_hot.rename(columns = {'No':'NotWaterfront', 'Yes':'IsWaterfront'}, inplace = True)\n",
    "# Drop column Waterfront as it is now encoded\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.drop('Waterfront', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns NewConstruction\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegression['NewConstruction'])\n",
    "one_hot.rename(columns = {'No':'NotNewConstruction', 'Yes':'IsNewConstruction'}, inplace = True)\n",
    "# Drop column NewConstruction as it is now encoded\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.drop('NewConstruction', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.join(one_hot)\n",
    "\n",
    "dfpdForLinearRegression[\"BathsHalf\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegression[\"BathsFull\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegression[\"Bedrooms\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegression[\"AcresTotal\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegression[\"Bedrooms\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegression[\"GarageSpaces\"].fillna(0, inplace = True)\n",
    "\n",
    "dfpdForLinearRegression = dfpdForLinearRegression.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same thing, except without style since it seems to be insignificant\n",
    "\n",
    "dfpdForLinearRegressionNoStyle = dfCache.toPandas()\n",
    "\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle[['SoldPrice', 'SettledDate', 'ZipCode', 'County', \n",
    "                                                    'AcresTotal', 'Age', 'InteriorSqFt', 'Bedrooms', \n",
    "                                                   'BathsFull', 'BathsHalf', 'Basement', 'GarageSpaces', \n",
    "                                                   'Fireplace', 'CentralAir', 'Waterfront', 'NewConstruction']]\n",
    "\n",
    "dfpdForLinearRegressionNoStyle['SettledDate'] = pd.to_datetime(dfpdForLinearRegressionNoStyle['SettledDate'])\n",
    "dfpdForLinearRegressionNoStyle['SettledDate'] = dfpdForLinearRegressionNoStyle['SettledDate'].map(dt.datetime.toordinal)\n",
    "\n",
    "dfpdForLinearRegressionNoStyle = oneHotEncode(dfpdForLinearRegressionNoStyle, 'County')\n",
    "\n",
    "# Get one hot encoding of columns Basement\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegressionNoStyle['Basement'])\n",
    "one_hot.rename(columns = {'No':'NoBasement', 'Yes':'HasBasement'}, inplace = True)\n",
    "# Drop column Basement as it is now encoded\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.drop('Basement', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns Fireplace\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegressionNoStyle['Fireplace'])\n",
    "one_hot.rename(columns = {'No':'NoFireplace', 'Yes':'HasFireplace'}, inplace = True)\n",
    "# Drop column Fireplace as it is now encoded\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.drop('Fireplace', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns CentralAir\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegressionNoStyle['CentralAir'])\n",
    "one_hot.rename(columns = {'No':'NoCentralAir', 'Yes':'HasCentralAir'}, inplace = True)\n",
    "# Drop column CentralAir as it is now encoded\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.drop('CentralAir', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns Waterfront\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegressionNoStyle['Waterfront'])\n",
    "one_hot.rename(columns = {'No':'NotWaterfront', 'Yes':'IsWaterfront'}, inplace = True)\n",
    "# Drop column Waterfront as it is now encoded\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.drop('Waterfront', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.join(one_hot)\n",
    "\n",
    "# Get one hot encoding of columns NewConstruction\n",
    "one_hot = pd.get_dummies(dfpdForLinearRegressionNoStyle['NewConstruction'])\n",
    "one_hot.rename(columns = {'No':'NotNewConstruction', 'Yes':'IsNewConstruction'}, inplace = True)\n",
    "# Drop column NewConstruction as it is now encoded\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.drop('NewConstruction', axis = 1)\n",
    "# Join the encoded df\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.join(one_hot)\n",
    "\n",
    "dfpdForLinearRegressionNoStyle[\"BathsHalf\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegressionNoStyle[\"BathsFull\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegressionNoStyle[\"Bedrooms\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegressionNoStyle[\"AcresTotal\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegressionNoStyle[\"Bedrooms\"].fillna(0, inplace = True)\n",
    "dfpdForLinearRegressionNoStyle[\"GarageSpaces\"].fillna(0, inplace = True)\n",
    "\n",
    "dfpdForLinearRegressionNoStyle = dfpdForLinearRegressionNoStyle.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61000, 686)\n",
      "(15251, 686)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(dfpdForLinearRegression, test_size = 0.2, random_state = 2) # splits the data into two parts with 1:4 ratio\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SoldPrice   R-squared:                       0.638\n",
      "Model:                            OLS   Adj. R-squared:                  0.635\n",
      "Method:                 Least Squares   F-statistic:                     183.0\n",
      "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:39:03   Log-Likelihood:            -8.2336e+05\n",
      "No. Observations:               61000   AIC:                         1.648e+06\n",
      "Df Residuals:                   60417   BIC:                         1.653e+06\n",
      "Df Model:                         582                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.708e+07   3.57e+05    -47.844      0.000   -1.78e+07   -1.64e+07\n",
      "SettledDate                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            72.3162      1.567     46.156      0.000      69.245      75.387\n",
      "ZipCode                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               118.4917      5.052     23.455      0.000     108.590     128.393\n",
      "AcresTotal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.785e+04    270.738     65.919      0.000    1.73e+04    1.84e+04\n",
      "Age                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -28.8306      6.129     -4.704      0.000     -40.843     -16.818\n",
      "InteriorSqFt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.4766      0.119     12.376      0.000       1.243       1.710\n",
      "Bedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.954e+04   1071.848     18.232      0.000    1.74e+04    2.16e+04\n",
      "BathsFull                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.238e+05   1078.793    114.712      0.000    1.22e+05    1.26e+05\n",
      "BathsHalf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            9.278e+04   1488.958     62.310      0.000    8.99e+04    9.57e+04\n",
      "GarageSpaces                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2625.6681    210.753     12.458      0.000    2212.591    3038.745\n",
      "ANNEARUNDELMD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -4.223e+06   8.93e+04    -47.303      0.000    -4.4e+06   -4.05e+06\n",
      "BALTIMOREMD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -4.326e+06   8.93e+04    -48.440      0.000    -4.5e+06   -4.15e+06\n",
      "HARFORDMD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -4.337e+06   8.92e+04    -48.603      0.000   -4.51e+06   -4.16e+06\n",
      "HOWARDMD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -4.193e+06   8.92e+04    -47.004      0.000   -4.37e+06   -4.02e+06\n",
      "AFrame                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -9.728e+04   2.04e+04     -4.780      0.000   -1.37e+05   -5.74e+04\n",
      "AFrame,AirLite,ArtDeco,BacktoBack,BeauxArts,Bilevel,Bungalow,CabinLodge,CapeCod,CarriageHouse,Chalet,Coastal,Colonial,Contemporary,ConvertedBarn,ConvertedDwelling,Cottage,Craftsman,Dome,Dutch,DwellingwSeparateLivingArea,FarmhouseNationalFolk,Federal,French,Georgian,Loft,LoftwithBedrooms,LogHome,Manor,Mediterranean,PreFabricated,Normandy,Other,PostAndBeam,Prairie,RaisedRanch,Rancher,Reverse,SaltBox,SidebySide,Spanish,SplitFoyer,SplitLevel,StraightThru,Traditional,Transitional,Trinity,Tudor,Condo    -0.0016      0.001     -1.172      0.241      -0.004       0.001\n",
      "AFrame,Bilevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.016e+05   1.77e+05     -0.575      0.565   -4.48e+05    2.45e+05\n",
      "AFrame,Bungalow,CapeCod,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -2.92e+05   1.77e+05     -1.652      0.099   -6.38e+05    5.45e+04\n",
      "AFrame,CabinLodge,Chalet,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -9.988e+04   1.77e+05     -0.565      0.572   -4.46e+05    2.47e+05\n",
      "AFrame,CabinLodge,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            6.935e+04   1.77e+05      0.392      0.695   -2.77e+05    4.16e+05\n",
      "AFrame,CapeCod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.842e+05   1.77e+05     -1.042      0.297   -5.31e+05    1.62e+05\n",
      "AFrame,CapeCod,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1.349e+05   1.25e+05     -1.078      0.281    -3.8e+05     1.1e+05\n",
      "AFrame,CapeCod,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -6.12e+04   1.77e+05     -0.346      0.729   -4.08e+05    2.85e+05\n",
      "AFrame,Chalet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -2.966e+04   1.77e+05     -0.168      0.867   -3.76e+05    3.17e+05\n",
      "AFrame,Coastal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0015      0.002      0.788      0.430      -0.002       0.005\n",
      "AFrame,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1.035e+04   1.77e+05      0.059      0.953   -3.36e+05    3.57e+05\n",
      "AFrame,Colonial,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -0.0030      0.002     -1.204      0.229      -0.008       0.002\n",
      "AFrame,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.135e+05   1.02e+05     -1.111      0.267   -3.14e+05    8.68e+04\n",
      "AFrame,Contemporary,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -2.708e+05   1.77e+05     -1.532      0.126   -6.17e+05    7.57e+04\n",
      "AFrame,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.539e+05   1.25e+05     -2.030      0.042   -4.99e+05   -8730.369\n",
      "AFrame,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -934.5482   8.86e+04     -0.011      0.992   -1.75e+05    1.73e+05\n",
      "AFrame,PreFabricated,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.717e+05   1.77e+05     -1.537      0.124   -6.18e+05    7.48e+04\n",
      "AFrame,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -0.0005      0.002     -0.200      0.841      -0.005       0.004\n",
      "AFrame,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -4.605e+04   8.85e+04     -0.520      0.603    -2.2e+05    1.27e+05\n",
      "AFrame,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -0.0026      0.003     -0.974      0.330      -0.008       0.003\n",
      "AFrame,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -1.834e+05   1.77e+05     -1.038      0.299    -5.3e+05    1.63e+05\n",
      "AFrame,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -1.47e+05   1.25e+05     -1.175      0.240   -3.92e+05    9.82e+04\n",
      "AFrame,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -0.0039      0.002     -1.627      0.104      -0.009       0.001\n",
      "AirLite,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.194e+05   1.77e+05     -0.675      0.500   -4.66e+05    2.27e+05\n",
      "ArtDeco                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.035e+05   8.86e+04      1.168      0.243   -7.01e+04    2.77e+05\n",
      "ArtDeco,BeauxArts,Colonial,Craftsman,Dutch,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                     3.779e+04   1.77e+05      0.214      0.831   -3.09e+05    3.84e+05\n",
      "ArtDeco,BeauxArts,Cottage,French,Normandy                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.27e+05   1.77e+05      0.718      0.472   -2.19e+05    4.73e+05\n",
      "ArtDeco,Bilevel,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -0.0030      0.003     -1.107      0.268      -0.008       0.002\n",
      "ArtDeco,Bungalow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     5.244e+04   1.77e+05      0.297      0.767   -2.94e+05    3.99e+05\n",
      "ArtDeco,Bungalow,Cottage,Craftsman,RaisedRanch,Rancher,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                        -4.366e+04   1.77e+05     -0.247      0.805    -3.9e+05    3.03e+05\n",
      "ArtDeco,CapeCod,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.233e+05   1.77e+05     -1.263      0.206    -5.7e+05    1.23e+05\n",
      "ArtDeco,CapeCod,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -2.185e+05   1.77e+05     -1.236      0.216   -5.65e+05    1.28e+05\n",
      "ArtDeco,Colonial,Contemporary,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -5.62e+04   1.77e+05     -0.318      0.751   -4.03e+05     2.9e+05\n",
      "ArtDeco,Craftsman,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.813e+05   1.77e+05     -1.026      0.305   -5.28e+05    1.65e+05\n",
      "ArtDeco,Mediterranean,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          5.211e+05   1.77e+05      2.948      0.003    1.75e+05    8.68e+05\n",
      "ArtDeco,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -6.593e+04   1.77e+05     -0.373      0.709   -4.12e+05    2.81e+05\n",
      "ArtDeco,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -2.703e+05   1.77e+05     -1.529      0.126   -6.17e+05    7.62e+04\n",
      "BacktoBack,DwellingwSeparateLivingArea,Rancher,SidebySide                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.204e+05   1.25e+05     -0.962      0.336   -3.66e+05    1.25e+05\n",
      "BeauxArts                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            3.487e+05   1.25e+05      2.788      0.005    1.04e+05    5.94e+05\n",
      "BeauxArts,Bungalow,CapeCod,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -0.0042      0.002     -1.938      0.053      -0.008    4.75e-05\n",
      "BeauxArts,CapeCod,Contemporary,ConvertedDwelling,Mediterranean,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                          -3.853e+04   1.77e+05     -0.218      0.827   -3.85e+05    3.08e+05\n",
      "BeauxArts,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.815e+05   1.77e+05     -1.027      0.305   -5.28e+05    1.65e+05\n",
      "BeauxArts,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -0.0003      0.002     -0.104      0.918      -0.005       0.005\n",
      "BeauxArts,Normandy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.0027      0.003      1.076      0.282      -0.002       0.008\n",
      "Bilevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.019e+05    1.2e+04     -8.462      0.000   -1.26e+05   -7.83e+04\n",
      "Bilevel,Bungalow,Rancher,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3384.8251   1.77e+05      0.019      0.985   -3.43e+05     3.5e+05\n",
      "Bilevel,CapeCod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.0032      0.002      1.474      0.140      -0.001       0.007\n",
      "Bilevel,Chalet,Colonial,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -2.114e+05   1.77e+05     -1.196      0.232   -5.58e+05    1.35e+05\n",
      "Bilevel,Coastal,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.636e+05   1.77e+05     -0.925      0.355    -5.1e+05    1.83e+05\n",
      "Bilevel,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.963e+05   6.28e+04     -3.127      0.002   -3.19e+05   -7.33e+04\n",
      "Bilevel,Colonial,Contemporary,Cottage,Craftsman,French,RaisedRanch,Rancher,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                               -1.585e+05   1.77e+05     -0.897      0.370   -5.05e+05    1.88e+05\n",
      "Bilevel,Colonial,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.237e+05   1.77e+05     -0.700      0.484    -4.7e+05    2.23e+05\n",
      "Bilevel,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -8.717e+04   7.24e+04     -1.204      0.229   -2.29e+05    5.47e+04\n",
      "Bilevel,Contemporary,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1.848e+05   1.77e+05      1.045      0.296   -1.62e+05    5.31e+05\n",
      "Bilevel,Contemporary,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    4.597e+05   1.77e+05      2.600      0.009    1.13e+05    8.06e+05\n",
      "Bilevel,ConvertedDwelling                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.179e+05   1.77e+05      0.667      0.505   -2.29e+05    4.64e+05\n",
      "Bilevel,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -6.933e+04   1.25e+05     -0.554      0.579   -3.14e+05    1.76e+05\n",
      "Bilevel,LoftwithBedrooms,Other,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -2.623e+05   1.77e+05     -1.484      0.138   -6.09e+05    8.42e+04\n",
      "Bilevel,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1.167e+05   1.77e+05      0.660      0.509    -2.3e+05    4.63e+05\n",
      "Bilevel,Other,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -6.813e+04   1.77e+05     -0.385      0.700   -4.15e+05    2.78e+05\n",
      "Bilevel,Other,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -0.0014      0.002     -0.681      0.496      -0.005       0.003\n",
      "Bilevel,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -8.221e+04   1.77e+05     -0.465      0.642   -4.29e+05    2.64e+05\n",
      "Bilevel,RaisedRanch,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.007e+05   1.25e+05     -0.805      0.421   -3.46e+05    1.44e+05\n",
      "Bilevel,RaisedRanch,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -8.801e+04   1.02e+05     -0.861      0.389   -2.88e+05    1.12e+05\n",
      "Bilevel,RaisedRanch,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -3.405e+04   1.77e+05     -0.193      0.847   -3.81e+05    3.12e+05\n",
      "Bilevel,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -6.997e+04   8.85e+04     -0.790      0.429   -2.44e+05    1.04e+05\n",
      "Bilevel,Reverse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -2.283e+05   1.77e+05     -1.291      0.197   -5.75e+05    1.18e+05\n",
      "Bilevel,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.279e+05   4.21e+04     -3.038      0.002    -2.1e+05   -4.54e+04\n",
      "Bilevel,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -6.76e+04   7.24e+04     -0.934      0.350   -2.09e+05    7.43e+04\n",
      "Bilevel,SplitFoyer,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -9.383e+04   1.77e+05     -0.531      0.596    -4.4e+05    2.53e+05\n",
      "Bilevel,SplitFoyer,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.317e+05   1.77e+05     -0.745      0.456   -4.78e+05    2.15e+05\n",
      "Bilevel,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.086e+05   3.52e+04     -3.086      0.002   -1.78e+05   -3.96e+04\n",
      "Bilevel,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.665e+05   1.77e+05     -0.942      0.346   -5.13e+05     1.8e+05\n",
      "Bilevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -9.881e+04   1.25e+05     -0.790      0.430   -3.44e+05    1.46e+05\n",
      "Bilevel,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -0.0006      0.002     -0.329      0.742      -0.004       0.003\n",
      "Bungalow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -9.443e+04   8827.551    -10.697      0.000   -1.12e+05   -7.71e+04\n",
      "Bungalow,CabinLodge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.0017      0.002      0.802      0.422      -0.002       0.006\n",
      "Bungalow,CabinLodge,CapeCod,CarriageHouse                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -2.751e+05   1.77e+05     -1.556      0.120   -6.22e+05    7.14e+04\n",
      "Bungalow,CabinLodge,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.491e+05   1.77e+05     -0.843      0.399   -4.96e+05    1.97e+05\n",
      "Bungalow,CabinLodge,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3.995e+04   1.77e+05      0.226      0.821   -3.07e+05    3.86e+05\n",
      "Bungalow,CapeCod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.304e+05    2.9e+04     -4.500      0.000   -1.87e+05   -7.36e+04\n",
      "Bungalow,CapeCod,Coastal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -0.0034      0.002     -1.869      0.062      -0.007       0.000\n",
      "Bungalow,CapeCod,Coastal,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.547e+04   1.77e+05     -0.088      0.930   -3.62e+05    3.31e+05\n",
      "Bungalow,CapeCod,Coastal,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -2.906e+05   1.77e+05     -1.644      0.100   -6.37e+05    5.59e+04\n",
      "Bungalow,CapeCod,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -7.549e+04   1.25e+05     -0.603      0.546   -3.21e+05     1.7e+05\n",
      "Bungalow,CapeCod,Colonial,Contemporary,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -2.605e+05   1.77e+05     -1.474      0.140   -6.07e+05    8.59e+04\n",
      "Bungalow,CapeCod,Colonial,Contemporary,Cottage,Craftsman,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                       4.547e+04   1.77e+05      0.257      0.797   -3.01e+05    3.92e+05\n",
      "Bungalow,CapeCod,Colonial,Contemporary,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -0.0033      0.002     -1.768      0.077      -0.007       0.000\n",
      "Bungalow,CapeCod,Colonial,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -9.593e+04   1.77e+05     -0.543      0.587   -4.42e+05    2.51e+05\n",
      "Bungalow,CapeCod,Colonial,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.389e+05   1.77e+05     -0.786      0.432   -4.85e+05    2.08e+05\n",
      "Bungalow,CapeCod,ConvertedDwelling,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.332e+05   1.77e+05      0.754      0.451   -2.13e+05     4.8e+05\n",
      "Bungalow,CapeCod,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -7.317e+04   6.71e+04     -1.091      0.275   -2.05e+05    5.83e+04\n",
      "Bungalow,CapeCod,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.967e+05   1.77e+05     -1.112      0.266   -5.43e+05     1.5e+05\n",
      "Bungalow,CapeCod,Cottage,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0058      0.002      2.999      0.003       0.002       0.010\n",
      "Bungalow,CapeCod,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           2.069e+04   1.02e+05      0.202      0.840    -1.8e+05    2.21e+05\n",
      "Bungalow,CapeCod,Craftsman,Georgian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.299e+05   1.77e+05     -0.735      0.462   -4.76e+05    2.17e+05\n",
      "Bungalow,CapeCod,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -3.568e+04   1.77e+05     -0.202      0.840   -3.82e+05    3.11e+05\n",
      "Bungalow,CapeCod,RaisedRanch,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.763e+05   1.77e+05     -0.997      0.319   -5.23e+05     1.7e+05\n",
      "Bungalow,CapeCod,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.398e+05   1.77e+05     -0.791      0.429   -4.86e+05    2.07e+05\n",
      "Bungalow,CapeCod,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.349e+05   1.25e+05     -1.078      0.281    -3.8e+05     1.1e+05\n",
      "Bungalow,CarriageHouse,Colonial,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                         -2.695e+05   1.77e+05     -1.524      0.127   -6.16e+05     7.7e+04\n",
      "Bungalow,CarriageHouse,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -7.246e+04   1.77e+05     -0.410      0.682   -4.19e+05    2.74e+05\n",
      "Bungalow,Coastal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -2.73e+05   1.77e+05     -1.544      0.123    -6.2e+05    7.36e+04\n",
      "Bungalow,Coastal,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.602e+04   1.02e+05     -0.157      0.875   -2.16e+05    1.84e+05\n",
      "Bungalow,Coastal,Cottage,Craftsman,Mediterranean,Rancher,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0057      0.002      2.982      0.003       0.002       0.010\n",
      "Bungalow,Coastal,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.0004      0.003      0.152      0.879      -0.005       0.006\n",
      "Bungalow,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -7.027e+04   7.24e+04     -0.971      0.332   -2.12e+05    7.16e+04\n",
      "Bungalow,Colonial,Contemporary,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -0.0013      0.002     -0.639      0.523      -0.005       0.003\n",
      "Bungalow,Colonial,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               0.0031      0.002      1.357      0.175      -0.001       0.008\n",
      "Bungalow,Colonial,Cottage,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -0.0003      0.002     -0.203      0.839      -0.004       0.003\n",
      "Bungalow,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.285e+05   7.93e+04     -1.621      0.105   -2.84e+05    2.69e+04\n",
      "Bungalow,Contemporary,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.503e+05   1.77e+05     -0.850      0.395   -4.97e+05    1.96e+05\n",
      "Bungalow,Contemporary,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -6.345e+04   1.25e+05     -0.507      0.612   -3.09e+05    1.82e+05\n",
      "Bungalow,ConvertedDwelling,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     4.665e+04   1.77e+05      0.264      0.792      -3e+05    3.93e+05\n",
      "Bungalow,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -3.955e+04   3.82e+04     -1.035      0.300   -1.14e+05    3.53e+04\n",
      "Bungalow,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -7.044e+04   1.77e+05     -0.398      0.690   -4.17e+05    2.76e+05\n",
      "Bungalow,Cottage,Craftsman,Other,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                -4.112e+04   1.77e+05     -0.233      0.816   -3.88e+05    3.05e+05\n",
      "Bungalow,Cottage,Craftsman,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.618e+04   1.77e+05     -0.092      0.927   -3.63e+05     3.3e+05\n",
      "Bungalow,Cottage,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -7.865e+04   1.77e+05     -0.445      0.656   -4.25e+05    2.68e+05\n",
      "Bungalow,Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -3.784e+04   6.71e+04     -0.564      0.573   -1.69e+05    9.36e+04\n",
      "Bungalow,Cottage,Rancher,Traditional,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -0.0017      0.002     -0.877      0.381      -0.006       0.002\n",
      "Bungalow,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.684e+04   1.77e+05     -0.152      0.879   -3.73e+05     3.2e+05\n",
      "Bungalow,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -4.78e+04   8.85e+04     -0.540      0.589   -2.21e+05    1.26e+05\n",
      "Bungalow,Craftsman,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             6803.6365   1.77e+05      0.038      0.969    -3.4e+05    3.53e+05\n",
      "Bungalow,Craftsman,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.828e+05   1.02e+05     -1.789      0.074   -3.83e+05    1.75e+04\n",
      "Bungalow,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -0.0003      0.002     -0.160      0.873      -0.004       0.003\n",
      "Bungalow,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -2.017e+05   1.77e+05     -1.141      0.254   -5.48e+05    1.45e+05\n",
      "Bungalow,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -8.158e+04   1.77e+05     -0.462      0.644   -4.28e+05    2.65e+05\n",
      "Bungalow,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -3.183e+04   1.77e+05     -0.180      0.857   -3.78e+05    3.15e+05\n",
      "Bungalow,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -9.375e+04   2.71e+04     -3.461      0.001   -1.47e+05   -4.07e+04\n",
      "Bungalow,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -0.0044      0.002     -1.952      0.051      -0.009    1.87e-05\n",
      "Bungalow,Rancher,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -3.092e+04   1.77e+05     -0.175      0.861   -3.77e+05    3.16e+05\n",
      "Bungalow,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.471e+05   1.77e+05     -0.832      0.405   -4.94e+05    1.99e+05\n",
      "Bungalow,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.0025      0.002      1.224      0.221      -0.002       0.007\n",
      "Bungalow,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.066e+05   5.62e+04     -1.896      0.058   -2.17e+05    3591.810\n",
      "CabinLodge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -7.633e+04   3.29e+04     -2.321      0.020   -1.41e+05   -1.19e+04\n",
      "CabinLodge,CapeCod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.0028      0.002      1.368      0.171      -0.001       0.007\n",
      "CabinLodge,CapeCod,CarriageHouse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.462e+05   1.77e+05     -0.827      0.408   -4.93e+05       2e+05\n",
      "CabinLodge,CarriageHouse,Coastal,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.336e+05   1.77e+05     -0.756      0.450    -4.8e+05    2.13e+05\n",
      "CabinLodge,Chalet,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.914e+04   1.77e+05      0.108      0.914   -3.27e+05    3.66e+05\n",
      "CabinLodge,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -3.626e+05   1.25e+05     -2.899      0.004   -6.08e+05   -1.17e+05\n",
      "CabinLodge,Colonial,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.74e+05   1.77e+05     -0.984      0.325    -5.2e+05    1.72e+05\n",
      "CabinLodge,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -8916.9023   1.02e+05     -0.087      0.930   -2.09e+05    1.91e+05\n",
      "CabinLodge,Contemporary,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.092e+05   1.25e+05     -0.873      0.383   -3.54e+05    1.36e+05\n",
      "CabinLodge,Contemporary,Craftsman,Other,PostAndBeam,Prairie,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                    -0.0052      0.002     -2.743      0.006      -0.009      -0.001\n",
      "CabinLodge,Contemporary,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -9.216e+04   1.77e+05     -0.521      0.602   -4.39e+05    2.54e+05\n",
      "CabinLodge,Contemporary,Other,PostAndBeam,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -8.181e+04   1.77e+05     -0.463      0.643   -4.28e+05    2.65e+05\n",
      "CabinLodge,Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.18e+05   1.77e+05     -0.667      0.505   -4.65e+05    2.29e+05\n",
      "CabinLodge,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.334e+06    1.8e+05     -7.389      0.000   -1.69e+06    -9.8e+05\n",
      "CabinLodge,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -7.696e+04   7.93e+04     -0.971      0.332   -2.32e+05    7.84e+04\n",
      "CabinLodge,LogHome,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3.633e+04   1.77e+05      0.206      0.837    -3.1e+05    3.83e+05\n",
      "CabinLodge,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.624e+05   1.77e+05     -0.919      0.358   -5.09e+05    1.84e+05\n",
      "CabinLodge,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -0.0038      0.001     -2.582      0.010      -0.007      -0.001\n",
      "CapeCod                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.081e+05   6613.984    -16.350      0.000   -1.21e+05   -9.52e+04\n",
      "CapeCod,CarriageHouse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -3.079e+05   1.77e+05     -1.742      0.082   -6.54e+05    3.86e+04\n",
      "CapeCod,CarriageHouse,Colonial,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.638e+05   1.77e+05     -0.926      0.354    -5.1e+05    1.83e+05\n",
      "CapeCod,CarriageHouse,Colonial,Georgian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.0002      0.002      0.099      0.921      -0.003       0.004\n",
      "CapeCod,CarriageHouse,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.0032      0.002      1.525      0.127      -0.001       0.007\n",
      "CapeCod,Chalet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -7.283e+05   1.77e+05     -4.119      0.000   -1.07e+06   -3.82e+05\n",
      "CapeCod,Coastal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.308e+05   1.77e+05     -0.740      0.459   -4.77e+05    2.16e+05\n",
      "CapeCod,Coastal,Colonial,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -4.376e+04   1.77e+05     -0.247      0.805    -3.9e+05    3.03e+05\n",
      "CapeCod,Coastal,Colonial,Cottage,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1.391e+05   1.77e+05      0.787      0.431   -2.07e+05    4.86e+05\n",
      "CapeCod,Coastal,Colonial,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   6.591e+05   1.77e+05      3.729      0.000    3.13e+05    1.01e+06\n",
      "CapeCod,Coastal,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.436e+05   1.77e+05     -1.378      0.168    -5.9e+05    1.03e+05\n",
      "CapeCod,Coastal,Contemporary,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.0015      0.002      0.770      0.441      -0.002       0.005\n",
      "CapeCod,Coastal,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              3.622e+04   1.25e+05      0.290      0.772   -2.09e+05    2.81e+05\n",
      "CapeCod,Coastal,Cottage,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -2.823e+04   1.77e+05     -0.160      0.873   -3.75e+05    3.18e+05\n",
      "CapeCod,Coastal,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3.448e+05   1.77e+05      1.951      0.051   -1668.723    6.91e+05\n",
      "CapeCod,Coastal,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.54e+05   8.86e+04      1.738      0.082   -1.96e+04    3.28e+05\n",
      "CapeCod,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -9.885e+04   2.68e+04     -3.692      0.000   -1.51e+05   -4.64e+04\n",
      "CapeCod,Colonial,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -7.715e+04   1.77e+05     -0.436      0.663   -4.24e+05    2.69e+05\n",
      "CapeCod,Colonial,Contemporary,Cottage,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.95e+05   1.77e+05     -1.103      0.270   -5.41e+05    1.51e+05\n",
      "CapeCod,Colonial,Contemporary,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -2.18e+05   1.25e+05     -1.743      0.081   -4.63e+05    2.72e+04\n",
      "CapeCod,Colonial,Contemporary,DwellingwSeparateLivingArea,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.33e+05   1.77e+05     -0.752      0.452   -4.79e+05    2.13e+05\n",
      "CapeCod,Colonial,Cottage,Georgian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1.486e+05   1.77e+05      0.841      0.401   -1.98e+05    4.95e+05\n",
      "CapeCod,Colonial,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -8.025e+04   1.77e+05     -0.454      0.650   -4.27e+05    2.66e+05\n",
      "CapeCod,Colonial,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -6.124e+04   1.25e+05     -0.490      0.624   -3.06e+05    1.84e+05\n",
      "CapeCod,Colonial,Craftsman,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.0058      0.002      2.568      0.010       0.001       0.010\n",
      "CapeCod,Colonial,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -0.0033      0.002     -1.470      0.142      -0.008       0.001\n",
      "CapeCod,Colonial,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -5.067e+05   1.77e+05     -2.866      0.004   -8.53e+05    -1.6e+05\n",
      "CapeCod,Colonial,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.216e+05   1.77e+05     -0.688      0.491   -4.68e+05    2.25e+05\n",
      "CapeCod,Colonial,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.305e+05   1.77e+05     -0.738      0.460   -4.77e+05    2.16e+05\n",
      "CapeCod,Colonial,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -2.772e+05   1.77e+05     -1.568      0.117   -6.24e+05    6.92e+04\n",
      "CapeCod,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.41e+05   7.24e+04     -1.948      0.051   -2.83e+05     834.338\n",
      "CapeCod,Contemporary,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.129e+05   1.77e+05     -0.639      0.523   -4.59e+05    2.34e+05\n",
      "CapeCod,Contemporary,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.178e+05   1.77e+05     -0.667      0.505   -4.64e+05    2.29e+05\n",
      "CapeCod,Contemporary,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -2.79e+05   1.25e+05     -2.231      0.026   -5.24e+05   -3.39e+04\n",
      "CapeCod,Contemporary,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -5.572e+04   1.77e+05     -0.315      0.753   -4.02e+05    2.91e+05\n",
      "CapeCod,Contemporary,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.442e+05   1.77e+05     -0.816      0.415   -4.91e+05    2.02e+05\n",
      "CapeCod,Contemporary,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -2.351e+05   1.77e+05     -1.330      0.184   -5.82e+05    1.11e+05\n",
      "CapeCod,Contemporary,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.29e+05   1.77e+05     -0.730      0.466   -4.75e+05    2.17e+05\n",
      "CapeCod,ConvertedDwelling,DwellingwSeparateLivingArea,LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                               -2.05e+05   1.77e+05     -1.160      0.246   -5.51e+05    1.41e+05\n",
      "CapeCod,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -9.748e+04   3.91e+04     -2.496      0.013   -1.74e+05   -2.09e+04\n",
      "CapeCod,Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.416e+05   1.77e+05     -0.801      0.423   -4.88e+05    2.05e+05\n",
      "CapeCod,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.919e+04   1.77e+05      0.109      0.914   -3.27e+05    3.66e+05\n",
      "CapeCod,Cottage,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.336e+05   1.77e+05      0.756      0.450   -2.13e+05     4.8e+05\n",
      "CapeCod,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.14e+05   5.92e+04     -1.925      0.054    -2.3e+05    2070.805\n",
      "CapeCod,Craftsman,Dutch,Federal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -4.048e+05   1.77e+05     -2.290      0.022   -7.51e+05   -5.84e+04\n",
      "CapeCod,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -6.879e+04   1.77e+05     -0.389      0.697   -4.15e+05    2.78e+05\n",
      "CapeCod,Craftsman,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2.453e+05   1.77e+05      1.388      0.165   -1.01e+05    5.92e+05\n",
      "CapeCod,DwellingwSeparateLivingArea,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -2.255e+05   1.77e+05     -1.276      0.202   -5.72e+05    1.21e+05\n",
      "CapeCod,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.25e+05   1.25e+05     -0.999      0.318    -3.7e+05     1.2e+05\n",
      "CapeCod,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.057e+05   1.77e+05      0.598      0.550   -2.41e+05    4.52e+05\n",
      "CapeCod,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.095e+05   1.77e+05     -0.620      0.536   -4.56e+05    2.37e+05\n",
      "CapeCod,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -3.659e+04   7.93e+04     -0.462      0.644   -1.92e+05    1.19e+05\n",
      "CapeCod,LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.986e+05   1.77e+05     -1.121      0.262   -5.46e+05    1.49e+05\n",
      "CapeCod,Mediterranean                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0022      0.002     -1.019      0.308      -0.006       0.002\n",
      "CapeCod,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.672e+05   5.92e+04     -2.824      0.005   -2.83e+05   -5.11e+04\n",
      "CapeCod,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -3.17e+04   1.77e+05     -0.179      0.858   -3.79e+05    3.16e+05\n",
      "CapeCod,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -5.949e+04   1.77e+05     -0.337      0.736   -4.06e+05    2.87e+05\n",
      "CapeCod,PreFabricated                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.433e+05   1.77e+05     -0.811      0.417    -4.9e+05    2.03e+05\n",
      "CapeCod,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.0076      0.002      3.788      0.000       0.004       0.012\n",
      "CapeCod,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -2.105e+05   1.25e+05     -1.683      0.092   -4.56e+05    3.46e+04\n",
      "CapeCod,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.203e+05   4.46e+04     -2.697      0.007   -2.08e+05   -3.29e+04\n",
      "CapeCod,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -2.788e+05   1.77e+05     -1.577      0.115   -6.25e+05    6.77e+04\n",
      "CapeCod,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.523e+05   1.77e+05     -0.861      0.389   -4.99e+05    1.94e+05\n",
      "CapeCod,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -9656.5869   1.77e+05     -0.055      0.956   -3.56e+05    3.37e+05\n",
      "CapeCod,StraightThru,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.519e+05   1.77e+05     -0.859      0.390   -4.98e+05    1.95e+05\n",
      "CapeCod,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.108e+05    3.9e+04     -2.837      0.005   -1.87e+05   -3.42e+04\n",
      "CapeCod,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 4.737e+05   1.25e+05      3.787      0.000    2.29e+05    7.19e+05\n",
      "CapeCod,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.0033      0.002      1.858      0.063      -0.000       0.007\n",
      "CapeCod,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1.254e+05   1.77e+05      0.709      0.478   -2.21e+05    4.72e+05\n",
      "CarriageHouse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -5.758e+04      4e+04     -1.440      0.150   -1.36e+05    2.08e+04\n",
      "CarriageHouse,Coastal,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       4.918e+05   1.77e+05      2.782      0.005    1.45e+05    8.38e+05\n",
      "CarriageHouse,Coastal,Cottage,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.902e+05   1.77e+05      1.076      0.282   -1.56e+05    5.37e+05\n",
      "CarriageHouse,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.098e+05   1.02e+05     -1.074      0.283    -3.1e+05    9.05e+04\n",
      "CarriageHouse,Colonial,DwellingwSeparateLivingArea,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                       2.849e+04   1.77e+05      0.161      0.872   -3.18e+05    3.75e+05\n",
      "CarriageHouse,Colonial,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   5.273e+05   1.77e+05      2.983      0.003    1.81e+05    8.74e+05\n",
      "CarriageHouse,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -2.282e+05   1.77e+05     -1.291      0.197   -5.75e+05    1.18e+05\n",
      "CarriageHouse,ConvertedBarn                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -0.0007      0.002     -0.430      0.667      -0.004       0.003\n",
      "CarriageHouse,ConvertedBarn,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0066      0.002     -3.126      0.002      -0.011      -0.002\n",
      "CarriageHouse,Federal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0009      0.002     -0.557      0.577      -0.004       0.002\n",
      "CarriageHouse,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0036      0.002     -1.993      0.046      -0.007   -5.91e-05\n",
      "CarriageHouse,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.758e+05   1.77e+05     -0.995      0.320   -5.22e+05    1.71e+05\n",
      "CarriageHouse,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.638e+05   1.77e+05     -0.927      0.354    -5.1e+05    1.83e+05\n",
      "CarriageHouse,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -0.0020      0.002     -0.962      0.336      -0.006       0.002\n",
      "Chalet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -9.814e+04    4.1e+04     -2.394      0.017   -1.78e+05   -1.78e+04\n",
      "Chalet,Coastal,Colonial,Contemporary,Cottage,Craftsman,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                            -2.602e+04   1.77e+05     -0.147      0.883   -3.72e+05     3.2e+05\n",
      "Chalet,Coastal,Cottage,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                             6.038e+04   1.77e+05      0.342      0.733   -2.86e+05    4.07e+05\n",
      "Chalet,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2.369e+04   1.25e+05      0.189      0.850   -2.21e+05    2.69e+05\n",
      "Chalet,Colonial,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           19.6991   1.77e+05      0.000      1.000   -3.46e+05    3.46e+05\n",
      "Chalet,Colonial,Contemporary,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                               6505.3049   1.77e+05      0.037      0.971    -3.4e+05    3.53e+05\n",
      "Chalet,Colonial,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -8.224e+04   1.77e+05     -0.465      0.642   -4.29e+05    2.64e+05\n",
      "Chalet,Colonial,RaisedRanch,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.51e+05   1.77e+05     -0.854      0.393   -4.97e+05    1.95e+05\n",
      "Chalet,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  5.169e+04   1.77e+05      0.292      0.770   -2.95e+05    3.98e+05\n",
      "Chalet,Contemporary,Cottage,Traditional,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.325e+05   1.77e+05     -0.750      0.453   -4.79e+05    2.14e+05\n",
      "Chalet,Contemporary,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -6.443e+04   1.77e+05     -0.365      0.715   -4.11e+05    2.82e+05\n",
      "Chalet,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -7.587e+04   1.25e+05     -0.607      0.544   -3.21e+05    1.69e+05\n",
      "Coastal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.792e+05   1.58e+04     11.319      0.000    1.48e+05     2.1e+05\n",
      "Coastal,Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     5.698e+04   3.19e+04      1.788      0.074   -5475.041    1.19e+05\n",
      "Coastal,Colonial,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -7.636e+04   8.86e+04     -0.862      0.389    -2.5e+05    9.72e+04\n",
      "Coastal,Colonial,Contemporary,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                              7.138e+04   1.77e+05      0.404      0.686   -2.75e+05    4.18e+05\n",
      "Coastal,Colonial,Contemporary,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.106e+05   1.77e+05     -0.626      0.532   -4.57e+05    2.36e+05\n",
      "Coastal,Colonial,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -3.661e+05   1.25e+05     -2.926      0.003   -6.11e+05   -1.21e+05\n",
      "Coastal,Colonial,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -7.452e+04   1.25e+05     -0.596      0.551    -3.2e+05    1.71e+05\n",
      "Coastal,Colonial,Craftsman,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.188e+06   1.77e+05      6.717      0.000    8.41e+05    1.53e+06\n",
      "Coastal,Colonial,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.0045      0.002      2.061      0.039       0.000       0.009\n",
      "Coastal,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 3.649e+05   4.01e+04      9.105      0.000    2.86e+05    4.43e+05\n",
      "Coastal,Contemporary,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1.718e+06   1.25e+05     13.734      0.000    1.47e+06    1.96e+06\n",
      "Coastal,Contemporary,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.413e+05   1.77e+05      0.799      0.424   -2.05e+05    4.88e+05\n",
      "Coastal,Contemporary,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1.686e+05   1.77e+05      0.954      0.340   -1.78e+05    5.15e+05\n",
      "Coastal,Contemporary,LoftwithBedrooms,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -2.634e+05   1.77e+05     -1.490      0.136    -6.1e+05    8.31e+04\n",
      "Coastal,Contemporary,MidCenturyModern                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0053      0.002     -2.982      0.003      -0.009      -0.002\n",
      "Coastal,Contemporary,Prairie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2.712e+05   1.77e+05      1.534      0.125   -7.53e+04    6.18e+05\n",
      "Coastal,Contemporary,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.624e+05   1.77e+05     -0.919      0.358   -5.09e+05    1.84e+05\n",
      "Coastal,Contemporary,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2.869e+05   1.25e+05      2.293      0.022    4.17e+04    5.32e+05\n",
      "Coastal,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      4.681e+04   4.61e+04      1.016      0.310   -4.35e+04    1.37e+05\n",
      "Coastal,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -6.869e+04   1.25e+05     -0.549      0.583   -3.14e+05    1.76e+05\n",
      "Coastal,Cottage,Dutch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                5.525e+05   1.77e+05      3.126      0.002    2.06e+05    8.99e+05\n",
      "Coastal,Cottage,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1.318e+05   1.77e+05     -0.745      0.456   -4.78e+05    2.15e+05\n",
      "Coastal,Cottage,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -4.765e+04   1.77e+05     -0.270      0.788   -3.94e+05    2.99e+05\n",
      "Coastal,Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -2.174e+04   1.77e+05     -0.123      0.902   -3.68e+05    3.25e+05\n",
      "Coastal,Cottage,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -0.0014      0.002     -0.740      0.459      -0.005       0.002\n",
      "Coastal,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1.333e+04   1.25e+05     -0.107      0.915   -2.58e+05    2.32e+05\n",
      "Coastal,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2.181e+05   4.94e+04      4.415      0.000    1.21e+05    3.15e+05\n",
      "Coastal,Craftsman,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -2.55e+05   1.77e+05     -1.442      0.149   -6.02e+05    9.15e+04\n",
      "Coastal,Craftsman,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.898e+05   1.77e+05     -1.074      0.283   -5.36e+05    1.57e+05\n",
      "Coastal,Craftsman,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -5.505e+04   1.77e+05     -0.311      0.756   -4.02e+05    2.91e+05\n",
      "Coastal,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        3.356e+05   1.77e+05      1.898      0.058    -1.1e+04    6.82e+05\n",
      "Coastal,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       5.555e+05   1.77e+05      3.141      0.002    2.09e+05    9.02e+05\n",
      "Coastal,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.031e+05   1.77e+05     -0.583      0.560    -4.5e+05    2.43e+05\n",
      "Coastal,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      6.972e+04   1.77e+05      0.394      0.693   -2.77e+05    4.16e+05\n",
      "Coastal,MidCenturyModern                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.393e+06   1.77e+05      7.878      0.000    1.05e+06    1.74e+06\n",
      "Coastal,Other,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.37e+04   1.77e+05     -0.078      0.938    -3.6e+05    3.33e+05\n",
      "Coastal,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            3.121e+05   1.25e+05      2.495      0.013    6.69e+04    5.57e+05\n",
      "Coastal,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -2.175e+05   1.77e+05     -1.231      0.218   -5.64e+05    1.29e+05\n",
      "Coastal,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -2.359e+05   1.25e+05     -1.886      0.059   -4.81e+05    9297.490\n",
      "Coastal,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3.489e+04   1.77e+05      0.197      0.844   -3.12e+05    3.81e+05\n",
      "Coastal,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -2.019e+04   1.77e+05     -0.114      0.909   -3.67e+05    3.26e+05\n",
      "Coastal,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.617e+04   1.25e+05     -0.129      0.897   -2.61e+05    2.29e+05\n",
      "Coastal,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  4.902e+05   5.62e+04      8.714      0.000     3.8e+05       6e+05\n",
      "Coastal,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 2.198e+05   7.24e+04      3.036      0.002    7.79e+04    3.62e+05\n",
      "Coastal,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    9.559e+05   1.77e+05      5.408      0.000    6.09e+05     1.3e+06\n",
      "Coastal,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         3.14e+05   1.77e+05      1.777      0.076   -3.24e+04     6.6e+05\n",
      "Colonial                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -8.244e+04   6293.465    -13.099      0.000   -9.48e+04   -7.01e+04\n",
      "Colonial,Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.139e+05   1.57e+04     -7.236      0.000   -1.45e+05   -8.31e+04\n",
      "Colonial,Contemporary,ConvertedDwelling                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.524e+05   1.77e+05     -0.862      0.389   -4.99e+05    1.94e+05\n",
      "Colonial,Contemporary,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.67e+05   1.77e+05     -1.510      0.131   -6.14e+05    7.95e+04\n",
      "Colonial,Contemporary,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -2.632e+05   1.77e+05     -1.488      0.137    -6.1e+05    8.34e+04\n",
      "Colonial,Contemporary,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      4.619e+04   5.92e+04      0.780      0.435   -6.99e+04    1.62e+05\n",
      "Colonial,Contemporary,Craftsman,LoftwithBedrooms,LogHome,MidCenturyModern,Other,PostAndBeam,RaisedRanch,Rancher,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                            -1.056e+05   1.77e+05     -0.597      0.550   -4.52e+05    2.41e+05\n",
      "Colonial,Contemporary,Craftsman,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.687e+05   1.77e+05     -0.954      0.340   -5.15e+05    1.78e+05\n",
      "Colonial,Contemporary,Craftsman,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2.523e+05   1.77e+05      1.427      0.153   -9.41e+04    5.99e+05\n",
      "Colonial,Contemporary,Craftsman,SplitFoyer,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                   -1.914e+05   1.25e+05     -1.530      0.126   -4.37e+05    5.38e+04\n",
      "Colonial,Contemporary,Craftsman,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -2.486e+05   1.77e+05     -1.406      0.160   -5.95e+05    9.79e+04\n",
      "Colonial,Contemporary,Dutch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -4.756e+04   1.77e+05     -0.269      0.788   -3.94e+05    2.99e+05\n",
      "Colonial,Contemporary,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2.736e+05   1.77e+05      1.548      0.122   -7.29e+04     6.2e+05\n",
      "Colonial,Contemporary,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -4613.9319   1.77e+05     -0.026      0.979   -3.51e+05    3.42e+05\n",
      "Colonial,Contemporary,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -0.0062      0.002     -3.486      0.000      -0.010      -0.003\n",
      "Colonial,Contemporary,Mediterranean,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.171e+05   1.77e+05     -0.663      0.508   -4.64e+05    2.29e+05\n",
      "Colonial,Contemporary,MidCenturyModern                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -4.674e+04   1.77e+05     -0.264      0.791   -3.93e+05       3e+05\n",
      "Colonial,Contemporary,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1567.5321   7.92e+04     -0.020      0.984   -1.57e+05    1.54e+05\n",
      "Colonial,Contemporary,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2.567e+05   1.77e+05      1.452      0.147   -8.98e+04    6.03e+05\n",
      "Colonial,Contemporary,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -1.554e+05   1.77e+05     -0.879      0.379   -5.02e+05    1.91e+05\n",
      "Colonial,Contemporary,RaisedRanch,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.289e+05   1.77e+05     -0.729      0.466   -4.75e+05    2.18e+05\n",
      "Colonial,Contemporary,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1.98e+04   1.02e+05      0.194      0.846    -1.8e+05     2.2e+05\n",
      "Colonial,Contemporary,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -0.0048      0.002     -1.972      0.049      -0.010   -2.88e-05\n",
      "Colonial,Contemporary,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -2.164e+05   1.77e+05     -1.224      0.221   -5.63e+05     1.3e+05\n",
      "Colonial,Contemporary,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    8.249e+04   8.85e+04      0.932      0.352   -9.11e+04    2.56e+05\n",
      "Colonial,Contemporary,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1.949e+05   7.93e+04      2.459      0.014    3.96e+04     3.5e+05\n",
      "Colonial,Contemporary,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1702.9423   1.77e+05      0.010      0.992   -3.45e+05    3.48e+05\n",
      "Colonial,ConvertedBarn,LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -8.464e+05   1.77e+05     -4.784      0.000   -1.19e+06      -5e+05\n",
      "Colonial,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     8.435e+04   6.28e+04      1.343      0.179   -3.87e+04    2.07e+05\n",
      "Colonial,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           8.149e+04   1.77e+05      0.461      0.645   -2.65e+05    4.28e+05\n",
      "Colonial,Cottage,Craftsman,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                        -7131.5945   1.77e+05     -0.040      0.968   -3.54e+05    3.39e+05\n",
      "Colonial,Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -8.388e+04   1.02e+05     -0.821      0.412   -2.84e+05    1.16e+05\n",
      "Colonial,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -4.153e+04   1.51e+04     -2.746      0.006   -7.12e+04   -1.19e+04\n",
      "Colonial,Craftsman,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -5579.1962   1.25e+05     -0.045      0.964   -2.51e+05     2.4e+05\n",
      "Colonial,Craftsman,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                 5.384e+04   1.77e+05      0.305      0.761   -2.93e+05       4e+05\n",
      "Colonial,Craftsman,Federal,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -6.335e+04   1.77e+05     -0.358      0.720    -4.1e+05    2.83e+05\n",
      "Colonial,Craftsman,LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -4.897e+04   2.96e+04     -1.654      0.098   -1.07e+05    9065.020\n",
      "Colonial,Craftsman,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.38e+05   1.25e+05     -1.103      0.270   -3.83e+05    1.07e+05\n",
      "Colonial,Craftsman,Other,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.372e+05   1.77e+05     -0.776      0.438   -4.84e+05    2.09e+05\n",
      "Colonial,Craftsman,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  2.06e+05   1.77e+05      1.165      0.244   -1.41e+05    5.53e+05\n",
      "Colonial,Craftsman,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -9.858e+04   1.77e+05     -0.558      0.577   -4.45e+05    2.48e+05\n",
      "Colonial,Craftsman,SaltBox,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.989e+05   1.77e+05     -1.125      0.261   -5.45e+05    1.48e+05\n",
      "Colonial,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -4.019e+04   4.33e+04     -0.927      0.354   -1.25e+05    4.48e+04\n",
      "Colonial,Craftsman,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2.601e+04   1.02e+05      0.254      0.799   -1.74e+05    2.26e+05\n",
      "Colonial,Dutch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -7.695e+04   2.38e+04     -3.229      0.001   -1.24e+05   -3.02e+04\n",
      "Colonial,Dutch,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.0005      0.002      0.224      0.822      -0.004       0.005\n",
      "Colonial,Dutch,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -4.944e+04   1.25e+05     -0.395      0.693   -2.95e+05    1.96e+05\n",
      "Colonial,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -2.034e+05   6.28e+04     -3.240      0.001   -3.26e+05   -8.04e+04\n",
      "Colonial,DwellingwSeparateLivingArea,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -7.637e+04   1.77e+05     -0.432      0.666   -4.23e+05     2.7e+05\n",
      "Colonial,DwellingwSeparateLivingArea,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -2.203e+05   1.25e+05     -1.761      0.078   -4.66e+05    2.49e+04\n",
      "Colonial,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -6.96e+04   3.34e+04     -2.085      0.037   -1.35e+05   -4158.742\n",
      "Colonial,FarmhouseNationalFolk,Federal                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.307e+05   1.77e+05     -0.739      0.460   -4.77e+05    2.16e+05\n",
      "Colonial,FarmhouseNationalFolk,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.367e+04   1.77e+05     -0.077      0.938    -3.6e+05    3.33e+05\n",
      "Colonial,FarmhouseNationalFolk,Manor,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                     4.369e+05   1.77e+05      2.472      0.013    9.05e+04    7.83e+05\n",
      "Colonial,FarmhouseNationalFolk,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -5.585e+04   1.77e+05     -0.316      0.752   -4.02e+05    2.91e+05\n",
      "Colonial,FarmhouseNationalFolk,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.534e+05   1.77e+05     -0.868      0.386      -5e+05    1.93e+05\n",
      "Colonial,FarmhouseNationalFolk,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.251e+05   1.77e+05     -0.708      0.479   -4.72e+05    2.21e+05\n",
      "Colonial,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -5.627e+04   6.28e+04     -0.897      0.370   -1.79e+05    6.67e+04\n",
      "Colonial,FarmhouseNationalFolk,Traditional,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.131e+05   1.77e+05     -0.640      0.522    -4.6e+05    2.33e+05\n",
      "Colonial,FarmhouseNationalFolk,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -6.531e+04   1.02e+05     -0.639      0.523   -2.66e+05    1.35e+05\n",
      "Colonial,Federal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -6.565e+04   7.93e+04     -0.828      0.407   -2.21e+05    8.97e+04\n",
      "Colonial,Federal,Georgian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -0.0021      0.002     -1.012      0.312      -0.006       0.002\n",
      "Colonial,Federal,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.701e+04   1.25e+05     -0.136      0.892   -2.62e+05    2.28e+05\n",
      "Colonial,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3.28e+05   6.28e+04      5.225      0.000    2.05e+05    4.51e+05\n",
      "Colonial,French,Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0010      0.002     -0.592      0.554      -0.004       0.002\n",
      "Colonial,French,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1.669e+04   1.77e+05      0.094      0.925    -3.3e+05    3.63e+05\n",
      "Colonial,French,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -6.45e+04   1.77e+05     -0.365      0.715   -4.11e+05    2.82e+05\n",
      "Colonial,French,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.0047      0.002      2.171      0.030       0.000       0.009\n",
      "Colonial,Georgian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -2.096e+05   7.24e+04     -2.894      0.004   -3.52e+05   -6.77e+04\n",
      "Colonial,Georgian,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        8.951e+05   1.25e+05      7.156      0.000     6.5e+05    1.14e+06\n",
      "Colonial,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -2.403e+04    3.4e+04     -0.708      0.479   -9.06e+04    4.25e+04\n",
      "Colonial,Loft,LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0014      0.002      0.812      0.417      -0.002       0.005\n",
      "Colonial,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -0.0023      0.002     -0.948      0.343      -0.007       0.002\n",
      "Colonial,Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       9.023e+04   8.86e+04      1.019      0.308   -8.34e+04    2.64e+05\n",
      "Colonial,Manor,Other,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.352e+05   1.77e+05     -0.765      0.444   -4.82e+05    2.11e+05\n",
      "Colonial,Manor,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              5126.9244   1.77e+05      0.029      0.977   -3.41e+05    3.52e+05\n",
      "Colonial,Mediterranean                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               3.135e+05   1.77e+05      1.774      0.076    -3.3e+04     6.6e+05\n",
      "Colonial,Mediterranean,Spanish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -2.782e+05   1.77e+05     -1.574      0.115   -6.25e+05    6.82e+04\n",
      "Colonial,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       4.244e+04   5.36e+04      0.792      0.429   -6.27e+04    1.48e+05\n",
      "Colonial,Other,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.996e+05   8.86e+04     -2.254      0.024   -3.73e+05    -2.6e+04\n",
      "Colonial,Other,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -9.414e+04   1.77e+05     -0.533      0.594   -4.41e+05    2.52e+05\n",
      "Colonial,Other,SplitFoyer,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.0010      0.002      0.592      0.554      -0.002       0.004\n",
      "Colonial,Other,SplitFoyer,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -6.926e+04   1.77e+05     -0.392      0.695   -4.16e+05    2.77e+05\n",
      "Colonial,Other,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.393e+05   1.77e+05     -0.788      0.431   -4.86e+05    2.07e+05\n",
      "Colonial,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -6.95e+04   1.02e+05     -0.680      0.496    -2.7e+05    1.31e+05\n",
      "Colonial,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3.12e+05   1.02e+05      3.053      0.002    1.12e+05    5.12e+05\n",
      "Colonial,PreFabricated                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -4.411e+05   1.77e+05     -2.495      0.013   -7.88e+05   -9.45e+04\n",
      "Colonial,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -0.0013      0.002     -0.602      0.547      -0.006       0.003\n",
      "Colonial,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.421e+05   4.76e+04     -2.984      0.003   -2.35e+05   -4.88e+04\n",
      "Colonial,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.186e+05   1.25e+05     -1.747      0.081   -4.64e+05    2.66e+04\n",
      "Colonial,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.155e+05   1.02e+05     -1.130      0.258   -3.16e+05    8.48e+04\n",
      "Colonial,SidebySide                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.095e+05   1.77e+05     -0.620      0.535   -4.56e+05    2.37e+05\n",
      "Colonial,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.754e+05   4.46e+04     -3.932      0.000   -2.63e+05   -8.79e+04\n",
      "Colonial,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -2.694e+05   1.77e+05     -1.524      0.128   -6.16e+05    7.71e+04\n",
      "Colonial,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.113e+05   3.82e+04     -2.915      0.004   -1.86e+05   -3.64e+04\n",
      "Colonial,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.218e+05   1.25e+05     -0.974      0.330   -3.67e+05    1.23e+05\n",
      "Colonial,StraightThru,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -8.479e+04   1.77e+05     -0.480      0.631   -4.31e+05    2.62e+05\n",
      "Colonial,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -4.316e+04   1.28e+04     -3.384      0.001   -6.81e+04   -1.82e+04\n",
      "Colonial,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -8.403e+04   3.66e+04     -2.296      0.022   -1.56e+05   -1.23e+04\n",
      "Colonial,Traditional,Transitional,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -2.011e+05   1.77e+05     -1.138      0.255   -5.47e+05    1.45e+05\n",
      "Colonial,Traditional,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1.359e+05   1.77e+05      0.769      0.442   -2.11e+05    4.82e+05\n",
      "Colonial,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                4.908e+04   2.37e+04      2.071      0.038    2637.655    9.55e+04\n",
      "Colonial,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3269.9071   5.92e+04      0.055      0.956   -1.13e+05    1.19e+05\n",
      "Colonial,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.494e+05    4.6e+04     -3.245      0.001    -2.4e+05   -5.92e+04\n",
      "CondoUnit                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.433e+05   5.14e+04     -2.790      0.005   -2.44e+05   -4.26e+04\n",
      "Contemporary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -3.928e+04   7395.353     -5.311      0.000   -5.38e+04   -2.48e+04\n",
      "Contemporary,ConvertedDwelling                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -8.287e+04   1.77e+05     -0.469      0.639   -4.29e+05    2.64e+05\n",
      "Contemporary,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -7.344e+04   1.77e+05     -0.415      0.678    -4.2e+05    2.73e+05\n",
      "Contemporary,Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1.774e+05   1.77e+05      1.004      0.316   -1.69e+05    5.24e+05\n",
      "Contemporary,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -3.068e+04   6.71e+04     -0.457      0.647   -1.62e+05    1.01e+05\n",
      "Contemporary,Craftsman,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -4363.6827   1.25e+05     -0.035      0.972    -2.5e+05    2.41e+05\n",
      "Contemporary,Craftsman,FarmhouseNationalFolk,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                       -0.0056      0.002     -2.539      0.011      -0.010      -0.001\n",
      "Contemporary,Craftsman,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      0.0037      0.002      1.584      0.113      -0.001       0.008\n",
      "Contemporary,Craftsman,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0026      0.001      2.045      0.041       0.000       0.005\n",
      "Contemporary,Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.276e+05   1.02e+05     -1.249      0.212   -3.28e+05    7.27e+04\n",
      "Contemporary,Craftsman,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1.984e+05   1.02e+05      1.941      0.052   -1971.176    3.99e+05\n",
      "Contemporary,Dome,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -0.0049      0.002     -2.351      0.019      -0.009      -0.001\n",
      "Contemporary,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -3.552e+05   1.77e+05     -2.009      0.045   -7.02e+05   -8664.772\n",
      "Contemporary,DwellingwSeparateLivingArea,Rancher,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.302e+04   1.77e+05     -0.074      0.941    -3.6e+05    3.34e+05\n",
      "Contemporary,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1.376e+05   1.25e+05      1.100      0.271   -1.08e+05    3.83e+05\n",
      "Contemporary,Federal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.308e+05   1.25e+05     -1.046      0.296   -3.76e+05    1.14e+05\n",
      "Contemporary,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  4.133e+05   1.77e+05      2.338      0.019    6.69e+04     7.6e+05\n",
      "Contemporary,French,Mediterranean,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                4.817e+04   1.77e+05      0.273      0.785   -2.98e+05    3.95e+05\n",
      "Contemporary,French,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -0.0011      0.001     -0.808      0.419      -0.004       0.002\n",
      "Contemporary,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -5.203e+04   4.46e+04     -1.167      0.243   -1.39e+05    3.54e+04\n",
      "Contemporary,Loft,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -0.0028      0.002     -1.751      0.080      -0.006       0.000\n",
      "Contemporary,LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        8.785e+04   1.77e+05      0.497      0.619   -2.59e+05    4.34e+05\n",
      "Contemporary,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -3.738e+05   1.25e+05     -2.988      0.003   -6.19e+05   -1.29e+05\n",
      "Contemporary,Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2.862e+05   1.77e+05      1.619      0.105   -6.03e+04    6.33e+05\n",
      "Contemporary,Mediterranean                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           7.198e+05   1.77e+05      4.070      0.000    3.73e+05    1.07e+06\n",
      "Contemporary,Mediterranean,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1.467e+05   1.77e+05      0.830      0.406      -2e+05    4.93e+05\n",
      "Contemporary,MidCenturyModern                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        4615.4173   6.28e+04      0.074      0.941   -1.18e+05    1.28e+05\n",
      "Contemporary,MidCenturyModern,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -0.0006      0.002     -0.277      0.782      -0.005       0.004\n",
      "Contemporary,MidCenturyModern,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.542e+05   1.77e+05     -0.872      0.383   -5.01e+05    1.92e+05\n",
      "Contemporary,MidCenturyModern,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -0.0055      0.003     -2.043      0.041      -0.011      -0.000\n",
      "Contemporary,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2.735e+05   5.62e+04      4.866      0.000    1.63e+05    3.84e+05\n",
      "Contemporary,Other,RaisedRanch,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2.049e+04   1.77e+05      0.116      0.908   -3.26e+05    3.67e+05\n",
      "Contemporary,Other,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           3.447e+04   1.02e+05      0.337      0.736   -1.66e+05    2.35e+05\n",
      "Contemporary,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -4.519e+04   1.77e+05     -0.256      0.798   -3.92e+05    3.01e+05\n",
      "Contemporary,Other,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -4.626e+04   1.25e+05     -0.370      0.711   -2.91e+05    1.99e+05\n",
      "Contemporary,Other,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -3.944e+04   1.25e+05     -0.315      0.753   -2.85e+05    2.06e+05\n",
      "Contemporary,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             6.161e+04   7.24e+04      0.851      0.395   -8.03e+04    2.04e+05\n",
      "Contemporary,PostAndBeam,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  6.157e+04   1.25e+05      0.492      0.623   -1.84e+05    3.07e+05\n",
      "Contemporary,Prairie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -0.0010      0.001     -0.734      0.463      -0.004       0.002\n",
      "Contemporary,Prairie,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1.578e+05   1.77e+05      0.893      0.372   -1.89e+05    5.04e+05\n",
      "Contemporary,PreFabricated                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.0036      0.002      1.894      0.058      -0.000       0.007\n",
      "Contemporary,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -6.679e+04   1.25e+05     -0.534      0.593   -3.12e+05    1.78e+05\n",
      "Contemporary,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -4.155e+04   1.77e+05     -0.235      0.814   -3.88e+05    3.05e+05\n",
      "Contemporary,RaisedRanch,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.11e+05   1.77e+05     -0.628      0.530   -4.58e+05    2.35e+05\n",
      "Contemporary,RaisedRanch,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.178e+05   1.02e+05     -1.153      0.249   -3.18e+05    8.25e+04\n",
      "Contemporary,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -5.838e+04   2.38e+04     -2.451      0.014   -1.05e+05   -1.17e+04\n",
      "Contemporary,Rancher,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -3.042e+05   1.77e+05     -1.720      0.085   -6.51e+05    4.23e+04\n",
      "Contemporary,Rancher,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -9.916e+04   1.25e+05     -0.793      0.428   -3.44e+05    1.46e+05\n",
      "Contemporary,Reverse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -2.539e+05   1.77e+05     -1.436      0.151      -6e+05    9.26e+04\n",
      "Contemporary,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    0.0003      0.003      0.117      0.907      -0.005       0.005\n",
      "Contemporary,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.092e+05    3.9e+04     -2.797      0.005   -1.86e+05   -3.27e+04\n",
      "Contemporary,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.618e+05   1.77e+05     -0.915      0.360   -5.08e+05    1.85e+05\n",
      "Contemporary,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.294e+05   3.09e+04     -4.184      0.000    -1.9e+05   -6.88e+04\n",
      "Contemporary,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -2.133e+05   1.77e+05     -1.207      0.228    -5.6e+05    1.33e+05\n",
      "Contemporary,SplitLevel,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -4.566e+04   1.25e+05     -0.365      0.715   -2.91e+05    1.99e+05\n",
      "Contemporary,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             3.899e+04   3.59e+04      1.087      0.277   -3.13e+04    1.09e+05\n",
      "Contemporary,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.35e+05   1.02e+05     -1.321      0.187   -3.35e+05    6.53e+04\n",
      "Contemporary,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            7.931e+04      4e+04      1.983      0.047     931.265    1.58e+05\n",
      "Contemporary,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    8.18e+04   1.77e+05      0.463      0.644   -2.65e+05    4.28e+05\n",
      "Contemporary,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -2.03e+05   1.77e+05     -1.149      0.251   -5.49e+05    1.43e+05\n",
      "Contemporary,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.408e+05   1.77e+05     -0.797      0.426   -4.87e+05    2.06e+05\n",
      "ConvertedBarn                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.017e+05   1.02e+05     -0.996      0.319   -3.02e+05    9.86e+04\n",
      "ConvertedBarn,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0.0033      0.002      2.028      0.043       0.000       0.007\n",
      "ConvertedBarn,Cottage,FarmhouseNationalFolk,Loft,Other,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.167e+05   1.77e+05     -0.660      0.509   -4.63e+05     2.3e+05\n",
      "ConvertedBarn,Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -8.37e+04   1.77e+05     -0.474      0.636    -4.3e+05    2.63e+05\n",
      "ConvertedBarn,DwellingwSeparateLivingArea,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                1.335e+05   1.77e+05      0.755      0.450   -2.13e+05     4.8e+05\n",
      "ConvertedDwelling                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -4.162e+05   1.77e+05     -2.354      0.019   -7.63e+05   -6.97e+04\n",
      "ConvertedDwelling,Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -6.277e+05   1.77e+05     -3.550      0.000   -9.74e+05   -2.81e+05\n",
      "ConvertedDwelling,Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -9.828e+04   1.77e+05     -0.556      0.578   -4.45e+05    2.48e+05\n",
      "ConvertedDwelling,DwellingwSeparateLivingArea,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                               0.0050      0.001      3.581      0.000       0.002       0.008\n",
      "ConvertedDwelling,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              3.328e+04   1.77e+05      0.188      0.851   -3.13e+05     3.8e+05\n",
      "ConvertedDwelling,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -3.045e+05   1.77e+05     -1.723      0.085   -6.51e+05    4.19e+04\n",
      "ConvertedDwelling,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1.403e+05   1.77e+05      0.794      0.427   -2.06e+05    4.87e+05\n",
      "Cottage                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -4.292e+04   1.02e+04     -4.223      0.000   -6.28e+04    -2.3e+04\n",
      "Cottage,Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    3.211e+04   7.93e+04      0.405      0.685   -1.23e+05    1.87e+05\n",
      "Cottage,Craftsman,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -2.436e+05   1.77e+05     -1.378      0.168    -5.9e+05    1.03e+05\n",
      "Cottage,Craftsman,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -0.0009      0.003     -0.338      0.736      -0.006       0.005\n",
      "Cottage,Craftsman,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.0014      0.001      1.162      0.245      -0.001       0.004\n",
      "Cottage,DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   9.64e+04   1.25e+05      0.771      0.441   -1.49e+05    3.42e+05\n",
      "Cottage,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.0012      0.003      0.401      0.688      -0.005       0.007\n",
      "Cottage,FarmhouseNationalFolk,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -6.97e+05   1.77e+05     -3.932      0.000   -1.04e+06    -3.5e+05\n",
      "Cottage,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -7.201e+04   1.77e+05     -0.407      0.684   -4.18e+05    2.74e+05\n",
      "Cottage,FarmhouseNationalFolk,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                           3.054e+05   1.77e+05      1.727      0.084   -4.12e+04    6.52e+05\n",
      "Cottage,FarmhouseNationalFolk,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -7.165e+05   1.77e+05     -4.052      0.000   -1.06e+06    -3.7e+05\n",
      "Cottage,FarmhouseNationalFolk,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -0.0016      0.002     -0.896      0.371      -0.005       0.002\n",
      "Cottage,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3.491e+05   1.25e+05      2.791      0.005    1.04e+05    5.94e+05\n",
      "Cottage,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         5287.7583   1.25e+05      0.042      0.966    -2.4e+05     2.5e+05\n",
      "Cottage,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -0.0014      0.001     -2.061      0.039      -0.003   -6.62e-05\n",
      "Cottage,Other,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -6.967e+04   1.77e+05     -0.394      0.694   -4.16e+05    2.77e+05\n",
      "Cottage,PreFabricated                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -3.1e+04   1.77e+05     -0.175      0.861   -3.77e+05    3.15e+05\n",
      "Cottage,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -9000.7159   1.77e+05     -0.051      0.959   -3.56e+05    3.38e+05\n",
      "Cottage,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -7.226e+04    3.4e+04     -2.126      0.033   -1.39e+05   -5655.003\n",
      "Cottage,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          4.612e+04   1.77e+05      0.261      0.794      -3e+05    3.93e+05\n",
      "Cottage,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -542.8740   1.25e+05     -0.004      0.997   -2.46e+05    2.45e+05\n",
      "Cottage,SplitLevel,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.0008      0.002      0.349      0.727      -0.004       0.005\n",
      "Cottage,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  5.105e+05   5.92e+04      8.619      0.000    3.94e+05    6.27e+05\n",
      "Cottage,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  2.43e+05   1.77e+05      1.375      0.169   -1.03e+05    5.89e+05\n",
      "Cottage,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        9.469e+04   1.77e+05      0.536      0.592   -2.52e+05    4.41e+05\n",
      "Craftsman                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.669e+04   7894.344      2.115      0.034    1221.769    3.22e+04\n",
      "Craftsman,Dutch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -0.0005      0.001     -0.586      0.558      -0.002       0.001\n",
      "Craftsman,FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      4420.7941   1.77e+05      0.025      0.980   -3.43e+05    3.52e+05\n",
      "Craftsman,FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                          6.464e+04   1.77e+05      0.366      0.715   -2.82e+05    4.11e+05\n",
      "Craftsman,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2.4e+04   7.92e+04      0.303      0.762   -1.31e+05    1.79e+05\n",
      "Craftsman,Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      6.438e+05   1.77e+05      3.642      0.000    2.97e+05     9.9e+05\n",
      "Craftsman,Other,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.785e+05   1.77e+05     -1.010      0.313   -5.25e+05    1.68e+05\n",
      "Craftsman,Other,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.965e+05   1.77e+05     -1.112      0.266   -5.43e+05     1.5e+05\n",
      "Craftsman,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1411.2283   1.77e+05      0.008      0.994   -3.46e+05    3.48e+05\n",
      "Craftsman,Prairie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2.56e+05   1.77e+05      1.448      0.148   -9.05e+04    6.02e+05\n",
      "Craftsman,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -3.676e+05   1.77e+05     -2.079      0.038   -7.14e+05   -2.11e+04\n",
      "Craftsman,RaisedRanch,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.321e+05   1.77e+05     -0.747      0.455   -4.79e+05    2.14e+05\n",
      "Craftsman,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.22e+04    4.6e+04     -0.265      0.791   -1.02e+05     7.8e+04\n",
      "Craftsman,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -3.973e+04   1.77e+05     -0.225      0.822   -3.86e+05    3.07e+05\n",
      "Craftsman,Spanish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.0030      0.003      0.945      0.344      -0.003       0.009\n",
      "Craftsman,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 4.67e+04   2.46e+04      1.895      0.058   -1595.710     9.5e+04\n",
      "Craftsman,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   4.902e+04   1.02e+05      0.479      0.632   -1.51e+05    2.49e+05\n",
      "Craftsman,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               3.408e+05   7.93e+04      4.300      0.000    1.85e+05    4.96e+05\n",
      "Craftsman,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.0007      0.003      0.240      0.811      -0.005       0.007\n",
      "Dome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -5.297e+04   1.77e+05     -0.300      0.764   -3.99e+05    2.94e+05\n",
      "Dutch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -5.126e+04   2.14e+04     -2.391      0.017   -9.33e+04   -9232.388\n",
      "Dutch,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.395e+05   1.77e+05     -0.789      0.430   -4.86e+05    2.07e+05\n",
      "Dutch,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -4.107e+04   1.77e+05     -0.232      0.816   -3.88e+05    3.05e+05\n",
      "DwellingwSeparateLivingArea                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1.483e+05   5.92e+04     -2.504      0.012   -2.64e+05   -3.22e+04\n",
      "DwellingwSeparateLivingArea,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.0006      0.003      0.189      0.850      -0.006       0.007\n",
      "DwellingwSeparateLivingArea,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -6.078e+04   1.25e+05     -0.486      0.627   -3.06e+05    1.84e+05\n",
      "DwellingwSeparateLivingArea,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -7.361e+04   8.85e+04     -0.831      0.406   -2.47e+05    9.99e+04\n",
      "DwellingwSeparateLivingArea,Rancher,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.502e+05   1.77e+05     -1.415      0.157   -5.97e+05    9.63e+04\n",
      "DwellingwSeparateLivingArea,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.789e+05   1.77e+05     -1.012      0.312   -5.25e+05    1.68e+05\n",
      "DwellingwSeparateLivingArea,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -3.816e+05   1.02e+05     -3.734      0.000   -5.82e+05   -1.81e+05\n",
      "DwellingwSeparateLivingArea,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -2.589e+05   1.25e+05     -2.069      0.039   -5.04e+05   -1.37e+04\n",
      "FarmhouseNationalFolk                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.41e+04   1.25e+04     -1.130      0.258   -3.85e+04    1.03e+04\n",
      "FarmhouseNationalFolk,French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.46e+05   1.77e+05      0.826      0.409      -2e+05    4.92e+05\n",
      "FarmhouseNationalFolk,LoftwithBedrooms,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0020      0.003      0.619      0.536      -0.004       0.008\n",
      "FarmhouseNationalFolk,Manor,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -0.0046      0.003     -1.437      0.151      -0.011       0.002\n",
      "FarmhouseNationalFolk,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -6.47e+04   1.25e+05     -0.517      0.605    -3.1e+05     1.8e+05\n",
      "FarmhouseNationalFolk,Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.97e+05   1.77e+05     -1.114      0.265   -5.43e+05    1.49e+05\n",
      "FarmhouseNationalFolk,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.33e+05   1.77e+05     -0.752      0.452   -4.79e+05    2.13e+05\n",
      "FarmhouseNationalFolk,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1.38e+05   5.93e+04      2.329      0.020    2.18e+04    2.54e+05\n",
      "FarmhouseNationalFolk,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1.229e+05   1.77e+05      0.695      0.487   -2.24e+05    4.69e+05\n",
      "FarmhouseNationalFolk,Traditional,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.0025      0.003      0.786      0.432      -0.004       0.009\n",
      "FarmhouseNationalFolk,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1.401e+05   1.25e+05      1.120      0.263   -1.05e+05    3.85e+05\n",
      "FarmhouseNationalFolk,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -1.166e+05   6.71e+04     -1.739      0.082   -2.48e+05    1.48e+04\n",
      "Federal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              7.415e+04   2.55e+04      2.908      0.004    2.42e+04    1.24e+05\n",
      "French                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               3.471e+05   2.07e+04     16.798      0.000    3.07e+05    3.88e+05\n",
      "French,Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         8.659e+05   1.77e+05      4.896      0.000    5.19e+05    1.21e+06\n",
      "French,Manor,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -0.0009      0.003     -0.277      0.781      -0.007       0.005\n",
      "French,Normandy,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1.586e+06   1.77e+05      8.967      0.000    1.24e+06    1.93e+06\n",
      "French,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0.0012      0.003      0.373      0.709      -0.005       0.008\n",
      "French,Rancher,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.933e+04   1.77e+05      0.109      0.913   -3.27e+05    3.66e+05\n",
      "French,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   4.232e+05   1.02e+05      4.140      0.000    2.23e+05    6.24e+05\n",
      "French,Traditional,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.649e+05   1.77e+05      0.933      0.351   -1.82e+05    5.11e+05\n",
      "French,Traditional,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1.472e+06   1.77e+05      8.325      0.000    1.13e+06    1.82e+06\n",
      "French,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  8.979e+04   1.25e+05      0.718      0.473   -1.55e+05    3.35e+05\n",
      "Georgian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              4.61e+05   3.15e+04     14.650      0.000    3.99e+05    5.23e+05\n",
      "Georgian,Loft                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -2.064e+05   1.77e+05     -1.167      0.243   -5.53e+05     1.4e+05\n",
      "Georgian,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1.493e+05   1.25e+05      1.193      0.233   -9.59e+04    3.94e+05\n",
      "Loft,LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -0.0030      0.003     -0.919      0.358      -0.009       0.003\n",
      "Loft,Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.058e+06   1.77e+05      5.983      0.000    7.11e+05     1.4e+06\n",
      "Loft,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.0030      0.003      0.933      0.351      -0.003       0.009\n",
      "Loft,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.347e+05   8.86e+04     -1.521      0.128   -3.08e+05    3.89e+04\n",
      "Loft,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.0085      0.003      2.738      0.006       0.002       0.015\n",
      "Loft,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1.294e+05   1.25e+05      1.034      0.301   -1.16e+05    3.74e+05\n",
      "Loft,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -2.256e+04   1.77e+05     -0.128      0.898   -3.69e+05    3.24e+05\n",
      "Loft,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.956e-10   1.32e-10     -1.478      0.139   -4.55e-10    6.37e-11\n",
      "LoftwithBedrooms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     7.458e+04   1.77e+05      0.422      0.673   -2.72e+05    4.21e+05\n",
      "LoftwithBedrooms,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.046e+05   1.77e+05     -1.158      0.247   -5.51e+05    1.42e+05\n",
      "LogHome                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -9.315e+04   3.46e+04     -2.694      0.007   -1.61e+05   -2.54e+04\n",
      "LogHome,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -2.43e+05   1.77e+05     -1.374      0.169    -5.9e+05    1.04e+05\n",
      "LogHome,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      5.227e-06   5.06e-06      1.033      0.301   -4.69e-06    1.51e-05\n",
      "Manor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                5.317e+05   3.74e+04     14.210      0.000    4.58e+05    6.05e+05\n",
      "Manor,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.376e+05   1.77e+05      0.778      0.436   -2.09e+05    4.84e+05\n",
      "Manor,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -2.072e+05   1.77e+05     -1.172      0.241   -5.54e+05    1.39e+05\n",
      "Manor,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -7.441e+04   1.25e+05     -0.595      0.552    -3.2e+05    1.71e+05\n",
      "Manor,Traditional,Trinity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -7.528e+04   8.87e+04     -0.849      0.396   -2.49e+05    9.85e+04\n",
      "Manor,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   6.718e+05   1.77e+05      3.800      0.000    3.25e+05    1.02e+06\n",
      "Manor,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -2.043e+05   1.77e+05     -1.155      0.248   -5.51e+05    1.42e+05\n",
      "Mediterranean                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -2.442e+04   6.71e+04     -0.364      0.716   -1.56e+05    1.07e+05\n",
      "Mediterranean,Spanish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -5.412e+04   1.77e+05     -0.306      0.759   -4.01e+05    2.92e+05\n",
      "Mediterranean,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -0.0016      0.003     -0.505      0.613      -0.008       0.005\n",
      "Mediterranean,Traditional,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.0028      0.003      0.869      0.385      -0.004       0.009\n",
      "Mediterranean,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.038e+04   1.77e+05      0.059      0.953   -3.36e+05    3.57e+05\n",
      "Mediterranean,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  6.217e+04   1.77e+05      0.352      0.725   -2.84e+05    4.09e+05\n",
      "MidCenturyModern                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2.464e+04   4.33e+04      0.569      0.569   -6.02e+04     1.1e+05\n",
      "MidCenturyModern,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -4.081e+04   1.25e+05     -0.326      0.744   -2.86e+05    2.04e+05\n",
      "MidCenturyModern,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.0046      0.003      1.569      0.117      -0.001       0.010\n",
      "MidCenturyModern,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2.729e+04   5.62e+04      0.485      0.627   -8.29e+04    1.37e+05\n",
      "MidCenturyModern,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3.06e+04   1.77e+05      0.173      0.863   -3.16e+05    3.77e+05\n",
      "MidCenturyModern,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -6.216e+04   1.25e+05     -0.497      0.619   -3.07e+05    1.83e+05\n",
      "MidCenturyModern,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -5.999e+04   1.25e+05     -0.480      0.631   -3.05e+05    1.85e+05\n",
      "MidCenturyModern,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1.291e+05   1.77e+05      0.730      0.465   -2.17e+05    4.76e+05\n",
      "Normandy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -1.102e+05   1.77e+05     -0.624      0.533   -4.57e+05    2.36e+05\n",
      "Normandy,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -9.389e+04   1.77e+05     -0.531      0.595    -4.4e+05    2.53e+05\n",
      "Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -9.927e+04   8535.879    -11.630      0.000   -1.16e+05   -8.25e+04\n",
      "Other,PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -3.024e+04   1.77e+05     -0.171      0.864   -3.77e+05    3.16e+05\n",
      "Other,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -2.282e+05   1.02e+05     -2.233      0.026   -4.28e+05   -2.79e+04\n",
      "Other,RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -2.097e+05   1.77e+05     -1.186      0.236   -5.56e+05    1.37e+05\n",
      "Other,RaisedRanch,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -1.534e+05   1.77e+05     -0.868      0.386      -5e+05    1.93e+05\n",
      "Other,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -7.704e+04   6.71e+04     -1.149      0.251   -2.08e+05    5.44e+04\n",
      "Other,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2.272e+04   1.25e+05      0.182      0.856   -2.22e+05    2.68e+05\n",
      "Other,Rancher,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -6.943e+04   1.77e+05     -0.393      0.695   -4.16e+05    2.77e+05\n",
      "Other,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.314e+05   2.83e+04     -4.646      0.000   -1.87e+05    -7.6e+04\n",
      "Other,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -2.531e+05   8.86e+04     -2.858      0.004   -4.27e+05   -7.95e+04\n",
      "Other,SplitFoyer,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.448e+04   1.77e+05     -0.082      0.935   -3.61e+05    3.32e+05\n",
      "Other,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -1.602e+05   7.24e+04     -2.214      0.027   -3.02e+05   -1.84e+04\n",
      "Other,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -7.73e+04   4.76e+04     -1.623      0.105   -1.71e+05     1.6e+04\n",
      "Other,Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -0.0018      0.003     -0.570      0.568      -0.008       0.004\n",
      "Other,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1.287e+05   1.25e+05      1.029      0.303   -1.16e+05    3.74e+05\n",
      "Other,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.0010      0.003      0.304      0.761      -0.005       0.007\n",
      "PostAndBeam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2.266e+05   4.33e+04      5.234      0.000    1.42e+05    3.11e+05\n",
      "PostAndBeam,Prairie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  9742.3746   1.77e+05      0.055      0.956   -3.37e+05    3.56e+05\n",
      "PostAndBeam,SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -5.684e+05   1.77e+05     -3.215      0.001   -9.15e+05   -2.22e+05\n",
      "Prairie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.132e+05   1.02e+05     -1.108      0.268   -3.14e+05     8.7e+04\n",
      "PreFabricated                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -1.426e+05   4.33e+04     -3.292      0.001   -2.28e+05   -5.77e+04\n",
      "PreFabricated,Other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -1.088e+05   1.77e+05     -0.616      0.538   -4.55e+05    2.38e+05\n",
      "PreFabricated,RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -2.675e+05   1.25e+05     -2.138      0.032   -5.13e+05   -2.23e+04\n",
      "PreFabricated,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.351e+05   7.24e+04     -1.866      0.062   -2.77e+05    6782.145\n",
      "RaisedRanch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1.039e+05   8868.576    -11.710      0.000   -1.21e+05   -8.65e+04\n",
      "RaisedRanch,Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -9.513e+04    1.4e+04     -6.789      0.000   -1.23e+05   -6.77e+04\n",
      "RaisedRanch,Rancher,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -4.242e+04   1.25e+05     -0.339      0.734   -2.88e+05    2.03e+05\n",
      "RaisedRanch,Rancher,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -1.483e+05   1.77e+05     -0.839      0.401   -4.95e+05    1.98e+05\n",
      "RaisedRanch,Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.41e+05   1.77e+05     -0.798      0.425   -4.88e+05    2.05e+05\n",
      "RaisedRanch,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.198e+05   5.62e+04     -2.131      0.033    -2.3e+05   -9593.151\n",
      "RaisedRanch,SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -1.414e+05   1.25e+05     -1.131      0.258   -3.87e+05    1.04e+05\n",
      "RaisedRanch,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -7.67e+04   1.25e+05     -0.613      0.540   -3.22e+05    1.68e+05\n",
      "RaisedRanch,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -9.447e+04   1.77e+05     -0.534      0.593   -4.41e+05    2.52e+05\n",
      "RaisedRanch,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.004e+05   8.85e+04     -1.134      0.257   -2.74e+05    7.31e+04\n",
      "Rancher                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -8.091e+04   6426.811    -12.589      0.000   -9.35e+04   -6.83e+04\n",
      "Rancher,Reverse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     -8.855e+04   1.25e+05     -0.708      0.479   -3.34e+05    1.57e+05\n",
      "Rancher,SidebySide                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -9.503e+04   1.77e+05     -0.538      0.591   -4.41e+05    2.51e+05\n",
      "Rancher,Spanish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0.0037      0.003      1.146      0.252      -0.003       0.010\n",
      "Rancher,SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -1.129e+05   1.77e+05     -0.639      0.523   -4.59e+05    2.34e+05\n",
      "Rancher,SplitFoyer,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      -1.937e+05   1.77e+05     -1.096      0.273    -5.4e+05    1.53e+05\n",
      "Rancher,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    -4.5e+04   1.02e+05     -0.440      0.660   -2.45e+05    1.55e+05\n",
      "Rancher,StraightThru                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -1.311e+05   1.77e+05     -0.742      0.458   -4.78e+05    2.15e+05\n",
      "Rancher,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 -5.813e+04   2.86e+04     -2.031      0.042   -1.14e+05   -2034.122\n",
      "Rancher,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                -4.953e+04   8.86e+04     -0.559      0.576   -2.23e+05    1.24e+05\n",
      "Rancher,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.0007      0.003      0.247      0.805      -0.005       0.007\n",
      "Rancher,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.0119      0.003      3.701      0.000       0.006       0.018\n",
      "SaltBox                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -3.225e+04   4.94e+04     -0.653      0.514   -1.29e+05    6.45e+04\n",
      "SidebySide                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -2.42e+05   1.77e+05     -1.369      0.171   -5.88e+05    1.04e+05\n",
      "SidebySide,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -7.246e+04   1.77e+05     -0.410      0.682   -4.19e+05    2.74e+05\n",
      "Spanish                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.492e+05   5.62e+04      2.655      0.008     3.9e+04    2.59e+05\n",
      "SplitFoyer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -1.272e+05   6861.440    -18.543      0.000   -1.41e+05   -1.14e+05\n",
      "SplitFoyer,SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -1.321e+05   2.22e+04     -5.962      0.000   -1.76e+05   -8.87e+04\n",
      "SplitFoyer,SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -8.662e+04   1.25e+05     -0.693      0.489   -3.32e+05    1.59e+05\n",
      "SplitFoyer,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -1.828e+05   4.94e+04     -3.702      0.000    -2.8e+05    -8.6e+04\n",
      "SplitFoyer,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.0054      0.003      1.721      0.085      -0.001       0.012\n",
      "SplitLevel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -9.397e+04   6894.448    -13.630      0.000   -1.07e+05   -8.05e+04\n",
      "SplitLevel,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              -4.927e+04   3.28e+04     -1.500      0.134   -1.14e+05    1.51e+04\n",
      "SplitLevel,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.507e+05   1.02e+05     -1.475      0.140   -3.51e+05    4.95e+04\n",
      "StraightThru                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -3.063e+05   1.77e+05     -1.733      0.083   -6.53e+05    4.02e+04\n",
      "StraightThru,Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             -1.17e+05   1.77e+05     -0.662      0.508   -4.63e+05    2.29e+05\n",
      "Traditional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -1.814e+04   7079.250     -2.563      0.010    -3.2e+04   -4267.578\n",
      "Traditional,CondoUnit                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -5.749e+04   1.77e+05     -0.325      0.745   -4.04e+05    2.89e+05\n",
      "Traditional,Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             3.494e+04    3.9e+04      0.895      0.371   -4.16e+04    1.11e+05\n",
      "Traditional,Trinity,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -8.792e+04   4.77e+04     -1.844      0.065   -1.81e+05    5537.523\n",
      "Traditional,Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               -5.754e+04   6.28e+04     -0.917      0.359   -1.81e+05    6.55e+04\n",
      "Traditional,Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -1.177e+04   1.25e+05     -0.094      0.925   -2.57e+05    2.33e+05\n",
      "Transitional                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         8.358e+04   1.14e+04      7.308      0.000    6.12e+04    1.06e+05\n",
      "Transitional,Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1806.1676   1.77e+05      0.010      0.992   -3.45e+05    3.48e+05\n",
      "Tudor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1.246e+05   1.95e+04      6.379      0.000    8.63e+04    1.63e+05\n",
      "Victorian                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           -3.522e+04   1.51e+04     -2.335      0.020   -6.48e+04   -5653.816\n",
      "Villa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                3.111e+05   4.33e+04      7.185      0.000    2.26e+05    3.96e+05\n",
      "NoBasement                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          -8.544e+06   1.78e+05    -47.868      0.000   -8.89e+06   -8.19e+06\n",
      "HasBasement                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -8.534e+06   1.78e+05    -47.818      0.000   -8.88e+06   -8.18e+06\n",
      "NoFireplace                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         -4818.5967   2175.030     -2.215      0.027   -9081.662    -555.531\n",
      "HasFireplace                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         5.159e+04   1902.762     27.112      0.000    4.79e+04    5.53e+04\n",
      "NoCentralAir                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -8.551e+06   1.78e+05    -47.927      0.000    -8.9e+06    -8.2e+06\n",
      "HasCentralAir                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       -8.528e+06   1.79e+05    -47.759      0.000   -8.88e+06   -8.18e+06\n",
      "NotWaterfront                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -8.74e+06   1.78e+05    -48.969      0.000   -9.09e+06   -8.39e+06\n",
      "IsWaterfront                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        -8.338e+06   1.78e+05    -46.712      0.000   -8.69e+06   -7.99e+06\n",
      "NotNewConstruction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  -8.564e+06   1.79e+05    -47.950      0.000   -8.91e+06   -8.21e+06\n",
      "IsNewConstruction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   -8.514e+06   1.78e+05    -47.733      0.000   -8.86e+06   -8.16e+06\n",
      "==============================================================================\n",
      "Omnibus:                    78547.399   Durbin-Watson:                   2.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         71352525.230\n",
      "Skew:                           6.562   Prob(JB):                         0.00\n",
      "Kurtosis:                     170.036   Cond. No.                     7.69e+23\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.62e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#set the training and testing data\n",
    "X = X_train.drop('SoldPrice', axis = 1)\n",
    "y = X_train.SoldPrice\n",
    "X = sm.add_constant(X) #add the constant to the model\n",
    "mod = sm.OLS(y, X, hasconst= True) #create the ordinary least squares model\n",
    "res = mod.fit() #fit the model\n",
    "print(res.summary()) #summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.scatter(X, y, color = 'red')\n",
    "plot.plot(xTrain, mod.predict(X), color = 'blue')\n",
    "plot.title('Salary vs Experience (Training set)')\n",
    "plot.xlabel('Years of Experience')\n",
    "plot.ylabel('Salary')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the residuals\n",
    "residuals = res.resid\n",
    "\n",
    "y_pred = res.predict(X)\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "\n",
    "plt.xlabel('predicted values')\n",
    "plt.ylabel('residuals')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61000, 24)\n",
      "(15251, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(dfpdForLinearRegressionNoStyle, test_size = 0.2, random_state = 2) # splits the data into two parts with 1:4 ratio\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SoldPrice   R-squared:                       0.609\n",
      "Model:                            OLS   Adj. R-squared:                  0.608\n",
      "Method:                 Least Squares   F-statistic:                     5267.\n",
      "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:39:08   Log-Likelihood:            -8.2575e+05\n",
      "No. Observations:               61000   AIC:                         1.652e+06\n",
      "Df Residuals:                   60981   BIC:                         1.652e+06\n",
      "Df Model:                          18                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const              -1.794e+07   3.64e+05    -49.247      0.000   -1.87e+07   -1.72e+07\n",
      "SettledDate           75.8189      1.599     47.422      0.000      72.685      78.953\n",
      "ZipCode              125.7848      5.178     24.291      0.000     115.635     135.934\n",
      "AcresTotal           1.86e+04    268.122     69.383      0.000    1.81e+04    1.91e+04\n",
      "Age                  -31.0015      6.258     -4.954      0.000     -43.268     -18.735\n",
      "InteriorSqFt           1.6140      0.123     13.074      0.000       1.372       1.856\n",
      "Bedrooms            1.667e+04   1079.566     15.442      0.000    1.46e+04    1.88e+04\n",
      "BathsFull           1.341e+05   1075.812    124.660      0.000    1.32e+05    1.36e+05\n",
      "BathsHalf           1.043e+05   1363.465     76.513      0.000    1.02e+05    1.07e+05\n",
      "GarageSpaces        2794.2810    217.696     12.836      0.000    2367.596    3220.967\n",
      "ANNEARUNDELMD      -4.436e+06   9.11e+04    -48.696      0.000   -4.61e+06   -4.26e+06\n",
      "BALTIMOREMD         -4.54e+06   9.11e+04    -49.812      0.000   -4.72e+06   -4.36e+06\n",
      "HARFORDMD          -4.554e+06   9.11e+04    -50.008      0.000   -4.73e+06   -4.38e+06\n",
      "HOWARDMD           -4.409e+06    9.1e+04    -48.445      0.000   -4.59e+06   -4.23e+06\n",
      "NoBasement          -8.97e+06   1.82e+05    -49.246      0.000   -9.33e+06   -8.61e+06\n",
      "HasBasement        -8.968e+06   1.82e+05    -49.246      0.000   -9.33e+06   -8.61e+06\n",
      "NoFireplace        -5118.1014   2233.388     -2.292      0.022   -9495.548    -740.655\n",
      "HasFireplace        5.459e+04   1948.785     28.013      0.000    5.08e+04    5.84e+04\n",
      "NoCentralAir       -8.979e+06   1.82e+05    -49.318      0.000   -9.34e+06   -8.62e+06\n",
      "HasCentralAir      -8.959e+06   1.82e+05    -49.173      0.000   -9.32e+06    -8.6e+06\n",
      "NotWaterfront      -9.186e+06   1.82e+05    -50.443      0.000   -9.54e+06   -8.83e+06\n",
      "IsWaterfront       -8.752e+06   1.82e+05    -48.044      0.000   -9.11e+06   -8.39e+06\n",
      "NotNewConstruction -9.016e+06   1.82e+05    -49.481      0.000   -9.37e+06   -8.66e+06\n",
      "IsNewConstruction  -8.923e+06   1.82e+05    -49.009      0.000   -9.28e+06   -8.57e+06\n",
      "==============================================================================\n",
      "Omnibus:                    77568.856   Durbin-Watson:                   2.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         58024146.407\n",
      "Skew:                           6.470   Prob(JB):                         0.00\n",
      "Kurtosis:                     153.538   Cond. No.                     3.62e+22\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.53e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#set the training and testing data\n",
    "X = X_train.drop('SoldPrice', axis = 1)\n",
    "y = X_train.SoldPrice\n",
    "X = sm.add_constant(X) #add the constant to the model\n",
    "mod = sm.OLS(y, X, hasconst= True) #create the ordinary least squares model\n",
    "res = mod.fit() #fit the model\n",
    "print(res.summary()) #summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the residuals\n",
    "residuals = res.resid\n",
    "\n",
    "y_pred = res.predict(X)\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "\n",
    "plt.xlabel('predicted values')\n",
    "plt.ylabel('residuals')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try with normalized scaling\n",
    "\n",
    "x = dfpdForLinearRegressionNoStyle.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "dfpdForLinearRegressionNoStyleScaled = pd.DataFrame(x_scaled, columns=dfpdForLinearRegressionNoStyle.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61000, 24)\n",
      "(15251, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(dfpdForLinearRegressionNoStyleScaled, test_size = 0.2, random_state = 2) # splits the data into two parts with 1:4 ratio\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SoldPrice   R-squared:                       0.609\n",
      "Model:                            OLS   Adj. R-squared:                  0.608\n",
      "Method:                 Least Squares   F-statistic:                     5267.\n",
      "Date:                Sun, 08 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:39:12   Log-Likelihood:             1.6326e+05\n",
      "No. Observations:               61000   AIC:                        -3.265e+05\n",
      "Df Residuals:                   60981   BIC:                        -3.263e+05\n",
      "Df Model:                          18                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.0038      0.000     10.384      0.000       0.003       0.005\n",
      "SettledDate            0.0126      0.000     47.422      0.000       0.012       0.013\n",
      "ZipCode                0.0124      0.001     24.291      0.000       0.011       0.013\n",
      "AcresTotal             0.4173      0.006     69.383      0.000       0.406       0.429\n",
      "Age                   -0.0060      0.001     -4.954      0.000      -0.008      -0.004\n",
      "InteriorSqFt           0.1630      0.012     13.074      0.000       0.139       0.187\n",
      "Bedrooms               0.0485      0.003     15.442      0.000       0.042       0.055\n",
      "BathsFull              0.1341      0.001    124.660      0.000       0.132       0.136\n",
      "BathsHalf              0.0854      0.001     76.513      0.000       0.083       0.088\n",
      "GarageSpaces           0.2058      0.016     12.836      0.000       0.174       0.237\n",
      "ANNEARUNDELMD          0.0054      0.000     37.946      0.000       0.005       0.006\n",
      "BALTIMOREMD           -0.0041      0.000    -27.331      0.000      -0.004      -0.004\n",
      "HARFORDMD             -0.0053      0.000    -30.158      0.000      -0.006      -0.005\n",
      "HOWARDMD               0.0078      0.000     43.072      0.000       0.007       0.008\n",
      "NoBasement             0.0018      0.000      8.825      0.000       0.001       0.002\n",
      "HasBasement            0.0020      0.000      9.300      0.000       0.002       0.002\n",
      "NoFireplace           -0.0005      0.000     -2.292      0.022      -0.001   -6.73e-05\n",
      "HasFireplace           0.0050      0.000     28.013      0.000       0.005       0.005\n",
      "NoCentralAir           0.0010      0.000      4.781      0.000       0.001       0.001\n",
      "HasCentralAir          0.0028      0.000     12.823      0.000       0.002       0.003\n",
      "NotWaterfront         -0.0178      0.000    -72.497      0.000      -0.018      -0.017\n",
      "IsWaterfront           0.0217      0.000     75.711      0.000       0.021       0.022\n",
      "NotNewConstruction    -0.0023      0.000    -10.174      0.000      -0.003      -0.002\n",
      "IsNewConstruction      0.0061      0.000     24.981      0.000       0.006       0.007\n",
      "==============================================================================\n",
      "Omnibus:                    77568.856   Durbin-Watson:                   2.011\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         58024146.407\n",
      "Skew:                           6.470   Prob(JB):                         0.00\n",
      "Kurtosis:                     153.538   Cond. No.                     1.04e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.64e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#set the training and testing data\n",
    "X = X_train.drop('SoldPrice', axis = 1)\n",
    "y = X_train.SoldPrice\n",
    "X = sm.add_constant(X) #add the constant to the model\n",
    "mod = sm.OLS(y, X, hasconst= True) #create the ordinary least squares model\n",
    "res = mod.fit() #fit the model\n",
    "print(res.summary()) #summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the residuals\n",
    "residuals = res.resid\n",
    "\n",
    "y_pred = res.predict(X)\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "\n",
    "plt.xlabel('predicted values')\n",
    "plt.ylabel('residuals')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Images/linearRegressionResiduals.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def model_experiment(num_iter = 5, \n",
    "                     models = ['ols', 'ridge', 'lasso'], alpha= 10, \n",
    "                     complexity = 'simple', degree = 3):\n",
    "    \n",
    "    X_train, X_test = train_test_split(dfpdForLinearRegressionNoStyle, test_size = 0.2) # splits the data into two parts with 1:4 ratio\n",
    "    X = X_train.drop('SoldPrice', axis = 1)\n",
    "    y = X_train.SoldPrice\n",
    "    \n",
    "    x_axis = np.arange(num_iter)\n",
    "    y_ols_test = []\n",
    "    y_lasso_test = []\n",
    "    y_ridge_test = []\n",
    "    sample_models = {}\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        if complexity == 'simple':\n",
    "            ## split train_test \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "        elif complexity == 'polynomial':\n",
    "            ## Create higher order terms\n",
    "            poly = PolynomialFeatures(degree=degree)\n",
    "            Xp = poly.fit_transform(X)\n",
    "            ## test-train split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(Xp, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "        ## Standard scale mean = 0, variance = 1\n",
    "        #sd = StandardScaler()\n",
    "\n",
    "        #sd.fit(X_train)\n",
    "\n",
    "        #X_train = sd.transform(X_train)\n",
    "\n",
    "        #X_test = sd.transform(X_test)\n",
    "\n",
    "        ## Be careful about the leakage\n",
    "\n",
    "        ## Vanilla model\n",
    "        if 'ols' in models:\n",
    "            lr = LinearRegression()\n",
    "\n",
    "            lr.fit(X_train, y_train)\n",
    "            \n",
    "            sample_models['ols'] = lr\n",
    "\n",
    "            test_score = lr.score(X_test, y_test)\n",
    "            train_score = lr.score(X_train, y_train)\n",
    "\n",
    "            y_ols_test.append(test_score)\n",
    "\n",
    "    #       print('test score OLS is %.2f and train score is %.2f'%(test_score, train_score))\n",
    "\n",
    "        if 'ridge' in models:\n",
    "            ## Ridge in the simple setting\n",
    "            ridge = Ridge(alpha = alpha, max_iter= 10000)\n",
    "            ridge.fit(X_train, y_train)\n",
    "            sample_models['ridge'] = ridge\n",
    "            y_ridge_test.append(ridge.score(X_test, y_test))\n",
    "    #         print('test score Ridge is %.2f and train score is %.2f'%(ridge.score(X_test, y_test),\n",
    "    #                                                             ridge.score(X_train, y_train)))\n",
    "\n",
    "        if 'lasso' in models:\n",
    "            ## Lasso in the simple setting\n",
    "            lasso = Lasso(alpha = alpha, max_iter= 10000)\n",
    "\n",
    "            lasso.fit(X_train, y_train)\n",
    "            \n",
    "            sample_models['lasso'] = lasso\n",
    "            \n",
    "            y_lasso_test.append(lasso.score(X_test, y_test))\n",
    "    #       print('test score Lasso is %.2f and train score is %.2f'%(lasso.score(X_test, y_test),\n",
    "    #                                                             lasso.score(X_train, y_train)))\n",
    "\n",
    "        i+=1\n",
    "    if 'ols' in models:\n",
    "        plt.plot(y_ols_test, label = 'ols')\n",
    "    if 'ridge' in models:\n",
    "        plt.plot(y_ridge_test, label = 'ridge')\n",
    "    if 'lasso' in models:\n",
    "        plt.plot(y_lasso_test, label = 'lasso')\n",
    "    plt.ylabel('R2 test score')\n",
    "    plt.xlabel('number of iterations')\n",
    "    all_results = y_ols_test + y_lasso_test + y_ridge_test\n",
    "    plt.ylim((np.min(all_results), np.max(all_results)))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(\"../Images/regressionComparison.png\",bbox_inches='tight')\n",
    "    return sample_models\n",
    "\n",
    "trained_models = model_experiment(num_iter=30, alpha = 30,\n",
    "                                   models = ['ols', 'ridge', 'lasso'], \n",
    "                                   complexity= 'simple', degree = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.17042050e+02  3.42541124e+02  7.79071880e+03  1.52565880e+03\n",
      "  1.12697981e+02  1.40995156e+04 -4.94942784e+03  1.72459442e+04\n",
      "  1.89813302e+04  9.11774578e+04 -2.68539748e+04  3.05480506e+04\n",
      " -9.48715337e+04  2.70774046e+04 -2.70774046e+04 -3.04016543e+03\n",
      "  8.09308074e+04 -1.52155433e+04  1.52155433e+04 -1.32294800e+05\n",
      "  1.32294800e+05  5.59403422e+04 -5.59403422e+04]\n",
      "[   147.5414861     258.15489536   -618.64114888   1869.40759739\n",
      "    131.27214669   2417.28860464   4184.63451231   1477.95802794\n",
      "  10120.28334417  21704.218456   -14089.76670014   1924.55139718\n",
      "  -9539.00315304   7043.14004918  -7043.14004918  -7939.87140681\n",
      "  15512.8089782   -3511.79943848   3511.79943848 -10695.39639528\n",
      "  10695.39639528    520.27139011   -520.27139011]\n",
      "[ 1.17311909e+02  3.41781949e+02  7.73970786e+03  1.52383114e+03\n",
      "  1.12709958e+02  1.37736534e+04 -4.58904116e+03  1.71636340e+04\n",
      "  1.88985495e+04  1.08017491e+05 -9.49096710e+03  4.73722513e+04\n",
      " -7.69311353e+04  5.33272127e+04 -1.13657049e-09 -2.51361344e+03\n",
      "  8.11149196e+04 -2.98074796e+04  7.96002201e-12 -2.64024304e+05\n",
      "  1.57021358e-09  1.09118669e+05 -4.24018041e-10]\n"
     ]
    }
   ],
   "source": [
    "# After run model_experiment with complexity == 'polynomial'\n",
    "\n",
    "lr_ols = trained_models['ols']\n",
    "lr_lasso = trained_models['lasso']\n",
    "lr_ridge =trained_models['ridge']\n",
    "\n",
    "# check the coefficients from Lasso\n",
    "\n",
    "print(lr_ols.coef_)\n",
    "print(lr_ridge.coef_)\n",
    "print(lr_lasso.coef_)\n",
    "\n",
    "# compare them with OLS/Ridge models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48800, 2600)\n",
      "(12200, 2600)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(dfpdForLinearRegressionNoStyle, test_size = 0.2) # splits the data into two parts with 1:4 ratio\n",
    "X = X_train.drop('SoldPrice', axis = 1)\n",
    "y = X_train.SoldPrice\n",
    "\n",
    "## Create higher order terms\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "Xp = poly.fit_transform(X)\n",
    "## test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xp, y, test_size = 0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.4255201302479357"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the training and testing data\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried here above with polynomial regression but got pretty bad results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 24)\n",
      "(153, 24)\n"
     ]
    }
   ],
   "source": [
    "sample = dfpdForLinearRegressionNoStyle.sample(frac=0.01, replace=False, random_state=1)\n",
    "\n",
    "X_train, X_test = train_test_split(sample, test_size = 0.2, random_state = 2) # splits the data into two parts with 1:4 ratio\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SoldPrice</th>\n",
       "      <th>SettledDate</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>AcresTotal</th>\n",
       "      <th>Age</th>\n",
       "      <th>InteriorSqFt</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>BathsFull</th>\n",
       "      <th>BathsHalf</th>\n",
       "      <th>GarageSpaces</th>\n",
       "      <th>ANNEARUNDELMD</th>\n",
       "      <th>BALTIMOREMD</th>\n",
       "      <th>HARFORDMD</th>\n",
       "      <th>HOWARDMD</th>\n",
       "      <th>NoBasement</th>\n",
       "      <th>HasBasement</th>\n",
       "      <th>NoFireplace</th>\n",
       "      <th>HasFireplace</th>\n",
       "      <th>NoCentralAir</th>\n",
       "      <th>HasCentralAir</th>\n",
       "      <th>NotWaterfront</th>\n",
       "      <th>IsWaterfront</th>\n",
       "      <th>NotNewConstruction</th>\n",
       "      <th>IsNewConstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52370</th>\n",
       "      <td>600000</td>\n",
       "      <td>738124</td>\n",
       "      <td>21144</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3806.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33492</th>\n",
       "      <td>390000</td>\n",
       "      <td>736626</td>\n",
       "      <td>21037</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84262</th>\n",
       "      <td>790000</td>\n",
       "      <td>737928</td>\n",
       "      <td>21784</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>4428.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19465</th>\n",
       "      <td>357000</td>\n",
       "      <td>737515</td>\n",
       "      <td>21236</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30178</th>\n",
       "      <td>230000</td>\n",
       "      <td>736874</td>\n",
       "      <td>21060</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SoldPrice  SettledDate  ZipCode  AcresTotal     Age  InteriorSqFt  \\\n",
       "52370     600000       738124    21144        1.61  1995.0        3806.0   \n",
       "33492     390000       736626    21037        1.00  1960.0        2438.0   \n",
       "84262     790000       737928    21784        6.00  1996.0        4428.0   \n",
       "19465     357000       737515    21236        0.15  1992.0        1984.0   \n",
       "30178     230000       736874    21060        0.21  1953.0        1810.0   \n",
       "\n",
       "       Bedrooms  BathsFull  BathsHalf  GarageSpaces  ANNEARUNDELMD  \\\n",
       "52370       5.0        2.0        1.0           2.0              1   \n",
       "33492       3.0        2.0        0.0           4.0              1   \n",
       "84262       4.0        2.0        1.0           4.0              0   \n",
       "19465       4.0        3.0        1.0           1.0              0   \n",
       "30178       3.0        2.0        0.0           1.0              1   \n",
       "\n",
       "       BALTIMOREMD  HARFORDMD  HOWARDMD  NoBasement  HasBasement  NoFireplace  \\\n",
       "52370            0          0         0           0            1            1   \n",
       "33492            0          0         0           0            1            1   \n",
       "84262            0          0         1           0            1            0   \n",
       "19465            1          0         0           0            1            0   \n",
       "30178            0          0         0           1            0            1   \n",
       "\n",
       "       HasFireplace  NoCentralAir  HasCentralAir  NotWaterfront  IsWaterfront  \\\n",
       "52370             0             0              1              1             0   \n",
       "33492             0             0              1              1             0   \n",
       "84262             1             0              1              1             0   \n",
       "19465             1             0              1              1             0   \n",
       "30178             0             0              1              1             0   \n",
       "\n",
       "       NotNewConstruction  IsNewConstruction  \n",
       "52370                   1                  0  \n",
       "33492                   1                  0  \n",
       "84262                   1                  0  \n",
       "19465                   1                  0  \n",
       "30178                   1                  0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=100, gamma=0.001)\n",
      "0.7551795135373355\n",
      "[438493.42722267]\n",
      "[438493.42722267]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Now try SVR\n",
    "X = X_train.drop('SoldPrice', axis = 1)\n",
    "y = X_train.SoldPrice\n",
    "y = np.asarray(y)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)\n",
    "\n",
    "regressor = SVR(kernel = 'rbf', C = 100, gamma = .001).fit(X, y)\n",
    "print(regressor)\n",
    "\n",
    "score = regressor.score(X, y)\n",
    "print(score)\n",
    "\n",
    "#print(X[1])\n",
    "\n",
    "data = [[738124, 21144, 1.61, 1995.0, 3806.0, 5.0, 2.0, 1.0, 2.0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0]]\n",
    "sc_Xpred = StandardScaler()\n",
    "Xpred = sc_Xpred.fit_transform(data)\n",
    "data2 = [[737928, 21784, 6.00, 1996.0, 4428.0, 4.0, 2.0, 1.0, 4.0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0]]\n",
    "sc_Xpred2 = StandardScaler()\n",
    "Xpred2 = sc_Xpred2.fit_transform(data2)\n",
    "#data = sc_X.fit_transform(data)\n",
    "\n",
    "\n",
    "y_pred = regressor.predict(Xpred)\n",
    "y_pred = sc_y.inverse_transform(y_pred)\n",
    "print(y_pred)\n",
    "\n",
    "y_pred2 = regressor.predict(Xpred2)\n",
    "y_pred2 = sc_y.inverse_transform(y_pred2)\n",
    "print(y_pred2)\n",
    "\n",
    "#Xshaped = np.array(X).reshape(-1,1)\n",
    "#print(len(X))\n",
    "#print(len(y))\n",
    "\n",
    "#plt.scatter(X, y, s=5, color=\"blue\", label=\"original\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "#X_grid = np.arange(np.min(X), np.max(X), 0.01) #this step required because data is feature scaled.\n",
    "#X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "#plt.scatter(X, y, color = 'red')\n",
    "#plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
    "#plt.title('Truth or Bluff (SVR)')\n",
    "#plt.xlabel('Position level')\n",
    "#plt.ylabel('Salary')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-08, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-08, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-08, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-08, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-08, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-08, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-08, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-08, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-08, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-08, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-08, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-07, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-07, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-07, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-07, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-07, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-07, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-07, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-07, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-07, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-07, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-07, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-06, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-06, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-06, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-06, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-06, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-06, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-06, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-06, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-06, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-06, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-06, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-05, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-05, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-05, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-05, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=1e-05, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-05, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-05, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-05, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=1e-05, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=1e-05, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=1e-05, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] .................... C=1, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1, gamma=0.0001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] ................. C=1, gamma=0.0001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] ................. C=1, gamma=0.0001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1, gamma=0.0001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] ................. C=1, gamma=0.0001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ................... C=1, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ................... C=1, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ................... C=1, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ................... C=1, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ................... C=1, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] .................... C=1, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ..................... C=1, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   0.1s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ...................... C=1, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.4s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.1s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-08, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-08, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-08, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=1e-07, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-07, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-07, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=1e-06, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-06, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-06, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=1e-05, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=1e-05, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=1e-05, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.0001, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] .................. C=10, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.8s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ................... C=10, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.1s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   0.7s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=   1.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] .................... C=10, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.6s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.5s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ..................... C=10, gamma=0.1, kernel=poly, total=   0.1s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-08, kernel=linear, total=   5.4s\n",
      "[CV] C=100, gamma=1e-08, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-08, kernel=linear, total=   5.4s\n",
      "[CV] C=100, gamma=1e-08, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-08, kernel=linear, total=   5.4s\n",
      "[CV] C=100, gamma=1e-08, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-08, kernel=linear, total=   4.4s\n",
      "[CV] C=100, gamma=1e-08, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-08, kernel=linear, total=   5.3s\n",
      "[CV] C=100, gamma=1e-08, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-08, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-07, kernel=linear, total=   5.4s\n",
      "[CV] C=100, gamma=1e-07, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-07, kernel=linear, total=   4.3s\n",
      "[CV] C=100, gamma=1e-07, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-07, kernel=linear, total=   4.5s\n",
      "[CV] C=100, gamma=1e-07, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-07, kernel=linear, total=   4.1s\n",
      "[CV] C=100, gamma=1e-07, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-07, kernel=linear, total=   4.7s\n",
      "[CV] C=100, gamma=1e-07, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-07, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-06, kernel=linear, total=   4.5s\n",
      "[CV] C=100, gamma=1e-06, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-06, kernel=linear, total=   4.2s\n",
      "[CV] C=100, gamma=1e-06, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-06, kernel=linear, total=   5.1s\n",
      "[CV] C=100, gamma=1e-06, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-06, kernel=linear, total=   4.4s\n",
      "[CV] C=100, gamma=1e-06, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-06, kernel=linear, total=   6.1s\n",
      "[CV] C=100, gamma=1e-06, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-06, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-05, kernel=linear, total=   5.2s\n",
      "[CV] C=100, gamma=1e-05, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-05, kernel=linear, total=   4.5s\n",
      "[CV] C=100, gamma=1e-05, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-05, kernel=linear, total=   4.5s\n",
      "[CV] C=100, gamma=1e-05, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-05, kernel=linear, total=   4.1s\n",
      "[CV] C=100, gamma=1e-05, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=1e-05, kernel=linear, total=   4.8s\n",
      "[CV] C=100, gamma=1e-05, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=1e-05, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=100, gamma=0.0001, kernel=linear, total=   4.5s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=100, gamma=0.0001, kernel=linear, total=   4.2s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=100, gamma=0.0001, kernel=linear, total=   4.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=100, gamma=0.0001, kernel=linear, total=   4.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=100, gamma=0.0001, kernel=linear, total=   4.7s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] ................. C=100, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] ................. C=100, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] ................. C=100, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] ................. C=100, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] ................. C=100, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=   4.3s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=   4.2s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=   4.3s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=   4.1s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=   4.7s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] .................. C=100, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.1s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total=   4.3s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total=   4.2s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total=   5.4s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total=   4.5s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total=   4.8s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=100, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=100, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=100, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=100, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ................... C=100, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=   4.4s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=   4.6s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=   4.4s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=   4.2s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=   5.4s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.1, kernel=poly, total=   0.6s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.1, kernel=poly, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.1, kernel=poly, total=   0.3s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.1, kernel=poly, total=   0.4s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=100, gamma=0.1, kernel=poly, total=   0.3s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-08, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-08, kernel=linear, total=  51.6s\n",
      "[CV] C=1000, gamma=1e-08, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-08, kernel=linear, total=  43.9s\n",
      "[CV] C=1000, gamma=1e-08, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-08, kernel=linear, total=  50.3s\n",
      "[CV] C=1000, gamma=1e-08, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-08, kernel=linear, total=  50.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-08, kernel=linear, total=  53.8s\n",
      "[CV] C=1000, gamma=1e-08, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-08, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-08, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-07, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-07, kernel=linear, total=  48.3s\n",
      "[CV] C=1000, gamma=1e-07, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-07, kernel=linear, total=  45.5s\n",
      "[CV] C=1000, gamma=1e-07, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-07, kernel=linear, total=  46.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-07, kernel=linear, total=  45.6s\n",
      "[CV] C=1000, gamma=1e-07, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-07, kernel=linear, total= 1.6min\n",
      "[CV] C=1000, gamma=1e-07, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-07, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-07, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=1e-06, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=linear ..............................\n",
      "[CV] ............... C=1000, gamma=1e-06, kernel=linear, total=  54.5s\n",
      "[CV] C=1000, gamma=1e-06, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-06, kernel=linear, total=  49.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-06, kernel=linear, total=  52.9s\n",
      "[CV] C=1000, gamma=1e-06, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-06, kernel=linear, total=  59.4s\n",
      "[CV] C=1000, gamma=1e-06, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-06, kernel=linear, total= 1.2min\n",
      "[CV] C=1000, gamma=1e-06, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-06, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-06, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=1e-05, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-05, kernel=linear, total=  57.4s\n",
      "[CV] C=1000, gamma=1e-05, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-05, kernel=linear, total= 1.0min\n",
      "[CV] C=1000, gamma=1e-05, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-05, kernel=linear, total= 1.0min\n",
      "[CV] C=1000, gamma=1e-05, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-05, kernel=linear, total= 1.0min\n",
      "[CV] C=1000, gamma=1e-05, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=1e-05, kernel=linear, total= 1.0min\n",
      "[CV] C=1000, gamma=1e-05, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=1e-05, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=1e-05, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=1000, gamma=0.0001, kernel=linear, total=  56.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=1000, gamma=0.0001, kernel=linear, total=  50.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=1000, gamma=0.0001, kernel=linear, total=  57.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=1000, gamma=0.0001, kernel=linear, total=  48.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. C=1000, gamma=0.0001, kernel=linear, total=  56.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV] ................ C=1000, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV] ................ C=1000, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV] ................ C=1000, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV] ................ C=1000, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=poly ...............................\n",
      "[CV] ................ C=1000, gamma=0.0001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total= 1.1min\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total=  57.9s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total=  55.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total=  50.2s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total=  59.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=poly ................................\n",
      "[CV] ................. C=1000, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total=  53.5s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total=  53.2s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total=  46.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total=  48.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total= 1.2min\n",
      "[CV] C=1000, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=1000, gamma=0.01, kernel=poly, total=   0.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=1000, gamma=0.01, kernel=poly, total=   0.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=1000, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=poly .................................\n",
      "[CV] .................. C=1000, gamma=0.01, kernel=poly, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total=  50.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total=  45.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total=  46.4s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total=  46.2s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total= 1.4min\n",
      "[CV] C=1000, gamma=0.1, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.1, kernel=poly, total=   0.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.1, kernel=poly, total=   0.4s\n",
      "[CV] C=1000, gamma=0.1, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.1, kernel=poly, total=   0.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.1, kernel=poly, total=   0.6s\n",
      "[CV] C=1000, gamma=0.1, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1000, gamma=0.1, kernel=poly, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed: 41.5min finished\n",
      "/Users/ZachV/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.45412445e-02, 7.44106770e-02, 9.09395218e-03, 1.78220272e-02,\n",
       "        8.80497456e-02, 9.11297798e-03, 1.38500214e-02, 7.01249599e-02,\n",
       "        8.86354446e-03, 1.32773399e-02, 8.34431171e-02, 1.01967335e-02,\n",
       "        1.07738495e-02, 7.10156441e-02, 8.47253799e-03, 1.19951725e-02,\n",
       "        6.94604397e-02, 9.17768478e-03, 1.18427277e-02, 9.35680866e-02,\n",
       "        1.14686012e-02, 1.53872013e-02, 8.12947273e-02, 4.28481102e-02,\n",
       "        1.33220196e-02, 6.96395445e-01, 8.49075317e-03, 1.22523308e-02,\n",
       "        5.17427254e-01, 1.05841160e-02, 1.52688026e-02, 6.00311327e-01,\n",
       "        1.08458519e-02, 1.41218662e-02, 6.22599983e-01, 1.12264156e-02,\n",
       "        1.28288269e-02, 5.83701515e-01, 8.88280869e-03, 1.42592430e-02,\n",
       "        5.46842003e-01, 8.45894814e-03, 2.15945721e-02, 5.37461472e-01,\n",
       "        1.62938118e-02, 5.41129589e-02, 6.66680527e-01, 1.43621063e-01,\n",
       "        1.34257793e-02, 5.33923578e-01, 1.68962955e-02, 2.22559929e-02,\n",
       "        6.33266640e-01, 1.28046036e-02, 1.62487030e-02, 6.38851643e-01,\n",
       "        8.39977264e-03, 1.13551617e-02, 5.74691820e-01, 1.09858990e-02,\n",
       "        9.63945389e-03, 6.70460033e-01, 1.42863274e-02, 2.61116028e-02,\n",
       "        8.27333832e-01, 8.83474350e-03, 3.88619900e-02, 7.69736814e-01,\n",
       "        1.24546051e-02, 2.68692017e-02, 7.01497030e-01, 1.41371393e-01,\n",
       "        1.16817474e-02, 5.15932183e+00, 8.39962959e-03, 1.21399403e-02,\n",
       "        4.60067716e+00, 8.35123062e-03, 1.15071297e-02, 4.84876351e+00,\n",
       "        8.57086182e-03, 9.67860222e-03, 4.61293445e+00, 8.33463669e-03,\n",
       "        1.61919594e-02, 4.38331623e+00, 8.37645531e-03, 2.32299805e-02,\n",
       "        4.31739016e+00, 8.66956711e-03, 8.25444221e-02, 4.65431185e+00,\n",
       "        1.55282021e-02, 3.33967209e-02, 4.61448078e+00, 3.64591789e-01,\n",
       "        1.19675636e-02, 4.98976296e+01, 8.55979919e-03, 1.09782696e-02,\n",
       "        5.63514061e+01, 1.18125916e-02, 1.09389782e-02, 5.79362836e+01,\n",
       "        1.10483646e-02, 1.82946205e-02, 6.13914502e+01, 1.51298523e-02,\n",
       "        3.04709911e-02, 5.38708810e+01, 1.01625443e-02, 1.45389986e-01,\n",
       "        5.75316460e+01, 9.95140076e-03, 5.11289787e-01, 5.42465450e+01,\n",
       "        4.95637894e-02, 3.71148586e-02, 5.46516282e+01, 7.06352139e-01]),\n",
       " 'std_fit_time': array([1.55143123e-03, 8.79386513e-03, 5.76284120e-04, 4.70854782e-03,\n",
       "        2.58485956e-02, 4.13100012e-04, 2.15133766e-03, 1.83719057e-03,\n",
       "        3.95658964e-04, 2.14402815e-03, 9.52521358e-03, 2.17882845e-03,\n",
       "        2.46801138e-04, 5.35709803e-03, 4.03907943e-04, 2.75842020e-03,\n",
       "        5.35225336e-03, 1.17965176e-03, 2.93295865e-04, 2.31138065e-02,\n",
       "        1.80258458e-03, 8.00545226e-04, 1.07715534e-02, 7.82123644e-03,\n",
       "        1.55402348e-03, 1.54638005e-01, 3.11575280e-04, 1.14588357e-03,\n",
       "        3.27955517e-02, 1.32832900e-03, 3.92152520e-03, 5.59463441e-02,\n",
       "        3.30153330e-04, 1.56219648e-03, 4.39848146e-02, 6.84137250e-04,\n",
       "        1.42636165e-03, 1.28060936e-01, 5.05284099e-04, 4.81509553e-04,\n",
       "        3.14261182e-02, 1.04216642e-04, 1.81851791e-03, 5.96602388e-02,\n",
       "        3.65470205e-03, 1.36564212e-02, 1.84931982e-01, 2.07257082e-02,\n",
       "        2.88658555e-03, 4.75812918e-02, 2.59944374e-03, 8.65036976e-03,\n",
       "        1.64685511e-01, 2.04309972e-03, 1.75414316e-03, 1.11283381e-01,\n",
       "        1.68023125e-04, 9.91339739e-04, 1.20772808e-01, 3.41970458e-03,\n",
       "        1.76837386e-04, 1.49595154e-01, 6.51284195e-04, 6.89354901e-03,\n",
       "        2.45846653e-02, 2.85162559e-04, 8.80085749e-03, 1.34537782e-01,\n",
       "        7.04901979e-04, 3.46890556e-03, 1.71229352e-01, 2.58662045e-02,\n",
       "        4.08852826e-04, 4.07533300e-01, 1.41278216e-04, 7.87356551e-04,\n",
       "        4.28782897e-01, 8.77984761e-05, 1.19504839e-03, 6.93874203e-01,\n",
       "        1.65773273e-04, 2.32715196e-04, 3.40456687e-01, 1.06425097e-04,\n",
       "        4.69374167e-04, 1.76658966e-01, 1.81587491e-04, 1.62684486e-03,\n",
       "        1.92383817e-01, 2.50647963e-04, 5.15296541e-03, 4.35908019e-01,\n",
       "        5.65561596e-04, 3.56274961e-03, 4.13084767e-01, 1.18821320e-01,\n",
       "        3.57337980e-04, 3.27655972e+00, 1.27598862e-04, 2.20194468e-04,\n",
       "        2.00377722e+01, 3.34896493e-03, 1.94576898e-03, 8.64163046e+00,\n",
       "        2.13601536e-03, 2.64172983e-03, 2.02172304e+00, 3.42156802e-03,\n",
       "        5.50593787e-03, 3.53655535e+00, 2.16352048e-03, 1.37514611e-02,\n",
       "        4.65092304e+00, 1.06359496e-03, 4.64602397e-02, 8.63987215e+00,\n",
       "        1.24921101e-02, 4.10218765e-03, 1.55896511e+01, 1.71579619e-01]),\n",
       " 'mean_score_time': array([0.00316119, 0.00157914, 0.00198531, 0.00351958, 0.00186453,\n",
       "        0.00195694, 0.00286012, 0.0014657 , 0.0016973 , 0.00229859,\n",
       "        0.00147929, 0.00230145, 0.00206981, 0.00143094, 0.00159245,\n",
       "        0.00201116, 0.00132537, 0.00159574, 0.00185747, 0.00148621,\n",
       "        0.00162678, 0.00210361, 0.00129399, 0.00162797, 0.00247021,\n",
       "        0.0014246 , 0.00160985, 0.00217552, 0.00133476, 0.00223112,\n",
       "        0.00273275, 0.00154366, 0.00207701, 0.00290451, 0.00162663,\n",
       "        0.0024384 , 0.00307374, 0.00131021, 0.0017004 , 0.00188818,\n",
       "        0.00152264, 0.00159845, 0.00182071, 0.00151711, 0.00312042,\n",
       "        0.00569782, 0.00123806, 0.00168018, 0.00260062, 0.00145121,\n",
       "        0.00298128, 0.00398846, 0.00151057, 0.00334668, 0.00497398,\n",
       "        0.00155487, 0.00159464, 0.00211339, 0.00163736, 0.00390654,\n",
       "        0.00194988, 0.00154591, 0.00346417, 0.00229383, 0.00288935,\n",
       "        0.00168376, 0.00300021, 0.0030632 , 0.00192485, 0.00217791,\n",
       "        0.00129013, 0.00156803, 0.0021924 , 0.00155287, 0.00161595,\n",
       "        0.00272908, 0.00127721, 0.00159059, 0.0020956 , 0.00133123,\n",
       "        0.00188346, 0.00191956, 0.0012856 , 0.00157757, 0.00183873,\n",
       "        0.00125957, 0.00158491, 0.00177584, 0.0013279 , 0.00160341,\n",
       "        0.00215025, 0.00128617, 0.00139203, 0.0021246 , 0.00132594,\n",
       "        0.00166545, 0.0024282 , 0.00132098, 0.00181146, 0.00212893,\n",
       "        0.00238028, 0.00196414, 0.00220566, 0.00179257, 0.00206017,\n",
       "        0.00288639, 0.00254021, 0.003196  , 0.00292106, 0.0013875 ,\n",
       "        0.00189486, 0.00280948, 0.0016665 , 0.00189443, 0.00201344,\n",
       "        0.00158963, 0.00159678, 0.00211377, 0.0014225 , 0.00214963]),\n",
       " 'std_score_time': array([1.49598436e-03, 5.05305275e-04, 5.22478614e-04, 1.20277940e-03,\n",
       "        8.86415968e-04, 2.71321349e-04, 6.53894697e-04, 2.58409165e-04,\n",
       "        7.18644380e-05, 8.67695586e-05, 3.87978506e-04, 5.92842474e-04,\n",
       "        2.55935876e-05, 3.60204109e-04, 3.46097725e-05, 1.11726375e-04,\n",
       "        3.88096823e-05, 3.30812974e-05, 1.06332698e-04, 1.14694216e-04,\n",
       "        5.12264719e-05, 2.93451158e-04, 5.59569167e-05, 1.74496889e-04,\n",
       "        3.41341454e-04, 2.10653381e-04, 6.21037884e-05, 5.44387256e-05,\n",
       "        8.85220412e-05, 3.90191887e-04, 5.75175204e-04, 1.49912825e-04,\n",
       "        2.88943646e-05, 4.66074030e-04, 2.58736781e-05, 4.94878791e-04,\n",
       "        1.09434566e-03, 8.64010773e-05, 5.49528707e-05, 3.58445822e-05,\n",
       "        3.90120485e-04, 2.08784989e-05, 2.93925147e-05, 4.93674404e-04,\n",
       "        1.42066437e-03, 2.40317473e-03, 4.47382537e-05, 7.42560243e-05,\n",
       "        5.81649621e-04, 4.07120745e-04, 6.23668107e-04, 1.65317606e-03,\n",
       "        3.63396669e-04, 1.38545328e-03, 1.28642375e-03, 5.73747573e-04,\n",
       "        1.54862732e-05, 1.97063593e-05, 5.69647192e-04, 3.64171304e-03,\n",
       "        7.93104483e-05, 3.50248854e-04, 1.68478834e-03, 5.83291392e-04,\n",
       "        1.79919812e-03, 5.65075974e-05, 7.67738380e-04, 3.45974629e-03,\n",
       "        2.31267919e-04, 3.34486852e-04, 6.77779027e-05, 1.04580880e-04,\n",
       "        5.31876743e-05, 5.37115551e-04, 4.13575907e-05, 8.31464408e-04,\n",
       "        2.02012443e-05, 2.69126318e-05, 6.48993766e-05, 5.04313853e-05,\n",
       "        1.40314420e-04, 6.84390737e-05, 6.15544875e-06, 2.15187264e-05,\n",
       "        4.68860668e-05, 5.40180950e-05, 5.68614266e-05, 3.39012776e-05,\n",
       "        7.67981143e-05, 4.90255852e-05, 3.71345686e-04, 3.93881925e-05,\n",
       "        1.47508479e-05, 2.06215692e-04, 1.16465326e-04, 7.56543289e-05,\n",
       "        2.26417357e-04, 6.19955426e-05, 1.09792561e-04, 5.49827775e-05,\n",
       "        2.18636728e-03, 4.84638517e-04, 5.20825425e-04, 2.99616545e-04,\n",
       "        2.68947190e-04, 7.38246652e-04, 1.91665411e-03, 3.89369118e-04,\n",
       "        7.59495343e-04, 2.14218402e-04, 3.11928180e-04, 7.59274088e-04,\n",
       "        4.38401329e-04, 4.15293723e-04, 4.90926955e-05, 5.88735250e-04,\n",
       "        8.67850964e-05, 2.44468296e-04, 2.16009054e-04, 4.74724342e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[1e-08, 1e-08, 1e-08, 1e-07, 1e-07, 1e-07, 1e-06, 1e-06,\n",
       "                    1e-06, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1,\n",
       "                    1e-08, 1e-08, 1e-08, 1e-07, 1e-07, 1e-07, 1e-06, 1e-06,\n",
       "                    1e-06, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1,\n",
       "                    1e-08, 1e-08, 1e-08, 1e-07, 1e-07, 1e-07, 1e-06, 1e-06,\n",
       "                    1e-06, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1,\n",
       "                    1e-08, 1e-08, 1e-08, 1e-07, 1e-07, 1e-07, 1e-06, 1e-06,\n",
       "                    1e-06, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1,\n",
       "                    1e-08, 1e-08, 1e-08, 1e-07, 1e-07, 1e-07, 1e-06, 1e-06,\n",
       "                    1e-06, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly',\n",
       "                    'rbf', 'linear', 'poly', 'rbf', 'linear', 'poly'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'gamma': 1e-08, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1e-08, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1e-08, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 1e-07, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1e-07, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1e-07, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1e-06, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1e-06, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1e-05, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-08, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-08, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-07, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-07, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-06, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-06, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-08, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-08, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-07, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-07, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-06, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-06, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 1e-08, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1e-08, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 1e-08, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1e-07, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 1e-07, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1e-06, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 1e-06, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1e-05, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 1e-08, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1e-08, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 1e-08, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 1e-07, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1e-07, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 1e-07, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1e-06, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 1e-06, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1e-05, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 1e-05, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}],\n",
       " 'split0_test_score': array([-0.07517222,  0.71027397, -0.07520895, -0.07483932,  0.71027397,\n",
       "        -0.07520895, -0.0710784 ,  0.71027397, -0.07520895, -0.04068702,\n",
       "         0.71027397, -0.07520895,  0.20782803,  0.71027397, -0.07520793,\n",
       "         0.58883541,  0.71027397, -0.07418324,  0.65400469,  0.71027397,\n",
       "         0.46286075,  0.35572928,  0.71027397,  0.20717897, -0.0748417 ,\n",
       "         0.71033466, -0.07520895, -0.07107872,  0.71033466, -0.07520895,\n",
       "        -0.04066154,  0.71033466, -0.07520895,  0.20925188,  0.71033466,\n",
       "        -0.07520894,  0.60058233,  0.71033466, -0.07519869,  0.70267738,\n",
       "         0.71033466, -0.06468687,  0.72556266,  0.71033466,  0.73985929,\n",
       "         0.43520376,  0.71033466, -0.62620713, -0.0748417 ,  0.71033466,\n",
       "        -0.07520895, -0.07107872,  0.71033466, -0.07520895, -0.04066154,\n",
       "         0.71033466, -0.07520895,  0.20925188,  0.71033466, -0.07520894,\n",
       "         0.60058233,  0.71033466, -0.07519869,  0.70267738,  0.71033466,\n",
       "        -0.06468687,  0.72556266,  0.71033466,  0.73985929,  0.43520376,\n",
       "         0.71033466, -0.62620713, -0.07110343,  0.71024835, -0.07520895,\n",
       "        -0.0406738 ,  0.71024835, -0.07520895,  0.20929032,  0.71024835,\n",
       "        -0.07520895,  0.60170423,  0.71024835, -0.07520885,  0.6995711 ,\n",
       "         0.71024835, -0.07510635,  0.76407719,  0.71024835,  0.02246031,\n",
       "         0.87259777,  0.71024835,  0.71550001,  0.42870455,  0.71024835,\n",
       "        -5.51296266, -0.0406104 ,  0.7104433 , -0.07520895,  0.20926203,\n",
       "         0.7104433 , -0.07520895,  0.60174688,  0.7104433 , -0.07520895,\n",
       "         0.69971677,  0.7104433 , -0.07520793,  0.73103324,  0.7104433 ,\n",
       "        -0.07418324,  0.82006666,  0.7104433 ,  0.46287143,  0.78962105,\n",
       "         0.7104433 ,  0.2072365 ,  0.42834912,  0.7104433 , -9.85748188]),\n",
       " 'split1_test_score': array([-0.02337   ,  0.65801629, -0.02342012, -0.02291944,  0.65801629,\n",
       "        -0.02342012, -0.01842474,  0.65801629, -0.02342012,  0.0187454 ,\n",
       "         0.65801629, -0.02342012,  0.30607457,  0.65801629, -0.02341917,\n",
       "         0.62691501,  0.65801629, -0.02246506,  0.70022389,  0.65801629,\n",
       "         0.40600894,  0.63957399,  0.65801629,  0.19971819, -0.02291896,\n",
       "         0.65811625, -0.02342012, -0.01842376,  0.65811625, -0.02342012,\n",
       "         0.01876645,  0.65811625, -0.02342012,  0.30733021,  0.65811625,\n",
       "        -0.02342011,  0.62441271,  0.65811625, -0.02341057,  0.67078647,\n",
       "         0.65811625, -0.01482114,  0.59414216,  0.65811625,  0.50618849,\n",
       "         0.60977164,  0.65811625, -0.4978964 , -0.02291896,  0.65811625,\n",
       "        -0.02342012, -0.01842376,  0.65811625, -0.02342012,  0.01876645,\n",
       "         0.65811625, -0.02342012,  0.30733021,  0.65811625, -0.02342011,\n",
       "         0.62441271,  0.65811625, -0.02341057,  0.67078647,  0.65811625,\n",
       "        -0.01482114,  0.59414216,  0.65811625,  0.50618849,  0.60977164,\n",
       "         0.65811625, -0.4978964 , -0.01841896,  0.65811991, -0.02342012,\n",
       "         0.01876461,  0.65811991, -0.02342012,  0.30748647,  0.65811991,\n",
       "        -0.02342012,  0.62413317,  0.65811991, -0.02342003,  0.66013118,\n",
       "         0.65811991, -0.02332457,  0.6928465 ,  0.65811991,  0.06373789,\n",
       "         0.2181698 ,  0.65811991,  0.38193377,  0.56568371,  0.65811991,\n",
       "        -2.51479011,  0.01859719,  0.65796933, -0.02342012,  0.30765633,\n",
       "         0.65796933, -0.02342012,  0.6242564 ,  0.65796933, -0.02342012,\n",
       "         0.65808908,  0.65796933, -0.02341917,  0.66987994,  0.65796933,\n",
       "        -0.02246506,  0.53661605,  0.65796933,  0.40600894,  0.12706258,\n",
       "         0.65796933,  0.19973266,  0.54743341,  0.65796933, -3.24265185]),\n",
       " 'split2_test_score': array([-4.03064182e-02,  6.06408540e-01, -4.03479472e-02, -3.99346433e-02,\n",
       "         6.06408540e-01, -4.03479472e-02, -3.58713826e-02,  6.06408540e-01,\n",
       "        -4.03479472e-02,  8.56116208e-03,  6.06408540e-01, -4.03479465e-02,\n",
       "         3.17609327e-01,  6.06408540e-01, -4.03472576e-02,  6.15746545e-01,\n",
       "         6.06408540e-01, -3.96589356e-02,  6.65418101e-01,  6.06408540e-01,\n",
       "         2.36573054e-01,  5.84508106e-01,  6.06408540e-01, -6.65646875e-01,\n",
       "        -3.99328159e-02,  6.04796197e-01, -4.03479472e-02, -3.58706025e-02,\n",
       "         6.04796197e-01, -4.03479472e-02,  8.58414287e-03,  6.04796197e-01,\n",
       "        -4.03479472e-02,  3.18505314e-01,  6.04796197e-01, -4.03479403e-02,\n",
       "         6.10045867e-01,  6.04796197e-01, -4.03410518e-02,  6.42161718e-01,\n",
       "         6.04796197e-01, -3.33825433e-02,  6.79678747e-01,  6.04796197e-01,\n",
       "         3.27066092e-01,  5.32279890e-01,  6.04796197e-01, -8.22031490e+00,\n",
       "        -3.99328159e-02,  6.04796197e-01, -4.03479472e-02, -3.58706025e-02,\n",
       "         6.04796197e-01, -4.03479472e-02,  8.58414287e-03,  6.04796197e-01,\n",
       "        -4.03479472e-02,  3.18505314e-01,  6.04796197e-01, -4.03479403e-02,\n",
       "         6.10045867e-01,  6.04796197e-01, -4.03410518e-02,  6.42161718e-01,\n",
       "         6.04796197e-01, -3.33825433e-02,  6.79678747e-01,  6.04796197e-01,\n",
       "         3.27066092e-01,  5.32279890e-01,  6.04796197e-01, -8.22031490e+00,\n",
       "        -3.58527943e-02,  6.06209303e-01, -4.03479472e-02,  8.61020141e-03,\n",
       "         6.06209303e-01, -4.03479472e-02,  3.18586553e-01,  6.06209303e-01,\n",
       "        -4.03479471e-02,  6.09520297e-01,  6.06209303e-01, -4.03478782e-02,\n",
       "         6.26811452e-01,  6.06209303e-01, -4.02789980e-02,  6.78289205e-01,\n",
       "         6.06209303e-01,  2.48847470e-02,  4.28369439e-01,  6.06209303e-01,\n",
       "         1.74700780e-01,  5.05443989e-01,  6.06209303e-01, -6.71272862e+00,\n",
       "         8.50148098e-03,  6.02268964e-01, -4.03479472e-02,  3.18282705e-01,\n",
       "         6.02268964e-01, -4.03479472e-02,  6.09495499e-01,  6.02268964e-01,\n",
       "        -4.03479465e-02,  6.25292488e-01,  6.02268964e-01, -4.03472576e-02,\n",
       "         6.45727506e-01,  6.02268964e-01, -3.96589356e-02,  5.81822335e-01,\n",
       "         6.02268964e-01,  2.36579169e-01,  1.03673648e-01,  6.02268964e-01,\n",
       "        -6.65923146e-01,  5.05443989e-01,  6.02268964e-01, -2.78004295e+01]),\n",
       " 'split3_test_score': array([-0.08360682,  0.76224959, -0.08364786, -0.08323913,  0.76224959,\n",
       "        -0.08364786, -0.07995061,  0.76224959, -0.08364786, -0.03891324,\n",
       "         0.76224959, -0.08364786,  0.28461976,  0.76224959, -0.08364678,\n",
       "         0.68500786,  0.76224959, -0.08256847,  0.77787049,  0.76224959,\n",
       "         0.35881403,  0.66428177,  0.76224959,  0.43706267, -0.08323756,\n",
       "         0.76224057, -0.08364786, -0.07995045,  0.76224057, -0.08364786,\n",
       "        -0.03889017,  0.76224057, -0.08364786,  0.28601691,  0.76224057,\n",
       "        -0.08364785,  0.68788673,  0.76224057, -0.08363705,  0.76605353,\n",
       "         0.76224057, -0.07307727,  0.75313673,  0.76224057,  0.54082094,\n",
       "         0.67079398,  0.76224057, -0.41297166, -0.08323756,  0.76224057,\n",
       "        -0.08364786, -0.07995045,  0.76224057, -0.08364786, -0.03889017,\n",
       "         0.76224057, -0.08364786,  0.28601691,  0.76224057, -0.08364785,\n",
       "         0.68788673,  0.76224057, -0.08363705,  0.76605353,  0.76224057,\n",
       "        -0.07307727,  0.75313673,  0.76224057,  0.54082094,  0.67079398,\n",
       "         0.76224057, -0.41297166, -0.07993583,  0.762069  , -0.08364786,\n",
       "        -0.03890455,  0.762069  , -0.08364786,  0.28617811,  0.762069  ,\n",
       "        -0.08364786,  0.68812443,  0.762069  , -0.08364775,  0.76686203,\n",
       "         0.762069  , -0.08353985,  0.74132847,  0.762069  ,  0.01233169,\n",
       "         0.6511119 ,  0.762069  ,  0.6849358 ,  0.60629008,  0.762069  ,\n",
       "        -2.72908176, -0.03875603,  0.76058888, -0.08364786,  0.28645222,\n",
       "         0.76058888, -0.08364786,  0.68822057,  0.76058888, -0.08364786,\n",
       "         0.76512531,  0.76058888, -0.08364678,  0.76526604,  0.76058888,\n",
       "        -0.08256847,  0.67495286,  0.76058888,  0.35874914,  0.55775293,\n",
       "         0.76058888,  0.43696695,  0.61447525,  0.76058888, -4.68435326]),\n",
       " 'split4_test_score': array([-2.17046236e-02,  5.35892076e-01, -2.17349092e-02, -2.14328381e-02,\n",
       "         5.35892076e-01, -2.17349092e-02, -1.87189609e-02,  5.35892076e-01,\n",
       "        -2.17349092e-02,  4.62365151e-03,  5.35892076e-01, -2.17349082e-02,\n",
       "         1.85961406e-01,  5.35892076e-01, -2.17339192e-02,  4.80609132e-01,\n",
       "         5.35892076e-01, -2.07453716e-02,  5.49901859e-01,  5.35892076e-01,\n",
       "         4.46390641e-01,  3.86279868e-01,  5.35892076e-01, -4.20810678e-01,\n",
       "        -2.14320999e-02,  5.35585281e-01, -2.17349092e-02, -1.87187717e-02,\n",
       "         5.35585281e-01, -2.17349092e-02,  4.64024831e-03,  5.35585281e-01,\n",
       "        -2.17349092e-02,  1.87002087e-01,  5.35585281e-01, -2.17348993e-02,\n",
       "         4.87511167e-01,  5.35585281e-01, -2.17250094e-02,  5.52380565e-01,\n",
       "         5.35585281e-01, -1.20531514e-02,  6.31960049e-01,  5.35585281e-01,\n",
       "         6.17179507e-01,  3.90332083e-01,  5.35585281e-01, -4.35440150e+00,\n",
       "        -2.14320999e-02,  5.35585281e-01, -2.17349092e-02, -1.87187717e-02,\n",
       "         5.35585281e-01, -2.17349092e-02,  4.64024831e-03,  5.35585281e-01,\n",
       "        -2.17349092e-02,  1.87002087e-01,  5.35585281e-01, -2.17348993e-02,\n",
       "         4.87511167e-01,  5.35585281e-01, -2.17250094e-02,  5.52380565e-01,\n",
       "         5.35585281e-01, -1.20531514e-02,  6.31960049e-01,  5.35585281e-01,\n",
       "         6.17179507e-01,  3.90332083e-01,  5.35585281e-01, -4.35440150e+00,\n",
       "        -1.87114216e-02,  5.35547758e-01, -2.17349092e-02,  4.64003718e-03,\n",
       "         5.35547758e-01, -2.17349092e-02,  1.86996709e-01,  5.35547758e-01,\n",
       "        -2.17349091e-02,  4.88595669e-01,  5.35547758e-01, -2.17348102e-02,\n",
       "         5.40194046e-01,  5.35547758e-01, -2.16359157e-02,  5.98728197e-01,\n",
       "         5.35547758e-01,  7.09321443e-02,  6.50915711e-01,  5.35547758e-01,\n",
       "         5.89427867e-01,  3.64684283e-01,  5.35547758e-01, -3.62766221e+00,\n",
       "         4.71727150e-03,  5.36119338e-01, -2.17349092e-02,  1.87067007e-01,\n",
       "         5.36119338e-01, -2.17349092e-02,  4.88624952e-01,  5.36119338e-01,\n",
       "        -2.17349082e-02,  5.37911435e-01,  5.36119338e-01, -2.17339192e-02,\n",
       "         5.65813057e-01,  5.36119338e-01, -2.07453716e-02,  6.59863453e-01,\n",
       "         5.36119338e-01,  4.46391143e-01,  4.65256264e-01,  5.36119338e-01,\n",
       "        -4.20997028e-01,  3.61878530e-01,  5.36119338e-01, -1.17236147e+01]),\n",
       " 'mean_test_score': array([-4.88320158e-02,  6.54568094e-01, -4.88719580e-02, -4.84730756e-02,\n",
       "         6.54568094e-01, -4.88719580e-02, -4.48088201e-02,  6.54568094e-01,\n",
       "        -4.88719580e-02, -9.53400981e-03,  6.54568094e-01, -4.88719570e-02,\n",
       "         2.60418621e-01,  6.54568094e-01, -4.88710097e-02,  5.99422794e-01,\n",
       "         6.54568094e-01, -4.79242157e-02,  6.69483806e-01,  6.54568094e-01,\n",
       "         3.82129485e-01,  5.26074601e-01,  6.54568094e-01, -4.84995453e-02,\n",
       "        -4.84726271e-02,  6.54214590e-01, -4.88719580e-02, -4.48084607e-02,\n",
       "         6.54214590e-01, -4.88719580e-02, -9.51217211e-03,  6.54214590e-01,\n",
       "        -4.88719580e-02,  2.61621279e-01,  6.54214590e-01, -4.88719485e-02,\n",
       "         6.02087761e-01,  6.54214590e-01, -4.88624754e-02,  6.66811932e-01,\n",
       "         6.54214590e-01, -3.96041960e-02,  6.76896071e-01,  6.54214590e-01,\n",
       "         5.46222863e-01,  5.27676270e-01,  6.54214590e-01, -2.82235832e+00,\n",
       "        -4.84726271e-02,  6.54214590e-01, -4.88719580e-02, -4.48084607e-02,\n",
       "         6.54214590e-01, -4.88719580e-02, -9.51217211e-03,  6.54214590e-01,\n",
       "        -4.88719580e-02,  2.61621279e-01,  6.54214590e-01, -4.88719485e-02,\n",
       "         6.02087761e-01,  6.54214590e-01, -4.88624754e-02,  6.66811932e-01,\n",
       "         6.54214590e-01, -3.96041960e-02,  6.76896071e-01,  6.54214590e-01,\n",
       "         5.46222863e-01,  5.27676270e-01,  6.54214590e-01, -2.82235832e+00,\n",
       "        -4.48044877e-02,  6.54438864e-01, -4.88719580e-02, -9.51269984e-03,\n",
       "         6.54438864e-01, -4.88719580e-02,  2.61707633e-01,  6.54438864e-01,\n",
       "        -4.88719579e-02,  6.02415560e-01,  6.54438864e-01, -4.88718631e-02,\n",
       "         6.58713962e-01,  6.54438864e-01, -4.87771365e-02,  6.95053913e-01,\n",
       "         6.54438864e-01,  3.88693559e-02,  5.64232924e-01,  6.54438864e-01,\n",
       "         5.09299647e-01,  4.94161321e-01,  6.54438864e-01, -4.21944507e+00,\n",
       "        -9.51009852e-03,  6.53477963e-01, -4.88719580e-02,  2.61744057e-01,\n",
       "         6.53477963e-01, -4.88719580e-02,  6.02468858e-01,  6.53477963e-01,\n",
       "        -4.88719570e-02,  6.57227015e-01,  6.53477963e-01, -4.88710097e-02,\n",
       "         6.75543957e-01,  6.53477963e-01, -4.79242157e-02,  6.54664272e-01,\n",
       "         6.53477963e-01,  3.82119963e-01,  4.08673295e-01,  6.53477963e-01,\n",
       "        -4.85968128e-02,  4.91516060e-01,  6.53477963e-01, -1.14617062e+01]),\n",
       " 'std_test_score': array([0.02592292, 0.07888432, 0.02592248, 0.02592653, 0.07888432,\n",
       "        0.02592248, 0.02600659, 0.07888432, 0.02592248, 0.02514458,\n",
       "        0.07888432, 0.02592248, 0.05338649, 0.07888432, 0.02592242,\n",
       "        0.06719504, 0.07888432, 0.02586478, 0.07382222, 0.07888432,\n",
       "        0.08117579, 0.12958233, 0.07888432, 0.42005729, 0.02592696,\n",
       "        0.07918256, 0.02592248, 0.0260069 , 0.07918256, 0.02592248,\n",
       "        0.02514278, 0.07918256, 0.02592248, 0.05334946, 0.07918256,\n",
       "        0.02592248, 0.06488954, 0.07918256, 0.0259219 , 0.07050276,\n",
       "        0.07918256, 0.0251458 , 0.05840595, 0.07918256, 0.13578773,\n",
       "        0.1045544 , 0.07918256, 3.0827403 , 0.02592696, 0.07918256,\n",
       "        0.02592248, 0.0260069 , 0.07918256, 0.02592248, 0.02514278,\n",
       "        0.07918256, 0.02592248, 0.05334946, 0.07918256, 0.02592248,\n",
       "        0.06488954, 0.07918256, 0.0259219 , 0.07050276, 0.07918256,\n",
       "        0.0251458 , 0.05840595, 0.07918256, 0.13578773, 0.1045544 ,\n",
       "        0.07918256, 3.0827403 , 0.02601162, 0.07896034, 0.02592248,\n",
       "        0.0251525 , 0.07896034, 0.02592248, 0.05340227, 0.07896034,\n",
       "        0.02592248, 0.06453467, 0.07896034, 0.02592247, 0.0754083 ,\n",
       "        0.07896034, 0.02591668, 0.05739359, 0.07896034, 0.0237299 ,\n",
       "        0.22287634, 0.07896034, 0.20394394, 0.08816405, 0.07896034,\n",
       "        1.63504672, 0.02505757, 0.07890929, 0.02592248, 0.05337803,\n",
       "        0.07890929, 0.02592248, 0.06455754, 0.07890929, 0.02592248,\n",
       "        0.07576831, 0.07890929, 0.02592242, 0.06941338, 0.07890929,\n",
       "        0.02586478, 0.09699272, 0.07890929, 0.08117954, 0.26186903,\n",
       "        0.07890929, 0.42015809, 0.08858403, 0.07890929, 8.75307236]),\n",
       " 'rank_test_score': array([ 93,  11, 114,  89,  11, 111,  84,  11, 106,  78,  11, 101,  72,\n",
       "         11,  97,  55,  11,  85,   5,  11,  66,  61,  11,  90,  87,  27,\n",
       "        114,  82,  27, 109,  75,  27, 104,  70,  27,  99,  53,  27,  94,\n",
       "          6,  27,  79,   2,  27,  57,  59,  27, 117,  87,  27, 114,  82,\n",
       "         27, 109,  75,  27, 104,  70,  27,  99,  53,  27,  94,   6,  27,\n",
       "         79,   2,  27,  57,  59,  27, 117,  81,  19, 113,  77,  19, 108,\n",
       "         69,  19, 103,  52,  19,  98,   8,  19,  92,   1,  19,  73,  56,\n",
       "         19,  62,  63,  19, 119,  74,  43, 111,  68,  43, 106,  51,  43,\n",
       "        101,   9,  43,  96,   4,  43,  86,  10,  43,  67,  65,  43,  91,\n",
       "         64,  43, 120], dtype=int32),\n",
       " 'split0_train_score': array([-0.04620157,  0.64735322, -0.04624157, -0.04583944,  0.64735322,\n",
       "        -0.04624157, -0.04181101,  0.64735322, -0.04624157, -0.00871477,\n",
       "         0.64735322, -0.04624156,  0.24685196,  0.64735322, -0.04623881,\n",
       "         0.58769216,  0.64735322, -0.04358386,  0.69204779,  0.64735322,\n",
       "         0.39957098,  0.73979682,  0.64735322,  0.93662892, -0.0458417 ,\n",
       "         0.64739338, -0.04624157, -0.04181131,  0.64739338, -0.04624157,\n",
       "        -0.00869177,  0.64739338, -0.04624157,  0.24799012,  0.64739338,\n",
       "        -0.04624154,  0.59171759,  0.64739338, -0.04621405,  0.66359503,\n",
       "         0.64739338, -0.0271169 ,  0.77501876,  0.64739338,  0.63796649,\n",
       "         0.9714445 ,  0.64739338,  0.97164196, -0.0458417 ,  0.64739338,\n",
       "        -0.04624157, -0.04181131,  0.64739338, -0.04624157, -0.00869177,\n",
       "         0.64739338, -0.04624157,  0.24799012,  0.64739338, -0.04624154,\n",
       "         0.59171759,  0.64739338, -0.04621405,  0.66359503,  0.64739338,\n",
       "        -0.0271169 ,  0.77501876,  0.64739338,  0.63796649,  0.9714445 ,\n",
       "         0.64739338,  0.97164196, -0.04183481,  0.64735448, -0.04624157,\n",
       "        -0.00875644,  0.64735448, -0.04624157,  0.24800959,  0.64735448,\n",
       "        -0.04624156,  0.59219086,  0.64735448, -0.04624129,  0.64982038,\n",
       "         0.64735448, -0.04596726,  0.71524295,  0.64735448,  0.07812657,\n",
       "         0.91048453,  0.64735448,  0.86993264,  0.98838055,  0.64735448,\n",
       "         0.98817087, -0.00869535,  0.64741303, -0.04624157,  0.2479778 ,\n",
       "         0.64741303, -0.04624157,  0.59222747,  0.64741303, -0.04624156,\n",
       "         0.64837188,  0.64741303, -0.04623881,  0.66813007,  0.64741303,\n",
       "        -0.04358386,  0.76979138,  0.64741303,  0.39957759,  0.95171048,\n",
       "         0.64741303,  0.93663029,  0.99053035,  0.64741303,  0.99000553]),\n",
       " 'split1_train_score': array([-0.03837137,  0.66934034, -0.03841412, -0.03798722,  0.66934034,\n",
       "        -0.03841412, -0.03415362,  0.66934034, -0.03841412, -0.00306835,\n",
       "         0.66934034, -0.03841411,  0.24838876,  0.66934034, -0.03841167,\n",
       "         0.58306984,  0.66934034, -0.03604559,  0.69730194,  0.66934034,\n",
       "         0.45864555,  0.6706902 ,  0.66934034,  0.96084789, -0.03798675,\n",
       "         0.66938815, -0.03841412, -0.03415265,  0.66938815, -0.03841412,\n",
       "        -0.00304668,  0.66938815, -0.03841412,  0.2498576 ,  0.66938815,\n",
       "        -0.03841409,  0.58517672,  0.66938815, -0.03838964,  0.67972551,\n",
       "         0.66938815, -0.02195651,  0.8660661 ,  0.66938815,  0.72888082,\n",
       "         0.98037199,  0.66938815,  0.981128  , -0.03798675,  0.66938815,\n",
       "        -0.03841412, -0.03415265,  0.66938815, -0.03841412, -0.00304668,\n",
       "         0.66938815, -0.03841412,  0.2498576 ,  0.66938815, -0.03841409,\n",
       "         0.58517672,  0.66938815, -0.03838964,  0.67972551,  0.66938815,\n",
       "        -0.02195651,  0.8660661 ,  0.66938815,  0.72888082,  0.98037199,\n",
       "         0.66938815,  0.981128  , -0.03414797,  0.66938384, -0.03841412,\n",
       "        -0.00304825,  0.66938384, -0.03841412,  0.25003347,  0.66938384,\n",
       "        -0.03841411,  0.58499887,  0.66938384, -0.03841387,  0.66788366,\n",
       "         0.66938384, -0.03817012,  0.76390261,  0.66938384,  0.08189258,\n",
       "         0.93864884,  0.66938384,  0.90578547,  0.99150105,  0.66938384,\n",
       "         0.99088758, -0.00320676,  0.66921104, -0.03841412,  0.25018838,\n",
       "         0.66921104, -0.03841412,  0.58505225,  0.66921104, -0.03841411,\n",
       "         0.66621736,  0.66921104, -0.03841167,  0.68799726,  0.66921104,\n",
       "        -0.03604559,  0.86711722,  0.66921104,  0.45864555,  0.96655994,\n",
       "         0.66921104,  0.96084929,  0.99208539,  0.66921104,  0.99167853]),\n",
       " 'split2_train_score': array([-0.04547162,  0.67664017, -0.04550116, -0.04520738,  0.67664017,\n",
       "        -0.04550116, -0.04227192,  0.67664017, -0.04550116, -0.00941117,\n",
       "         0.67664017, -0.04550116,  0.235399  ,  0.67664017, -0.04549955,\n",
       "         0.59967124,  0.67664017, -0.04388736,  0.68393149,  0.67664017,\n",
       "         0.46568632,  0.68368026,  0.67664017,  0.95922094, -0.04520585,\n",
       "         0.67647143, -0.04550116, -0.04227125,  0.67647143, -0.04550116,\n",
       "        -0.00938972,  0.67647143, -0.04550116,  0.23663318,  0.67647143,\n",
       "        -0.04550115,  0.60443141,  0.67647143, -0.045485  ,  0.68274467,\n",
       "         0.67647143, -0.02946881,  0.8425864 ,  0.67647143,  0.73522216,\n",
       "         0.98690931,  0.67647143,  0.98377421, -0.04520585,  0.67647143,\n",
       "        -0.04550116, -0.04227125,  0.67647143, -0.04550116, -0.00938972,\n",
       "         0.67647143, -0.04550116,  0.23663318,  0.67647143, -0.04550115,\n",
       "         0.60443141,  0.67647143, -0.045485  ,  0.68274467,  0.67647143,\n",
       "        -0.02946881,  0.8425864 ,  0.67647143,  0.73522216,  0.98690931,\n",
       "         0.67647143,  0.98377421, -0.04225637,  0.67645019, -0.04550116,\n",
       "        -0.00936795,  0.67645019, -0.04550116,  0.23675063,  0.67645019,\n",
       "        -0.04550116,  0.60501904,  0.67645019, -0.045501  ,  0.67332829,\n",
       "         0.67645019, -0.04533957,  0.75927553,  0.67645019,  0.09423147,\n",
       "         0.94986545,  0.67645019,  0.91423327,  0.99226781,  0.67645019,\n",
       "         0.99128314, -0.00945768,  0.67650867, -0.04550116,  0.23652975,\n",
       "         0.67650867, -0.04550116,  0.60503303,  0.67650867, -0.04550116,\n",
       "         0.67135711,  0.67650867, -0.04549955,  0.69127409,  0.67650867,\n",
       "        -0.04388736,  0.84815421,  0.67650867,  0.46569203,  0.96907356,\n",
       "         0.67650867,  0.95922115,  0.99226781,  0.67650867,  0.99166993]),\n",
       " 'split3_train_score': array([-0.03813574,  0.63490581, -0.03816833, -0.03784335,  0.63490581,\n",
       "        -0.03816833, -0.03513737,  0.63490581, -0.03816833, -0.00382536,\n",
       "         0.63490581, -0.03816833,  0.23580066,  0.63490581, -0.03816602,\n",
       "         0.54475897,  0.63490581, -0.03593867,  0.67469131,  0.63490581,\n",
       "         0.46125437,  0.66780264,  0.63490581,  0.94875954, -0.03784249,\n",
       "         0.63487896, -0.03816833, -0.0351372 ,  0.63487896, -0.03816833,\n",
       "        -0.00380458,  0.63487896, -0.03816833,  0.23708861,  0.63487896,\n",
       "        -0.0381683 ,  0.55040845,  0.63487896, -0.03814524,  0.65501286,\n",
       "         0.63487896, -0.02242933,  0.83182577,  0.63487896,  0.71334901,\n",
       "         0.97567848,  0.63487896,  0.97268038, -0.03784249,  0.63487896,\n",
       "        -0.03816833, -0.0351372 ,  0.63487896, -0.03816833, -0.00380458,\n",
       "         0.63487896, -0.03816833,  0.23708861,  0.63487896, -0.0381683 ,\n",
       "         0.55040845,  0.63487896, -0.03814524,  0.65501286,  0.63487896,\n",
       "        -0.02242933,  0.83182577,  0.63487896,  0.71334901,  0.97567848,\n",
       "         0.63487896,  0.97268038, -0.03512913,  0.63511588, -0.03816833,\n",
       "        -0.00381185,  0.63511588, -0.03816833,  0.23723106,  0.63511588,\n",
       "        -0.03816833,  0.55109486,  0.63511588, -0.0381681 ,  0.63639504,\n",
       "         0.63511588, -0.03793816,  0.75809371,  0.63511588,  0.07061444,\n",
       "         0.93424241,  0.63511588,  0.89588862,  0.99018458,  0.63511588,\n",
       "         0.99029987, -0.00372862,  0.635386  , -0.03816833,  0.23740702,\n",
       "         0.635386  , -0.03816833,  0.55118781,  0.635386  , -0.03816833,\n",
       "         0.63212436,  0.635386  , -0.03816602,  0.66952978,  0.635386  ,\n",
       "        -0.03593867,  0.83272894,  0.635386  ,  0.46120239,  0.95605365,\n",
       "         0.635386  ,  0.94876451,  0.99181976,  0.635386  ,  0.99121676]),\n",
       " 'split4_train_score': array([-0.04827127,  0.7194307 , -0.04831987, -0.04783551,  0.7194307 ,\n",
       "        -0.04831987, -0.04348535,  0.7194307 , -0.04831987, -0.00756198,\n",
       "         0.7194307 , -0.04831987,  0.26997435,  0.7194307 , -0.04831743,\n",
       "         0.64912736,  0.7194307 , -0.04598058,  0.74639925,  0.7194307 ,\n",
       "         0.43369871,  0.76385846,  0.7194307 ,  0.95061651, -0.04783399,\n",
       "         0.71942573, -0.04831987, -0.04348511,  0.71942573, -0.04831987,\n",
       "        -0.00754216,  0.71942573, -0.04831987,  0.27105376,  0.71942573,\n",
       "        -0.04831984,  0.65145046,  0.71942573, -0.04829548,  0.73309647,\n",
       "         0.71942573, -0.03336617,  0.85724591,  0.71942573,  0.71178523,\n",
       "         0.98148342,  0.71942573,  0.98087272, -0.04783399,  0.71942573,\n",
       "        -0.04831987, -0.04348511,  0.71942573, -0.04831987, -0.00754216,\n",
       "         0.71942573, -0.04831987,  0.27105376,  0.71942573, -0.04831984,\n",
       "         0.65145046,  0.71942573, -0.04829548,  0.73309647,  0.71942573,\n",
       "        -0.03336617,  0.85724591,  0.71942573,  0.71178523,  0.98148342,\n",
       "         0.71942573,  0.98087272, -0.04346992,  0.71950176, -0.04831987,\n",
       "        -0.00754399,  0.71950176, -0.04831987,  0.27099751,  0.71950176,\n",
       "        -0.04831987,  0.65182692,  0.71950176, -0.04831962,  0.71560573,\n",
       "         0.71950176, -0.04807689,  0.7981582 ,  0.71950176,  0.05375119,\n",
       "         0.92104379,  0.71950176,  0.88138802,  0.98969387,  0.71950176,\n",
       "         0.98882886, -0.00740829,  0.7195273 , -0.04831987,  0.27112478,\n",
       "         0.7195273 , -0.04831987,  0.6518437 ,  0.7195273 , -0.04831987,\n",
       "         0.71286934,  0.7195273 , -0.04831743,  0.74559281,  0.7195273 ,\n",
       "        -0.04598058,  0.86802403,  0.7195273 ,  0.43369953,  0.96241372,\n",
       "         0.7195273 ,  0.95061735,  0.98984231,  0.7195273 ,  0.98904926]),\n",
       " 'mean_train_score': array([-0.04329031,  0.66953405, -0.04332901, -0.04294258,  0.66953405,\n",
       "        -0.04332901, -0.03937185,  0.66953405, -0.04332901, -0.00651633,\n",
       "         0.66953405, -0.04332901,  0.24728295,  0.66953405, -0.04332669,\n",
       "         0.59286391,  0.66953405, -0.04108721,  0.69887435,  0.66953405,\n",
       "         0.44377119,  0.70516567,  0.66953405,  0.95121476, -0.04294215,\n",
       "         0.66951153, -0.04332901, -0.0393715 ,  0.66951153, -0.04332901,\n",
       "        -0.00649498,  0.66951153, -0.04332901,  0.24852465,  0.66951153,\n",
       "        -0.04332898,  0.59663693,  0.66951153, -0.04330588,  0.68283491,\n",
       "         0.66951153, -0.02686754,  0.83454859,  0.66951153,  0.70544074,\n",
       "         0.97917754,  0.66951153,  0.97801945, -0.04294215,  0.66951153,\n",
       "        -0.04332901, -0.0393715 ,  0.66951153, -0.04332901, -0.00649498,\n",
       "         0.66951153, -0.04332901,  0.24852465,  0.66951153, -0.04332898,\n",
       "         0.59663693,  0.66951153, -0.04330588,  0.68283491,  0.66951153,\n",
       "        -0.02686754,  0.83454859,  0.66951153,  0.70544074,  0.97917754,\n",
       "         0.66951153,  0.97801945, -0.03936764,  0.66956123, -0.04332901,\n",
       "        -0.0065057 ,  0.66956123, -0.04332901,  0.24860445,  0.66956123,\n",
       "        -0.04332901,  0.59702611,  0.66956123, -0.04332878,  0.66860662,\n",
       "         0.66956123, -0.0430984 ,  0.7589346 ,  0.66956123,  0.07572325,\n",
       "         0.930857  ,  0.66956123,  0.8934456 ,  0.99040557,  0.66956123,\n",
       "         0.98989407, -0.00649934,  0.66960921, -0.04332901,  0.24864555,\n",
       "         0.66960921, -0.04332901,  0.59706885,  0.66960921, -0.04332901,\n",
       "         0.66618801,  0.66960921, -0.04332669,  0.6925048 ,  0.66960921,\n",
       "        -0.04108721,  0.83716316,  0.66960921,  0.44376342,  0.96116227,\n",
       "         0.66960921,  0.95121652,  0.99130912,  0.66960921,  0.990724  ]),\n",
       " 'std_train_score': array([0.00421448, 0.0290906 , 0.0042166 , 0.0041957 , 0.0290906 ,\n",
       "        0.0042166 , 0.00391003, 0.0290906 , 0.0042166 , 0.00258598,\n",
       "        0.0290906 , 0.0042166 , 0.01256487, 0.0290906 , 0.00421661,\n",
       "        0.03361152, 0.0290906 , 0.00424133, 0.02496317, 0.0290906 ,\n",
       "        0.02474791, 0.0392182 , 0.0290906 , 0.00867213, 0.00419582,\n",
       "        0.02908096, 0.0042166 , 0.00391021, 0.02908096, 0.0042166 ,\n",
       "        0.00258577, 0.02908096, 0.0042166 , 0.01250451, 0.02908096,\n",
       "        0.0042166 , 0.03273495, 0.02908096, 0.00421672, 0.02712984,\n",
       "        0.02908096, 0.00430992, 0.03201357, 0.02908096, 0.03490541,\n",
       "        0.00526436, 0.02908096, 0.00490101, 0.00419582, 0.02908096,\n",
       "        0.0042166 , 0.00391021, 0.02908096, 0.0042166 , 0.00258577,\n",
       "        0.02908096, 0.0042166 , 0.01250451, 0.02908096, 0.0042166 ,\n",
       "        0.03273495, 0.02908096, 0.00421672, 0.02712984, 0.02908096,\n",
       "        0.00430992, 0.03201357, 0.02908096, 0.03490541, 0.00526436,\n",
       "        0.02908096, 0.00490101, 0.00391076, 0.0290557 , 0.0042166 ,\n",
       "        0.00259026, 0.0290557 , 0.0042166 , 0.01243955, 0.0290557 ,\n",
       "        0.0042166 , 0.03269474, 0.0290557 , 0.0042166 , 0.02691558,\n",
       "        0.0290557 , 0.00421793, 0.02635509, 0.0290557 , 0.01338105,\n",
       "        0.0137465 , 0.0290557 , 0.01605374, 0.00136558, 0.0290557 ,\n",
       "        0.00119878, 0.00256587, 0.02899474, 0.0042166 , 0.01249991,\n",
       "        0.02899474, 0.0042166 , 0.03266992, 0.02899474, 0.0042166 ,\n",
       "        0.02714264, 0.02899474, 0.00421661, 0.02815013, 0.02899474,\n",
       "        0.00424133, 0.03613602, 0.02899474, 0.02473915, 0.00646102,\n",
       "        0.02899474, 0.00867172, 0.00095294, 0.02899474, 0.00103631])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid = {\n",
    "    \"kernel\": [\"rbf\", \"linear\", \"poly\"],\n",
    "    \"C\": [1,10,10,100,1000],\n",
    "    \"gamma\": [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "}\n",
    "\n",
    "X = X_train.drop('SoldPrice', axis = 1)\n",
    "y = X_train.SoldPrice\n",
    "y = np.asarray(y)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)\n",
    "\n",
    "regressor = SVR()\n",
    "\n",
    "grid_search_cv = GridSearchCV(estimator = regressor, param_grid= grid, cv =5, return_train_score= True, verbose= 2)\n",
    "grid_search_cv.fit(X, y)\n",
    "grid_search_cv.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>87</th>\n",
       "      <th>66</th>\n",
       "      <th>42</th>\n",
       "      <th>108</th>\n",
       "      <th>18</th>\n",
       "      <th>63</th>\n",
       "      <th>39</th>\n",
       "      <th>84</th>\n",
       "      <th>105</th>\n",
       "      <th>111</th>\n",
       "      <th>7</th>\n",
       "      <th>16</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>19</th>\n",
       "      <th>22</th>\n",
       "      <th>13</th>\n",
       "      <th>10</th>\n",
       "      <th>91</th>\n",
       "      <th>73</th>\n",
       "      <th>88</th>\n",
       "      <th>82</th>\n",
       "      <th>85</th>\n",
       "      <th>76</th>\n",
       "      <th>94</th>\n",
       "      <th>79</th>\n",
       "      <th>49</th>\n",
       "      <th>40</th>\n",
       "      <th>43</th>\n",
       "      <th>70</th>\n",
       "      <th>52</th>\n",
       "      <th>55</th>\n",
       "      <th>67</th>\n",
       "      <th>61</th>\n",
       "      <th>64</th>\n",
       "      <th>37</th>\n",
       "      <th>58</th>\n",
       "      <th>46</th>\n",
       "      <th>28</th>\n",
       "      <th>34</th>\n",
       "      <th>31</th>\n",
       "      <th>25</th>\n",
       "      <th>109</th>\n",
       "      <th>118</th>\n",
       "      <th>115</th>\n",
       "      <th>97</th>\n",
       "      <th>100</th>\n",
       "      <th>106</th>\n",
       "      <th>103</th>\n",
       "      <th>112</th>\n",
       "      <th>102</th>\n",
       "      <th>81</th>\n",
       "      <th>36</th>\n",
       "      <th>60</th>\n",
       "      <th>15</th>\n",
       "      <th>90</th>\n",
       "      <th>44</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>45</th>\n",
       "      <th>21</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>117</th>\n",
       "      <th>114</th>\n",
       "      <th>20</th>\n",
       "      <th>113</th>\n",
       "      <th>99</th>\n",
       "      <th>78</th>\n",
       "      <th>33</th>\n",
       "      <th>57</th>\n",
       "      <th>12</th>\n",
       "      <th>89</th>\n",
       "      <th>96</th>\n",
       "      <th>54</th>\n",
       "      <th>30</th>\n",
       "      <th>75</th>\n",
       "      <th>9</th>\n",
       "      <th>41</th>\n",
       "      <th>65</th>\n",
       "      <th>72</th>\n",
       "      <th>27</th>\n",
       "      <th>51</th>\n",
       "      <th>6</th>\n",
       "      <th>17</th>\n",
       "      <th>110</th>\n",
       "      <th>48</th>\n",
       "      <th>24</th>\n",
       "      <th>3</th>\n",
       "      <th>23</th>\n",
       "      <th>116</th>\n",
       "      <th>86</th>\n",
       "      <th>0</th>\n",
       "      <th>38</th>\n",
       "      <th>62</th>\n",
       "      <th>107</th>\n",
       "      <th>14</th>\n",
       "      <th>83</th>\n",
       "      <th>59</th>\n",
       "      <th>35</th>\n",
       "      <th>104</th>\n",
       "      <th>11</th>\n",
       "      <th>80</th>\n",
       "      <th>32</th>\n",
       "      <th>56</th>\n",
       "      <th>101</th>\n",
       "      <th>8</th>\n",
       "      <th>77</th>\n",
       "      <th>53</th>\n",
       "      <th>29</th>\n",
       "      <th>5</th>\n",
       "      <th>98</th>\n",
       "      <th>74</th>\n",
       "      <th>2</th>\n",
       "      <th>50</th>\n",
       "      <th>26</th>\n",
       "      <th>47</th>\n",
       "      <th>71</th>\n",
       "      <th>95</th>\n",
       "      <th>119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.02323</td>\n",
       "      <td>0.038862</td>\n",
       "      <td>0.0215946</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.0118427</td>\n",
       "      <td>0.0261116</td>\n",
       "      <td>0.0142592</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.0182946</td>\n",
       "      <td>0.14539</td>\n",
       "      <td>0.070125</td>\n",
       "      <td>0.0694604</td>\n",
       "      <td>0.0880497</td>\n",
       "      <td>0.0744107</td>\n",
       "      <td>0.0935681</td>\n",
       "      <td>0.0812947</td>\n",
       "      <td>0.0710156</td>\n",
       "      <td>0.0834431</td>\n",
       "      <td>4.65431</td>\n",
       "      <td>5.15932</td>\n",
       "      <td>4.31739</td>\n",
       "      <td>4.61293</td>\n",
       "      <td>4.38332</td>\n",
       "      <td>4.60068</td>\n",
       "      <td>4.61448</td>\n",
       "      <td>4.84876</td>\n",
       "      <td>0.533924</td>\n",
       "      <td>0.546842</td>\n",
       "      <td>0.537461</td>\n",
       "      <td>0.701497</td>\n",
       "      <td>0.633267</td>\n",
       "      <td>0.638852</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.67046</td>\n",
       "      <td>0.827334</td>\n",
       "      <td>0.583702</td>\n",
       "      <td>0.574692</td>\n",
       "      <td>0.666681</td>\n",
       "      <td>0.517427</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.600311</td>\n",
       "      <td>0.696395</td>\n",
       "      <td>53.8709</td>\n",
       "      <td>54.6516</td>\n",
       "      <td>54.2465</td>\n",
       "      <td>49.8976</td>\n",
       "      <td>56.3514</td>\n",
       "      <td>61.3915</td>\n",
       "      <td>57.9363</td>\n",
       "      <td>57.5316</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.0096786</td>\n",
       "      <td>0.0128288</td>\n",
       "      <td>0.00963945</td>\n",
       "      <td>0.0119952</td>\n",
       "      <td>0.0825444</td>\n",
       "      <td>0.0162938</td>\n",
       "      <td>0.0124546</td>\n",
       "      <td>0.0268692</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>0.0153872</td>\n",
       "      <td>0.0155282</td>\n",
       "      <td>0.0333967</td>\n",
       "      <td>0.0371149</td>\n",
       "      <td>0.51129</td>\n",
       "      <td>0.0114686</td>\n",
       "      <td>0.0099514</td>\n",
       "      <td>0.0109783</td>\n",
       "      <td>0.0115071</td>\n",
       "      <td>0.0141219</td>\n",
       "      <td>0.0113552</td>\n",
       "      <td>0.0107738</td>\n",
       "      <td>0.00866957</td>\n",
       "      <td>0.0119676</td>\n",
       "      <td>0.0162487</td>\n",
       "      <td>0.0152688</td>\n",
       "      <td>0.0121399</td>\n",
       "      <td>0.0132773</td>\n",
       "      <td>0.00845895</td>\n",
       "      <td>0.00883474</td>\n",
       "      <td>0.0116817</td>\n",
       "      <td>0.0122523</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.01385</td>\n",
       "      <td>0.00917768</td>\n",
       "      <td>0.0101625</td>\n",
       "      <td>0.0134258</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.0428481</td>\n",
       "      <td>0.0495638</td>\n",
       "      <td>0.00837646</td>\n",
       "      <td>0.0145412</td>\n",
       "      <td>0.00888281</td>\n",
       "      <td>0.0142863</td>\n",
       "      <td>0.0151299</td>\n",
       "      <td>0.00847254</td>\n",
       "      <td>0.00833464</td>\n",
       "      <td>0.0109859</td>\n",
       "      <td>0.0112264</td>\n",
       "      <td>0.0110484</td>\n",
       "      <td>0.0101967</td>\n",
       "      <td>0.00857086</td>\n",
       "      <td>0.0108459</td>\n",
       "      <td>0.00839977</td>\n",
       "      <td>0.0118126</td>\n",
       "      <td>0.00886354</td>\n",
       "      <td>0.00835123</td>\n",
       "      <td>0.0128046</td>\n",
       "      <td>0.0105841</td>\n",
       "      <td>0.00911298</td>\n",
       "      <td>0.0085598</td>\n",
       "      <td>0.00839963</td>\n",
       "      <td>0.00909395</td>\n",
       "      <td>0.0168963</td>\n",
       "      <td>0.00849075</td>\n",
       "      <td>0.143621</td>\n",
       "      <td>0.141371</td>\n",
       "      <td>0.364592</td>\n",
       "      <td>0.706352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.00162684</td>\n",
       "      <td>0.00880086</td>\n",
       "      <td>0.00181852</td>\n",
       "      <td>0.00550594</td>\n",
       "      <td>0.000293296</td>\n",
       "      <td>0.00689355</td>\n",
       "      <td>0.00048151</td>\n",
       "      <td>0.000469374</td>\n",
       "      <td>0.00264173</td>\n",
       "      <td>0.0137515</td>\n",
       "      <td>0.00183719</td>\n",
       "      <td>0.00535225</td>\n",
       "      <td>0.0258486</td>\n",
       "      <td>0.00879387</td>\n",
       "      <td>0.0231138</td>\n",
       "      <td>0.0107716</td>\n",
       "      <td>0.0053571</td>\n",
       "      <td>0.00952521</td>\n",
       "      <td>0.435908</td>\n",
       "      <td>0.407533</td>\n",
       "      <td>0.192384</td>\n",
       "      <td>0.340457</td>\n",
       "      <td>0.176659</td>\n",
       "      <td>0.428783</td>\n",
       "      <td>0.413085</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.0475813</td>\n",
       "      <td>0.0314261</td>\n",
       "      <td>0.0596602</td>\n",
       "      <td>0.171229</td>\n",
       "      <td>0.164686</td>\n",
       "      <td>0.111283</td>\n",
       "      <td>0.134538</td>\n",
       "      <td>0.149595</td>\n",
       "      <td>0.0245847</td>\n",
       "      <td>0.128061</td>\n",
       "      <td>0.120773</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.0327956</td>\n",
       "      <td>0.0439848</td>\n",
       "      <td>0.0559463</td>\n",
       "      <td>0.154638</td>\n",
       "      <td>3.53656</td>\n",
       "      <td>15.5897</td>\n",
       "      <td>8.63987</td>\n",
       "      <td>3.27656</td>\n",
       "      <td>20.0378</td>\n",
       "      <td>2.02172</td>\n",
       "      <td>8.64163</td>\n",
       "      <td>4.65092</td>\n",
       "      <td>0.00194577</td>\n",
       "      <td>0.000232715</td>\n",
       "      <td>0.00142636</td>\n",
       "      <td>0.000176837</td>\n",
       "      <td>0.00275842</td>\n",
       "      <td>0.00515297</td>\n",
       "      <td>0.0036547</td>\n",
       "      <td>0.000704902</td>\n",
       "      <td>0.00346891</td>\n",
       "      <td>0.0136564</td>\n",
       "      <td>0.000800545</td>\n",
       "      <td>0.000565562</td>\n",
       "      <td>0.00356275</td>\n",
       "      <td>0.00410219</td>\n",
       "      <td>0.0464602</td>\n",
       "      <td>0.00180258</td>\n",
       "      <td>0.00106359</td>\n",
       "      <td>0.000220194</td>\n",
       "      <td>0.00119505</td>\n",
       "      <td>0.0015622</td>\n",
       "      <td>0.00099134</td>\n",
       "      <td>0.000246801</td>\n",
       "      <td>0.000250648</td>\n",
       "      <td>0.000357338</td>\n",
       "      <td>0.00175414</td>\n",
       "      <td>0.00392153</td>\n",
       "      <td>0.000787357</td>\n",
       "      <td>0.00214403</td>\n",
       "      <td>0.000104217</td>\n",
       "      <td>0.000285163</td>\n",
       "      <td>0.000408853</td>\n",
       "      <td>0.00114588</td>\n",
       "      <td>0.00865037</td>\n",
       "      <td>0.00215134</td>\n",
       "      <td>0.00117965</td>\n",
       "      <td>0.00216352</td>\n",
       "      <td>0.00288659</td>\n",
       "      <td>0.00155402</td>\n",
       "      <td>0.00470855</td>\n",
       "      <td>0.00782124</td>\n",
       "      <td>0.0124921</td>\n",
       "      <td>0.000181587</td>\n",
       "      <td>0.00155143</td>\n",
       "      <td>0.000505284</td>\n",
       "      <td>0.000651284</td>\n",
       "      <td>0.00342157</td>\n",
       "      <td>0.000403908</td>\n",
       "      <td>0.000106425</td>\n",
       "      <td>0.0034197</td>\n",
       "      <td>0.000684137</td>\n",
       "      <td>0.00213602</td>\n",
       "      <td>0.00217883</td>\n",
       "      <td>0.000165773</td>\n",
       "      <td>0.000330153</td>\n",
       "      <td>0.000168023</td>\n",
       "      <td>0.00334896</td>\n",
       "      <td>0.000395659</td>\n",
       "      <td>8.77985e-05</td>\n",
       "      <td>0.0020431</td>\n",
       "      <td>0.00132833</td>\n",
       "      <td>0.0004131</td>\n",
       "      <td>0.000127599</td>\n",
       "      <td>0.000141278</td>\n",
       "      <td>0.000576284</td>\n",
       "      <td>0.00259944</td>\n",
       "      <td>0.000311575</td>\n",
       "      <td>0.0207257</td>\n",
       "      <td>0.0258662</td>\n",
       "      <td>0.118821</td>\n",
       "      <td>0.17158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00177584</td>\n",
       "      <td>0.00300021</td>\n",
       "      <td>0.00182071</td>\n",
       "      <td>0.00292106</td>\n",
       "      <td>0.00185747</td>\n",
       "      <td>0.00229383</td>\n",
       "      <td>0.00188818</td>\n",
       "      <td>0.00183873</td>\n",
       "      <td>0.00288639</td>\n",
       "      <td>0.00280948</td>\n",
       "      <td>0.0014657</td>\n",
       "      <td>0.00132537</td>\n",
       "      <td>0.00186453</td>\n",
       "      <td>0.00157914</td>\n",
       "      <td>0.00148621</td>\n",
       "      <td>0.00129399</td>\n",
       "      <td>0.00143094</td>\n",
       "      <td>0.00147929</td>\n",
       "      <td>0.00128617</td>\n",
       "      <td>0.00155287</td>\n",
       "      <td>0.0013279</td>\n",
       "      <td>0.0012856</td>\n",
       "      <td>0.00125957</td>\n",
       "      <td>0.00127721</td>\n",
       "      <td>0.00132594</td>\n",
       "      <td>0.00133123</td>\n",
       "      <td>0.00145121</td>\n",
       "      <td>0.00152264</td>\n",
       "      <td>0.00151711</td>\n",
       "      <td>0.00129013</td>\n",
       "      <td>0.00151057</td>\n",
       "      <td>0.00155487</td>\n",
       "      <td>0.0030632</td>\n",
       "      <td>0.00154591</td>\n",
       "      <td>0.00288935</td>\n",
       "      <td>0.00131021</td>\n",
       "      <td>0.00163736</td>\n",
       "      <td>0.00123806</td>\n",
       "      <td>0.00133476</td>\n",
       "      <td>0.00162663</td>\n",
       "      <td>0.00154366</td>\n",
       "      <td>0.0014246</td>\n",
       "      <td>0.0013875</td>\n",
       "      <td>0.0014225</td>\n",
       "      <td>0.00158963</td>\n",
       "      <td>0.00132098</td>\n",
       "      <td>0.00238028</td>\n",
       "      <td>0.00254021</td>\n",
       "      <td>0.00179257</td>\n",
       "      <td>0.0016665</td>\n",
       "      <td>0.00220566</td>\n",
       "      <td>0.00191956</td>\n",
       "      <td>0.00307374</td>\n",
       "      <td>0.00194988</td>\n",
       "      <td>0.00201116</td>\n",
       "      <td>0.00215025</td>\n",
       "      <td>0.00312042</td>\n",
       "      <td>0.00192485</td>\n",
       "      <td>0.00217791</td>\n",
       "      <td>0.00569782</td>\n",
       "      <td>0.00210361</td>\n",
       "      <td>0.00139203</td>\n",
       "      <td>0.0021246</td>\n",
       "      <td>0.00211377</td>\n",
       "      <td>0.00201344</td>\n",
       "      <td>0.00162678</td>\n",
       "      <td>0.00189443</td>\n",
       "      <td>0.00212893</td>\n",
       "      <td>0.0020956</td>\n",
       "      <td>0.00290451</td>\n",
       "      <td>0.00211339</td>\n",
       "      <td>0.00206981</td>\n",
       "      <td>0.00160341</td>\n",
       "      <td>0.0024282</td>\n",
       "      <td>0.00497398</td>\n",
       "      <td>0.00273275</td>\n",
       "      <td>0.00272908</td>\n",
       "      <td>0.00229859</td>\n",
       "      <td>0.00159845</td>\n",
       "      <td>0.00168376</td>\n",
       "      <td>0.0021924</td>\n",
       "      <td>0.00217552</td>\n",
       "      <td>0.00398846</td>\n",
       "      <td>0.00286012</td>\n",
       "      <td>0.00159574</td>\n",
       "      <td>0.00189486</td>\n",
       "      <td>0.00260062</td>\n",
       "      <td>0.00247021</td>\n",
       "      <td>0.00351958</td>\n",
       "      <td>0.00162797</td>\n",
       "      <td>0.00159678</td>\n",
       "      <td>0.00158491</td>\n",
       "      <td>0.00316119</td>\n",
       "      <td>0.0017004</td>\n",
       "      <td>0.00346417</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.00159245</td>\n",
       "      <td>0.00157757</td>\n",
       "      <td>0.00390654</td>\n",
       "      <td>0.0024384</td>\n",
       "      <td>0.00206017</td>\n",
       "      <td>0.00230145</td>\n",
       "      <td>0.00188346</td>\n",
       "      <td>0.00207701</td>\n",
       "      <td>0.00159464</td>\n",
       "      <td>0.00196414</td>\n",
       "      <td>0.0016973</td>\n",
       "      <td>0.00159059</td>\n",
       "      <td>0.00334668</td>\n",
       "      <td>0.00223112</td>\n",
       "      <td>0.00195694</td>\n",
       "      <td>0.00181146</td>\n",
       "      <td>0.00161595</td>\n",
       "      <td>0.00198531</td>\n",
       "      <td>0.00298128</td>\n",
       "      <td>0.00160985</td>\n",
       "      <td>0.00168018</td>\n",
       "      <td>0.00156803</td>\n",
       "      <td>0.00166545</td>\n",
       "      <td>0.00214963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>3.39013e-05</td>\n",
       "      <td>0.000767738</td>\n",
       "      <td>2.93925e-05</td>\n",
       "      <td>0.000759495</td>\n",
       "      <td>0.000106333</td>\n",
       "      <td>0.000583291</td>\n",
       "      <td>3.58446e-05</td>\n",
       "      <td>4.68861e-05</td>\n",
       "      <td>0.000738247</td>\n",
       "      <td>0.000759274</td>\n",
       "      <td>0.000258409</td>\n",
       "      <td>3.88097e-05</td>\n",
       "      <td>0.000886416</td>\n",
       "      <td>0.000505305</td>\n",
       "      <td>0.000114694</td>\n",
       "      <td>5.59569e-05</td>\n",
       "      <td>0.000360204</td>\n",
       "      <td>0.000387979</td>\n",
       "      <td>3.93882e-05</td>\n",
       "      <td>0.000537116</td>\n",
       "      <td>7.67981e-05</td>\n",
       "      <td>6.15545e-06</td>\n",
       "      <td>5.40181e-05</td>\n",
       "      <td>2.02012e-05</td>\n",
       "      <td>0.000116465</td>\n",
       "      <td>5.04314e-05</td>\n",
       "      <td>0.000407121</td>\n",
       "      <td>0.00039012</td>\n",
       "      <td>0.000493674</td>\n",
       "      <td>6.77779e-05</td>\n",
       "      <td>0.000363397</td>\n",
       "      <td>0.000573748</td>\n",
       "      <td>0.00345975</td>\n",
       "      <td>0.000350249</td>\n",
       "      <td>0.0017992</td>\n",
       "      <td>8.64011e-05</td>\n",
       "      <td>0.000569647</td>\n",
       "      <td>4.47383e-05</td>\n",
       "      <td>8.8522e-05</td>\n",
       "      <td>2.58737e-05</td>\n",
       "      <td>0.000149913</td>\n",
       "      <td>0.000210653</td>\n",
       "      <td>0.000214218</td>\n",
       "      <td>0.000216009</td>\n",
       "      <td>0.000588735</td>\n",
       "      <td>6.19955e-05</td>\n",
       "      <td>0.00218637</td>\n",
       "      <td>0.00191665</td>\n",
       "      <td>0.000299617</td>\n",
       "      <td>0.000438401</td>\n",
       "      <td>0.000520825</td>\n",
       "      <td>6.84391e-05</td>\n",
       "      <td>0.00109435</td>\n",
       "      <td>7.93104e-05</td>\n",
       "      <td>0.000111726</td>\n",
       "      <td>0.000371346</td>\n",
       "      <td>0.00142066</td>\n",
       "      <td>0.000231268</td>\n",
       "      <td>0.000334487</td>\n",
       "      <td>0.00240317</td>\n",
       "      <td>0.000293451</td>\n",
       "      <td>1.47508e-05</td>\n",
       "      <td>0.000206216</td>\n",
       "      <td>0.000244468</td>\n",
       "      <td>4.90927e-05</td>\n",
       "      <td>5.12265e-05</td>\n",
       "      <td>0.000415294</td>\n",
       "      <td>5.49828e-05</td>\n",
       "      <td>6.48994e-05</td>\n",
       "      <td>0.000466074</td>\n",
       "      <td>1.97064e-05</td>\n",
       "      <td>2.55936e-05</td>\n",
       "      <td>4.90256e-05</td>\n",
       "      <td>0.000226417</td>\n",
       "      <td>0.00128642</td>\n",
       "      <td>0.000575175</td>\n",
       "      <td>0.000831464</td>\n",
       "      <td>8.67696e-05</td>\n",
       "      <td>2.08785e-05</td>\n",
       "      <td>5.65076e-05</td>\n",
       "      <td>5.31877e-05</td>\n",
       "      <td>5.44387e-05</td>\n",
       "      <td>0.00165318</td>\n",
       "      <td>0.000653895</td>\n",
       "      <td>3.30813e-05</td>\n",
       "      <td>0.000311928</td>\n",
       "      <td>0.00058165</td>\n",
       "      <td>0.000341341</td>\n",
       "      <td>0.00120278</td>\n",
       "      <td>0.000174497</td>\n",
       "      <td>8.67851e-05</td>\n",
       "      <td>5.68614e-05</td>\n",
       "      <td>0.00149598</td>\n",
       "      <td>5.49529e-05</td>\n",
       "      <td>0.00168479</td>\n",
       "      <td>0.000389369</td>\n",
       "      <td>3.46098e-05</td>\n",
       "      <td>2.15187e-05</td>\n",
       "      <td>0.00364171</td>\n",
       "      <td>0.000494879</td>\n",
       "      <td>0.000268947</td>\n",
       "      <td>0.000592842</td>\n",
       "      <td>0.000140314</td>\n",
       "      <td>2.88944e-05</td>\n",
       "      <td>1.54863e-05</td>\n",
       "      <td>0.000484639</td>\n",
       "      <td>7.18644e-05</td>\n",
       "      <td>2.69126e-05</td>\n",
       "      <td>0.00138545</td>\n",
       "      <td>0.000390192</td>\n",
       "      <td>0.000271321</td>\n",
       "      <td>0.000109793</td>\n",
       "      <td>4.13576e-05</td>\n",
       "      <td>0.000522479</td>\n",
       "      <td>0.000623668</td>\n",
       "      <td>6.21038e-05</td>\n",
       "      <td>7.4256e-05</td>\n",
       "      <td>0.000104581</td>\n",
       "      <td>7.56543e-05</td>\n",
       "      <td>0.000474724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_gamma</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_kernel</th>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>rbf</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "      <td>poly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-06, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-07, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-08, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-05, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-08, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-05, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-07, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-06, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-08, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-07, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-06, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-07, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-06, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-08, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-08, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-07, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-05, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-06, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'linear'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-07, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-08, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-08, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-07, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-08, 'kernel': 'rbf'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-05, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-05, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-06, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-05, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-06, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-06, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-06, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-07, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-06, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-07, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-07, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-07, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-07, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-08, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-08, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1, 'gamma': 1e-08, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-08, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-08, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.764077</td>\n",
       "      <td>0.725563</td>\n",
       "      <td>0.725563</td>\n",
       "      <td>0.731033</td>\n",
       "      <td>0.654005</td>\n",
       "      <td>0.702677</td>\n",
       "      <td>0.702677</td>\n",
       "      <td>0.699571</td>\n",
       "      <td>0.699717</td>\n",
       "      <td>0.820067</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710274</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710335</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>0.601747</td>\n",
       "      <td>0.601704</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>0.588835</td>\n",
       "      <td>0.872598</td>\n",
       "      <td>0.739859</td>\n",
       "      <td>0.739859</td>\n",
       "      <td>0.435204</td>\n",
       "      <td>0.435204</td>\n",
       "      <td>0.355729</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.428705</td>\n",
       "      <td>0.428349</td>\n",
       "      <td>0.789621</td>\n",
       "      <td>0.462861</td>\n",
       "      <td>0.462871</td>\n",
       "      <td>0.209262</td>\n",
       "      <td>0.20929</td>\n",
       "      <td>0.209252</td>\n",
       "      <td>0.209252</td>\n",
       "      <td>0.207828</td>\n",
       "      <td>0.0224603</td>\n",
       "      <td>-0.0406104</td>\n",
       "      <td>-0.0406615</td>\n",
       "      <td>-0.0406615</td>\n",
       "      <td>-0.0406738</td>\n",
       "      <td>-0.040687</td>\n",
       "      <td>-0.0646869</td>\n",
       "      <td>-0.0646869</td>\n",
       "      <td>-0.0711034</td>\n",
       "      <td>-0.0710787</td>\n",
       "      <td>-0.0710787</td>\n",
       "      <td>-0.0710784</td>\n",
       "      <td>-0.0741832</td>\n",
       "      <td>-0.0741832</td>\n",
       "      <td>-0.0748417</td>\n",
       "      <td>-0.0748417</td>\n",
       "      <td>-0.0748393</td>\n",
       "      <td>0.207179</td>\n",
       "      <td>0.207236</td>\n",
       "      <td>-0.0751064</td>\n",
       "      <td>-0.0751722</td>\n",
       "      <td>-0.0751987</td>\n",
       "      <td>-0.0751987</td>\n",
       "      <td>-0.0752079</td>\n",
       "      <td>-0.0752079</td>\n",
       "      <td>-0.0752089</td>\n",
       "      <td>-0.0752089</td>\n",
       "      <td>-0.0752089</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.626207</td>\n",
       "      <td>-0.626207</td>\n",
       "      <td>-5.51296</td>\n",
       "      <td>-9.85748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.66988</td>\n",
       "      <td>0.700224</td>\n",
       "      <td>0.670786</td>\n",
       "      <td>0.670786</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.658089</td>\n",
       "      <td>0.536616</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.658016</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.65812</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.658116</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.624256</td>\n",
       "      <td>0.624133</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0.626915</td>\n",
       "      <td>0.21817</td>\n",
       "      <td>0.506188</td>\n",
       "      <td>0.506188</td>\n",
       "      <td>0.609772</td>\n",
       "      <td>0.609772</td>\n",
       "      <td>0.639574</td>\n",
       "      <td>0.381934</td>\n",
       "      <td>0.565684</td>\n",
       "      <td>0.547433</td>\n",
       "      <td>0.127063</td>\n",
       "      <td>0.406009</td>\n",
       "      <td>0.406009</td>\n",
       "      <td>0.307656</td>\n",
       "      <td>0.307486</td>\n",
       "      <td>0.30733</td>\n",
       "      <td>0.30733</td>\n",
       "      <td>0.306075</td>\n",
       "      <td>0.0637379</td>\n",
       "      <td>0.0185972</td>\n",
       "      <td>0.0187665</td>\n",
       "      <td>0.0187665</td>\n",
       "      <td>0.0187646</td>\n",
       "      <td>0.0187454</td>\n",
       "      <td>-0.0148211</td>\n",
       "      <td>-0.0148211</td>\n",
       "      <td>-0.018419</td>\n",
       "      <td>-0.0184238</td>\n",
       "      <td>-0.0184238</td>\n",
       "      <td>-0.0184247</td>\n",
       "      <td>-0.0224651</td>\n",
       "      <td>-0.0224651</td>\n",
       "      <td>-0.022919</td>\n",
       "      <td>-0.022919</td>\n",
       "      <td>-0.0229194</td>\n",
       "      <td>0.199718</td>\n",
       "      <td>0.199733</td>\n",
       "      <td>-0.0233246</td>\n",
       "      <td>-0.02337</td>\n",
       "      <td>-0.0234106</td>\n",
       "      <td>-0.0234106</td>\n",
       "      <td>-0.0234192</td>\n",
       "      <td>-0.0234192</td>\n",
       "      <td>-0.02342</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.0234201</td>\n",
       "      <td>-0.497896</td>\n",
       "      <td>-0.497896</td>\n",
       "      <td>-2.51479</td>\n",
       "      <td>-3.24265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.678289</td>\n",
       "      <td>0.679679</td>\n",
       "      <td>0.679679</td>\n",
       "      <td>0.645728</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.642162</td>\n",
       "      <td>0.642162</td>\n",
       "      <td>0.626811</td>\n",
       "      <td>0.625292</td>\n",
       "      <td>0.581822</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606409</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.606209</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.604796</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.602269</td>\n",
       "      <td>0.609495</td>\n",
       "      <td>0.60952</td>\n",
       "      <td>0.610046</td>\n",
       "      <td>0.610046</td>\n",
       "      <td>0.615747</td>\n",
       "      <td>0.428369</td>\n",
       "      <td>0.327066</td>\n",
       "      <td>0.327066</td>\n",
       "      <td>0.53228</td>\n",
       "      <td>0.53228</td>\n",
       "      <td>0.584508</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.505444</td>\n",
       "      <td>0.505444</td>\n",
       "      <td>0.103674</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.236579</td>\n",
       "      <td>0.318283</td>\n",
       "      <td>0.318587</td>\n",
       "      <td>0.318505</td>\n",
       "      <td>0.318505</td>\n",
       "      <td>0.317609</td>\n",
       "      <td>0.0248847</td>\n",
       "      <td>0.00850148</td>\n",
       "      <td>0.00858414</td>\n",
       "      <td>0.00858414</td>\n",
       "      <td>0.0086102</td>\n",
       "      <td>0.00856116</td>\n",
       "      <td>-0.0333825</td>\n",
       "      <td>-0.0333825</td>\n",
       "      <td>-0.0358528</td>\n",
       "      <td>-0.0358706</td>\n",
       "      <td>-0.0358706</td>\n",
       "      <td>-0.0358714</td>\n",
       "      <td>-0.0396589</td>\n",
       "      <td>-0.0396589</td>\n",
       "      <td>-0.0399328</td>\n",
       "      <td>-0.0399328</td>\n",
       "      <td>-0.0399346</td>\n",
       "      <td>-0.665647</td>\n",
       "      <td>-0.665923</td>\n",
       "      <td>-0.040279</td>\n",
       "      <td>-0.0403064</td>\n",
       "      <td>-0.0403411</td>\n",
       "      <td>-0.0403411</td>\n",
       "      <td>-0.0403473</td>\n",
       "      <td>-0.0403473</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-0.0403479</td>\n",
       "      <td>-8.22031</td>\n",
       "      <td>-8.22031</td>\n",
       "      <td>-6.71273</td>\n",
       "      <td>-27.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.741328</td>\n",
       "      <td>0.753137</td>\n",
       "      <td>0.753137</td>\n",
       "      <td>0.765266</td>\n",
       "      <td>0.77787</td>\n",
       "      <td>0.766054</td>\n",
       "      <td>0.766054</td>\n",
       "      <td>0.766862</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.674953</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.76225</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762069</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.762241</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.760589</td>\n",
       "      <td>0.688221</td>\n",
       "      <td>0.688124</td>\n",
       "      <td>0.687887</td>\n",
       "      <td>0.687887</td>\n",
       "      <td>0.685008</td>\n",
       "      <td>0.651112</td>\n",
       "      <td>0.540821</td>\n",
       "      <td>0.540821</td>\n",
       "      <td>0.670794</td>\n",
       "      <td>0.670794</td>\n",
       "      <td>0.664282</td>\n",
       "      <td>0.684936</td>\n",
       "      <td>0.60629</td>\n",
       "      <td>0.614475</td>\n",
       "      <td>0.557753</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.358749</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.286178</td>\n",
       "      <td>0.286017</td>\n",
       "      <td>0.286017</td>\n",
       "      <td>0.28462</td>\n",
       "      <td>0.0123317</td>\n",
       "      <td>-0.038756</td>\n",
       "      <td>-0.0388902</td>\n",
       "      <td>-0.0388902</td>\n",
       "      <td>-0.0389045</td>\n",
       "      <td>-0.0389132</td>\n",
       "      <td>-0.0730773</td>\n",
       "      <td>-0.0730773</td>\n",
       "      <td>-0.0799358</td>\n",
       "      <td>-0.0799505</td>\n",
       "      <td>-0.0799505</td>\n",
       "      <td>-0.0799506</td>\n",
       "      <td>-0.0825685</td>\n",
       "      <td>-0.0825685</td>\n",
       "      <td>-0.0832376</td>\n",
       "      <td>-0.0832376</td>\n",
       "      <td>-0.0832391</td>\n",
       "      <td>0.437063</td>\n",
       "      <td>0.436967</td>\n",
       "      <td>-0.0835398</td>\n",
       "      <td>-0.0836068</td>\n",
       "      <td>-0.0836371</td>\n",
       "      <td>-0.0836371</td>\n",
       "      <td>-0.0836468</td>\n",
       "      <td>-0.0836468</td>\n",
       "      <td>-0.0836477</td>\n",
       "      <td>-0.0836478</td>\n",
       "      <td>-0.0836478</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.0836479</td>\n",
       "      <td>-0.412972</td>\n",
       "      <td>-0.412972</td>\n",
       "      <td>-2.72908</td>\n",
       "      <td>-4.68435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.598728</td>\n",
       "      <td>0.63196</td>\n",
       "      <td>0.63196</td>\n",
       "      <td>0.565813</td>\n",
       "      <td>0.549902</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.540194</td>\n",
       "      <td>0.537911</td>\n",
       "      <td>0.659863</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535892</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535548</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.535585</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.488625</td>\n",
       "      <td>0.488596</td>\n",
       "      <td>0.487511</td>\n",
       "      <td>0.487511</td>\n",
       "      <td>0.480609</td>\n",
       "      <td>0.650916</td>\n",
       "      <td>0.61718</td>\n",
       "      <td>0.61718</td>\n",
       "      <td>0.390332</td>\n",
       "      <td>0.390332</td>\n",
       "      <td>0.38628</td>\n",
       "      <td>0.589428</td>\n",
       "      <td>0.364684</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.465256</td>\n",
       "      <td>0.446391</td>\n",
       "      <td>0.446391</td>\n",
       "      <td>0.187067</td>\n",
       "      <td>0.186997</td>\n",
       "      <td>0.187002</td>\n",
       "      <td>0.187002</td>\n",
       "      <td>0.185961</td>\n",
       "      <td>0.0709321</td>\n",
       "      <td>0.00471727</td>\n",
       "      <td>0.00464025</td>\n",
       "      <td>0.00464025</td>\n",
       "      <td>0.00464004</td>\n",
       "      <td>0.00462365</td>\n",
       "      <td>-0.0120532</td>\n",
       "      <td>-0.0120532</td>\n",
       "      <td>-0.0187114</td>\n",
       "      <td>-0.0187188</td>\n",
       "      <td>-0.0187188</td>\n",
       "      <td>-0.018719</td>\n",
       "      <td>-0.0207454</td>\n",
       "      <td>-0.0207454</td>\n",
       "      <td>-0.0214321</td>\n",
       "      <td>-0.0214321</td>\n",
       "      <td>-0.0214328</td>\n",
       "      <td>-0.420811</td>\n",
       "      <td>-0.420997</td>\n",
       "      <td>-0.0216359</td>\n",
       "      <td>-0.0217046</td>\n",
       "      <td>-0.021725</td>\n",
       "      <td>-0.021725</td>\n",
       "      <td>-0.0217339</td>\n",
       "      <td>-0.0217339</td>\n",
       "      <td>-0.0217348</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-0.0217349</td>\n",
       "      <td>-4.3544</td>\n",
       "      <td>-4.3544</td>\n",
       "      <td>-3.62766</td>\n",
       "      <td>-11.7236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.676896</td>\n",
       "      <td>0.676896</td>\n",
       "      <td>0.675544</td>\n",
       "      <td>0.669484</td>\n",
       "      <td>0.666812</td>\n",
       "      <td>0.666812</td>\n",
       "      <td>0.658714</td>\n",
       "      <td>0.657227</td>\n",
       "      <td>0.654664</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.653478</td>\n",
       "      <td>0.602469</td>\n",
       "      <td>0.602416</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>0.599423</td>\n",
       "      <td>0.564233</td>\n",
       "      <td>0.546223</td>\n",
       "      <td>0.546223</td>\n",
       "      <td>0.527676</td>\n",
       "      <td>0.527676</td>\n",
       "      <td>0.526075</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.494161</td>\n",
       "      <td>0.491516</td>\n",
       "      <td>0.408673</td>\n",
       "      <td>0.382129</td>\n",
       "      <td>0.38212</td>\n",
       "      <td>0.261744</td>\n",
       "      <td>0.261708</td>\n",
       "      <td>0.261621</td>\n",
       "      <td>0.261621</td>\n",
       "      <td>0.260419</td>\n",
       "      <td>0.0388694</td>\n",
       "      <td>-0.0095101</td>\n",
       "      <td>-0.00951217</td>\n",
       "      <td>-0.00951217</td>\n",
       "      <td>-0.0095127</td>\n",
       "      <td>-0.00953401</td>\n",
       "      <td>-0.0396042</td>\n",
       "      <td>-0.0396042</td>\n",
       "      <td>-0.0448045</td>\n",
       "      <td>-0.0448085</td>\n",
       "      <td>-0.0448085</td>\n",
       "      <td>-0.0448088</td>\n",
       "      <td>-0.0479242</td>\n",
       "      <td>-0.0479242</td>\n",
       "      <td>-0.0484726</td>\n",
       "      <td>-0.0484726</td>\n",
       "      <td>-0.0484731</td>\n",
       "      <td>-0.0484995</td>\n",
       "      <td>-0.0485968</td>\n",
       "      <td>-0.0487771</td>\n",
       "      <td>-0.048832</td>\n",
       "      <td>-0.0488625</td>\n",
       "      <td>-0.0488625</td>\n",
       "      <td>-0.048871</td>\n",
       "      <td>-0.048871</td>\n",
       "      <td>-0.0488719</td>\n",
       "      <td>-0.0488719</td>\n",
       "      <td>-0.0488719</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-0.048872</td>\n",
       "      <td>-2.82236</td>\n",
       "      <td>-2.82236</td>\n",
       "      <td>-4.21945</td>\n",
       "      <td>-11.4617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0573936</td>\n",
       "      <td>0.0584059</td>\n",
       "      <td>0.0584059</td>\n",
       "      <td>0.0694134</td>\n",
       "      <td>0.0738222</td>\n",
       "      <td>0.0705028</td>\n",
       "      <td>0.0705028</td>\n",
       "      <td>0.0754083</td>\n",
       "      <td>0.0757683</td>\n",
       "      <td>0.0969927</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0788843</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0789603</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0791826</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0789093</td>\n",
       "      <td>0.0645575</td>\n",
       "      <td>0.0645347</td>\n",
       "      <td>0.0648895</td>\n",
       "      <td>0.0648895</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.222876</td>\n",
       "      <td>0.135788</td>\n",
       "      <td>0.135788</td>\n",
       "      <td>0.104554</td>\n",
       "      <td>0.104554</td>\n",
       "      <td>0.129582</td>\n",
       "      <td>0.203944</td>\n",
       "      <td>0.0881641</td>\n",
       "      <td>0.088584</td>\n",
       "      <td>0.261869</td>\n",
       "      <td>0.0811758</td>\n",
       "      <td>0.0811795</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.0534023</td>\n",
       "      <td>0.0533495</td>\n",
       "      <td>0.0533495</td>\n",
       "      <td>0.0533865</td>\n",
       "      <td>0.0237299</td>\n",
       "      <td>0.0250576</td>\n",
       "      <td>0.0251428</td>\n",
       "      <td>0.0251428</td>\n",
       "      <td>0.0251525</td>\n",
       "      <td>0.0251446</td>\n",
       "      <td>0.0251458</td>\n",
       "      <td>0.0251458</td>\n",
       "      <td>0.0260116</td>\n",
       "      <td>0.0260069</td>\n",
       "      <td>0.0260069</td>\n",
       "      <td>0.0260066</td>\n",
       "      <td>0.0258648</td>\n",
       "      <td>0.0258648</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.0259265</td>\n",
       "      <td>0.420057</td>\n",
       "      <td>0.420158</td>\n",
       "      <td>0.0259167</td>\n",
       "      <td>0.0259229</td>\n",
       "      <td>0.0259219</td>\n",
       "      <td>0.0259219</td>\n",
       "      <td>0.0259224</td>\n",
       "      <td>0.0259224</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>0.0259225</td>\n",
       "      <td>3.08274</td>\n",
       "      <td>3.08274</td>\n",
       "      <td>1.63505</td>\n",
       "      <td>8.75307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.715243</td>\n",
       "      <td>0.775019</td>\n",
       "      <td>0.775019</td>\n",
       "      <td>0.66813</td>\n",
       "      <td>0.692048</td>\n",
       "      <td>0.663595</td>\n",
       "      <td>0.663595</td>\n",
       "      <td>0.64982</td>\n",
       "      <td>0.648372</td>\n",
       "      <td>0.769791</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647353</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.647413</td>\n",
       "      <td>0.592227</td>\n",
       "      <td>0.592191</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>0.587692</td>\n",
       "      <td>0.910485</td>\n",
       "      <td>0.637966</td>\n",
       "      <td>0.637966</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.739797</td>\n",
       "      <td>0.869933</td>\n",
       "      <td>0.988381</td>\n",
       "      <td>0.99053</td>\n",
       "      <td>0.95171</td>\n",
       "      <td>0.399571</td>\n",
       "      <td>0.399578</td>\n",
       "      <td>0.247978</td>\n",
       "      <td>0.24801</td>\n",
       "      <td>0.24799</td>\n",
       "      <td>0.24799</td>\n",
       "      <td>0.246852</td>\n",
       "      <td>0.0781266</td>\n",
       "      <td>-0.00869535</td>\n",
       "      <td>-0.00869177</td>\n",
       "      <td>-0.00869177</td>\n",
       "      <td>-0.00875644</td>\n",
       "      <td>-0.00871477</td>\n",
       "      <td>-0.0271169</td>\n",
       "      <td>-0.0271169</td>\n",
       "      <td>-0.0418348</td>\n",
       "      <td>-0.0418113</td>\n",
       "      <td>-0.0418113</td>\n",
       "      <td>-0.041811</td>\n",
       "      <td>-0.0435839</td>\n",
       "      <td>-0.0435839</td>\n",
       "      <td>-0.0458417</td>\n",
       "      <td>-0.0458417</td>\n",
       "      <td>-0.0458394</td>\n",
       "      <td>0.936629</td>\n",
       "      <td>0.93663</td>\n",
       "      <td>-0.0459673</td>\n",
       "      <td>-0.0462016</td>\n",
       "      <td>-0.046214</td>\n",
       "      <td>-0.046214</td>\n",
       "      <td>-0.0462388</td>\n",
       "      <td>-0.0462388</td>\n",
       "      <td>-0.0462413</td>\n",
       "      <td>-0.0462415</td>\n",
       "      <td>-0.0462415</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>-0.0462416</td>\n",
       "      <td>0.971642</td>\n",
       "      <td>0.971642</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.990006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.763903</td>\n",
       "      <td>0.866066</td>\n",
       "      <td>0.866066</td>\n",
       "      <td>0.687997</td>\n",
       "      <td>0.697302</td>\n",
       "      <td>0.679726</td>\n",
       "      <td>0.679726</td>\n",
       "      <td>0.667884</td>\n",
       "      <td>0.666217</td>\n",
       "      <td>0.867117</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.66934</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669384</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.669211</td>\n",
       "      <td>0.585052</td>\n",
       "      <td>0.584999</td>\n",
       "      <td>0.585177</td>\n",
       "      <td>0.585177</td>\n",
       "      <td>0.58307</td>\n",
       "      <td>0.938649</td>\n",
       "      <td>0.728881</td>\n",
       "      <td>0.728881</td>\n",
       "      <td>0.980372</td>\n",
       "      <td>0.980372</td>\n",
       "      <td>0.67069</td>\n",
       "      <td>0.905785</td>\n",
       "      <td>0.991501</td>\n",
       "      <td>0.992085</td>\n",
       "      <td>0.96656</td>\n",
       "      <td>0.458646</td>\n",
       "      <td>0.458646</td>\n",
       "      <td>0.250188</td>\n",
       "      <td>0.250033</td>\n",
       "      <td>0.249858</td>\n",
       "      <td>0.249858</td>\n",
       "      <td>0.248389</td>\n",
       "      <td>0.0818926</td>\n",
       "      <td>-0.00320676</td>\n",
       "      <td>-0.00304668</td>\n",
       "      <td>-0.00304668</td>\n",
       "      <td>-0.00304825</td>\n",
       "      <td>-0.00306835</td>\n",
       "      <td>-0.0219565</td>\n",
       "      <td>-0.0219565</td>\n",
       "      <td>-0.034148</td>\n",
       "      <td>-0.0341527</td>\n",
       "      <td>-0.0341527</td>\n",
       "      <td>-0.0341536</td>\n",
       "      <td>-0.0360456</td>\n",
       "      <td>-0.0360456</td>\n",
       "      <td>-0.0379867</td>\n",
       "      <td>-0.0379867</td>\n",
       "      <td>-0.0379872</td>\n",
       "      <td>0.960848</td>\n",
       "      <td>0.960849</td>\n",
       "      <td>-0.0381701</td>\n",
       "      <td>-0.0383714</td>\n",
       "      <td>-0.0383896</td>\n",
       "      <td>-0.0383896</td>\n",
       "      <td>-0.0384117</td>\n",
       "      <td>-0.0384117</td>\n",
       "      <td>-0.0384139</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>-0.0384141</td>\n",
       "      <td>0.981128</td>\n",
       "      <td>0.981128</td>\n",
       "      <td>0.990888</td>\n",
       "      <td>0.991679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.759276</td>\n",
       "      <td>0.842586</td>\n",
       "      <td>0.842586</td>\n",
       "      <td>0.691274</td>\n",
       "      <td>0.683931</td>\n",
       "      <td>0.682745</td>\n",
       "      <td>0.682745</td>\n",
       "      <td>0.673328</td>\n",
       "      <td>0.671357</td>\n",
       "      <td>0.848154</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67664</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.67645</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.676509</td>\n",
       "      <td>0.605033</td>\n",
       "      <td>0.605019</td>\n",
       "      <td>0.604431</td>\n",
       "      <td>0.604431</td>\n",
       "      <td>0.599671</td>\n",
       "      <td>0.949865</td>\n",
       "      <td>0.735222</td>\n",
       "      <td>0.735222</td>\n",
       "      <td>0.986909</td>\n",
       "      <td>0.986909</td>\n",
       "      <td>0.68368</td>\n",
       "      <td>0.914233</td>\n",
       "      <td>0.992268</td>\n",
       "      <td>0.992268</td>\n",
       "      <td>0.969074</td>\n",
       "      <td>0.465686</td>\n",
       "      <td>0.465692</td>\n",
       "      <td>0.23653</td>\n",
       "      <td>0.236751</td>\n",
       "      <td>0.236633</td>\n",
       "      <td>0.236633</td>\n",
       "      <td>0.235399</td>\n",
       "      <td>0.0942315</td>\n",
       "      <td>-0.00945768</td>\n",
       "      <td>-0.00938972</td>\n",
       "      <td>-0.00938972</td>\n",
       "      <td>-0.00936795</td>\n",
       "      <td>-0.00941117</td>\n",
       "      <td>-0.0294688</td>\n",
       "      <td>-0.0294688</td>\n",
       "      <td>-0.0422564</td>\n",
       "      <td>-0.0422712</td>\n",
       "      <td>-0.0422712</td>\n",
       "      <td>-0.0422719</td>\n",
       "      <td>-0.0438874</td>\n",
       "      <td>-0.0438874</td>\n",
       "      <td>-0.0452058</td>\n",
       "      <td>-0.0452058</td>\n",
       "      <td>-0.0452074</td>\n",
       "      <td>0.959221</td>\n",
       "      <td>0.959221</td>\n",
       "      <td>-0.0453396</td>\n",
       "      <td>-0.0454716</td>\n",
       "      <td>-0.045485</td>\n",
       "      <td>-0.045485</td>\n",
       "      <td>-0.0454995</td>\n",
       "      <td>-0.0454995</td>\n",
       "      <td>-0.045501</td>\n",
       "      <td>-0.0455011</td>\n",
       "      <td>-0.0455011</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>-0.0455012</td>\n",
       "      <td>0.983774</td>\n",
       "      <td>0.983774</td>\n",
       "      <td>0.991283</td>\n",
       "      <td>0.99167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.758094</td>\n",
       "      <td>0.831826</td>\n",
       "      <td>0.831826</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.674691</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.636395</td>\n",
       "      <td>0.632124</td>\n",
       "      <td>0.832729</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.634906</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.634879</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.551188</td>\n",
       "      <td>0.551095</td>\n",
       "      <td>0.550408</td>\n",
       "      <td>0.550408</td>\n",
       "      <td>0.544759</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0.713349</td>\n",
       "      <td>0.713349</td>\n",
       "      <td>0.975678</td>\n",
       "      <td>0.975678</td>\n",
       "      <td>0.667803</td>\n",
       "      <td>0.895889</td>\n",
       "      <td>0.990185</td>\n",
       "      <td>0.99182</td>\n",
       "      <td>0.956054</td>\n",
       "      <td>0.461254</td>\n",
       "      <td>0.461202</td>\n",
       "      <td>0.237407</td>\n",
       "      <td>0.237231</td>\n",
       "      <td>0.237089</td>\n",
       "      <td>0.237089</td>\n",
       "      <td>0.235801</td>\n",
       "      <td>0.0706144</td>\n",
       "      <td>-0.00372862</td>\n",
       "      <td>-0.00380458</td>\n",
       "      <td>-0.00380458</td>\n",
       "      <td>-0.00381185</td>\n",
       "      <td>-0.00382536</td>\n",
       "      <td>-0.0224293</td>\n",
       "      <td>-0.0224293</td>\n",
       "      <td>-0.0351291</td>\n",
       "      <td>-0.0351372</td>\n",
       "      <td>-0.0351372</td>\n",
       "      <td>-0.0351374</td>\n",
       "      <td>-0.0359387</td>\n",
       "      <td>-0.0359387</td>\n",
       "      <td>-0.0378425</td>\n",
       "      <td>-0.0378425</td>\n",
       "      <td>-0.0378434</td>\n",
       "      <td>0.94876</td>\n",
       "      <td>0.948765</td>\n",
       "      <td>-0.0379382</td>\n",
       "      <td>-0.0381357</td>\n",
       "      <td>-0.0381452</td>\n",
       "      <td>-0.0381452</td>\n",
       "      <td>-0.038166</td>\n",
       "      <td>-0.038166</td>\n",
       "      <td>-0.0381681</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>-0.0381683</td>\n",
       "      <td>0.97268</td>\n",
       "      <td>0.97268</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.991217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.798158</td>\n",
       "      <td>0.857246</td>\n",
       "      <td>0.857246</td>\n",
       "      <td>0.745593</td>\n",
       "      <td>0.746399</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>0.715606</td>\n",
       "      <td>0.712869</td>\n",
       "      <td>0.868024</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.651844</td>\n",
       "      <td>0.651827</td>\n",
       "      <td>0.65145</td>\n",
       "      <td>0.65145</td>\n",
       "      <td>0.649127</td>\n",
       "      <td>0.921044</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.711785</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.763858</td>\n",
       "      <td>0.881388</td>\n",
       "      <td>0.989694</td>\n",
       "      <td>0.989842</td>\n",
       "      <td>0.962414</td>\n",
       "      <td>0.433699</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.271125</td>\n",
       "      <td>0.270998</td>\n",
       "      <td>0.271054</td>\n",
       "      <td>0.271054</td>\n",
       "      <td>0.269974</td>\n",
       "      <td>0.0537512</td>\n",
       "      <td>-0.00740829</td>\n",
       "      <td>-0.00754216</td>\n",
       "      <td>-0.00754216</td>\n",
       "      <td>-0.00754399</td>\n",
       "      <td>-0.00756198</td>\n",
       "      <td>-0.0333662</td>\n",
       "      <td>-0.0333662</td>\n",
       "      <td>-0.0434699</td>\n",
       "      <td>-0.0434851</td>\n",
       "      <td>-0.0434851</td>\n",
       "      <td>-0.0434854</td>\n",
       "      <td>-0.0459806</td>\n",
       "      <td>-0.0459806</td>\n",
       "      <td>-0.047834</td>\n",
       "      <td>-0.047834</td>\n",
       "      <td>-0.0478355</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>-0.0480769</td>\n",
       "      <td>-0.0482713</td>\n",
       "      <td>-0.0482955</td>\n",
       "      <td>-0.0482955</td>\n",
       "      <td>-0.0483174</td>\n",
       "      <td>-0.0483174</td>\n",
       "      <td>-0.0483196</td>\n",
       "      <td>-0.0483198</td>\n",
       "      <td>-0.0483198</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>-0.0483199</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>0.988829</td>\n",
       "      <td>0.989049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.758935</td>\n",
       "      <td>0.834549</td>\n",
       "      <td>0.834549</td>\n",
       "      <td>0.692505</td>\n",
       "      <td>0.698874</td>\n",
       "      <td>0.682835</td>\n",
       "      <td>0.682835</td>\n",
       "      <td>0.668607</td>\n",
       "      <td>0.666188</td>\n",
       "      <td>0.837163</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669534</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669561</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.669609</td>\n",
       "      <td>0.597069</td>\n",
       "      <td>0.597026</td>\n",
       "      <td>0.596637</td>\n",
       "      <td>0.596637</td>\n",
       "      <td>0.592864</td>\n",
       "      <td>0.930857</td>\n",
       "      <td>0.705441</td>\n",
       "      <td>0.705441</td>\n",
       "      <td>0.979178</td>\n",
       "      <td>0.979178</td>\n",
       "      <td>0.705166</td>\n",
       "      <td>0.893446</td>\n",
       "      <td>0.990406</td>\n",
       "      <td>0.991309</td>\n",
       "      <td>0.961162</td>\n",
       "      <td>0.443771</td>\n",
       "      <td>0.443763</td>\n",
       "      <td>0.248646</td>\n",
       "      <td>0.248604</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>0.247283</td>\n",
       "      <td>0.0757232</td>\n",
       "      <td>-0.00649934</td>\n",
       "      <td>-0.00649498</td>\n",
       "      <td>-0.00649498</td>\n",
       "      <td>-0.0065057</td>\n",
       "      <td>-0.00651633</td>\n",
       "      <td>-0.0268675</td>\n",
       "      <td>-0.0268675</td>\n",
       "      <td>-0.0393676</td>\n",
       "      <td>-0.0393715</td>\n",
       "      <td>-0.0393715</td>\n",
       "      <td>-0.0393719</td>\n",
       "      <td>-0.0410872</td>\n",
       "      <td>-0.0410872</td>\n",
       "      <td>-0.0429422</td>\n",
       "      <td>-0.0429422</td>\n",
       "      <td>-0.0429426</td>\n",
       "      <td>0.951215</td>\n",
       "      <td>0.951217</td>\n",
       "      <td>-0.0430984</td>\n",
       "      <td>-0.0432903</td>\n",
       "      <td>-0.0433059</td>\n",
       "      <td>-0.0433059</td>\n",
       "      <td>-0.0433267</td>\n",
       "      <td>-0.0433267</td>\n",
       "      <td>-0.0433288</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>-0.043329</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>0.978019</td>\n",
       "      <td>0.989894</td>\n",
       "      <td>0.990724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0263551</td>\n",
       "      <td>0.0320136</td>\n",
       "      <td>0.0320136</td>\n",
       "      <td>0.0281501</td>\n",
       "      <td>0.0249632</td>\n",
       "      <td>0.0271298</td>\n",
       "      <td>0.0271298</td>\n",
       "      <td>0.0269156</td>\n",
       "      <td>0.0271426</td>\n",
       "      <td>0.036136</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290906</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.0290557</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0289947</td>\n",
       "      <td>0.0326699</td>\n",
       "      <td>0.0326947</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>0.0336115</td>\n",
       "      <td>0.0137465</td>\n",
       "      <td>0.0349054</td>\n",
       "      <td>0.0349054</td>\n",
       "      <td>0.00526436</td>\n",
       "      <td>0.00526436</td>\n",
       "      <td>0.0392182</td>\n",
       "      <td>0.0160537</td>\n",
       "      <td>0.00136558</td>\n",
       "      <td>0.00095294</td>\n",
       "      <td>0.00646102</td>\n",
       "      <td>0.0247479</td>\n",
       "      <td>0.0247392</td>\n",
       "      <td>0.0124999</td>\n",
       "      <td>0.0124396</td>\n",
       "      <td>0.0125045</td>\n",
       "      <td>0.0125045</td>\n",
       "      <td>0.0125649</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>0.00256587</td>\n",
       "      <td>0.00258577</td>\n",
       "      <td>0.00258577</td>\n",
       "      <td>0.00259026</td>\n",
       "      <td>0.00258598</td>\n",
       "      <td>0.00430992</td>\n",
       "      <td>0.00430992</td>\n",
       "      <td>0.00391076</td>\n",
       "      <td>0.00391021</td>\n",
       "      <td>0.00391021</td>\n",
       "      <td>0.00391003</td>\n",
       "      <td>0.00424133</td>\n",
       "      <td>0.00424133</td>\n",
       "      <td>0.00419582</td>\n",
       "      <td>0.00419582</td>\n",
       "      <td>0.0041957</td>\n",
       "      <td>0.00867213</td>\n",
       "      <td>0.00867172</td>\n",
       "      <td>0.00421793</td>\n",
       "      <td>0.00421448</td>\n",
       "      <td>0.00421672</td>\n",
       "      <td>0.00421672</td>\n",
       "      <td>0.00421661</td>\n",
       "      <td>0.00421661</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.0042166</td>\n",
       "      <td>0.00490101</td>\n",
       "      <td>0.00490101</td>\n",
       "      <td>0.00119878</td>\n",
       "      <td>0.00103631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            87   \\\n",
       "mean_fit_time                                           0.02323   \n",
       "std_fit_time                                         0.00162684   \n",
       "mean_score_time                                      0.00177584   \n",
       "std_score_time                                      3.39013e-05   \n",
       "param_C                                                     100   \n",
       "param_gamma                                               0.001   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                      0.764077   \n",
       "split1_test_score                                      0.692847   \n",
       "split2_test_score                                      0.678289   \n",
       "split3_test_score                                      0.741328   \n",
       "split4_test_score                                      0.598728   \n",
       "mean_test_score                                        0.695054   \n",
       "std_test_score                                        0.0573936   \n",
       "rank_test_score                                               1   \n",
       "split0_train_score                                     0.715243   \n",
       "split1_train_score                                     0.763903   \n",
       "split2_train_score                                     0.759276   \n",
       "split3_train_score                                     0.758094   \n",
       "split4_train_score                                     0.798158   \n",
       "mean_train_score                                       0.758935   \n",
       "std_train_score                                       0.0263551   \n",
       "\n",
       "                                                          66   \\\n",
       "mean_fit_time                                        0.038862   \n",
       "std_fit_time                                       0.00880086   \n",
       "mean_score_time                                    0.00300021   \n",
       "std_score_time                                    0.000767738   \n",
       "param_C                                                    10   \n",
       "param_gamma                                              0.01   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "split0_test_score                                    0.725563   \n",
       "split1_test_score                                    0.594142   \n",
       "split2_test_score                                    0.679679   \n",
       "split3_test_score                                    0.753137   \n",
       "split4_test_score                                     0.63196   \n",
       "mean_test_score                                      0.676896   \n",
       "std_test_score                                      0.0584059   \n",
       "rank_test_score                                             2   \n",
       "split0_train_score                                   0.775019   \n",
       "split1_train_score                                   0.866066   \n",
       "split2_train_score                                   0.842586   \n",
       "split3_train_score                                   0.831826   \n",
       "split4_train_score                                   0.857246   \n",
       "mean_train_score                                     0.834549   \n",
       "std_train_score                                     0.0320136   \n",
       "\n",
       "                                                          42   \\\n",
       "mean_fit_time                                       0.0215946   \n",
       "std_fit_time                                       0.00181852   \n",
       "mean_score_time                                    0.00182071   \n",
       "std_score_time                                    2.93925e-05   \n",
       "param_C                                                    10   \n",
       "param_gamma                                              0.01   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "split0_test_score                                    0.725563   \n",
       "split1_test_score                                    0.594142   \n",
       "split2_test_score                                    0.679679   \n",
       "split3_test_score                                    0.753137   \n",
       "split4_test_score                                     0.63196   \n",
       "mean_test_score                                      0.676896   \n",
       "std_test_score                                      0.0584059   \n",
       "rank_test_score                                             2   \n",
       "split0_train_score                                   0.775019   \n",
       "split1_train_score                                   0.866066   \n",
       "split2_train_score                                   0.842586   \n",
       "split3_train_score                                   0.831826   \n",
       "split4_train_score                                   0.857246   \n",
       "mean_train_score                                     0.834549   \n",
       "std_train_score                                     0.0320136   \n",
       "\n",
       "                                                              108  \\\n",
       "mean_fit_time                                            0.030471   \n",
       "std_fit_time                                           0.00550594   \n",
       "mean_score_time                                        0.00292106   \n",
       "std_score_time                                        0.000759495   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                0.0001   \n",
       "param_kernel                                                  rbf   \n",
       "params              {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                        0.731033   \n",
       "split1_test_score                                         0.66988   \n",
       "split2_test_score                                        0.645728   \n",
       "split3_test_score                                        0.765266   \n",
       "split4_test_score                                        0.565813   \n",
       "mean_test_score                                          0.675544   \n",
       "std_test_score                                          0.0694134   \n",
       "rank_test_score                                                 4   \n",
       "split0_train_score                                        0.66813   \n",
       "split1_train_score                                       0.687997   \n",
       "split2_train_score                                       0.691274   \n",
       "split3_train_score                                        0.66953   \n",
       "split4_train_score                                       0.745593   \n",
       "mean_train_score                                         0.692505   \n",
       "std_train_score                                         0.0281501   \n",
       "\n",
       "                                                         18   \\\n",
       "mean_fit_time                                      0.0118427   \n",
       "std_fit_time                                     0.000293296   \n",
       "mean_score_time                                   0.00185747   \n",
       "std_score_time                                   0.000106333   \n",
       "param_C                                                    1   \n",
       "param_gamma                                             0.01   \n",
       "param_kernel                                             rbf   \n",
       "params              {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   0.654005   \n",
       "split1_test_score                                   0.700224   \n",
       "split2_test_score                                   0.665418   \n",
       "split3_test_score                                    0.77787   \n",
       "split4_test_score                                   0.549902   \n",
       "mean_test_score                                     0.669484   \n",
       "std_test_score                                     0.0738222   \n",
       "rank_test_score                                            5   \n",
       "split0_train_score                                  0.692048   \n",
       "split1_train_score                                  0.697302   \n",
       "split2_train_score                                  0.683931   \n",
       "split3_train_score                                  0.674691   \n",
       "split4_train_score                                  0.746399   \n",
       "mean_train_score                                    0.698874   \n",
       "std_train_score                                    0.0249632   \n",
       "\n",
       "                                                           63   \\\n",
       "mean_fit_time                                        0.0261116   \n",
       "std_fit_time                                        0.00689355   \n",
       "mean_score_time                                     0.00229383   \n",
       "std_score_time                                     0.000583291   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              0.001   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.702677   \n",
       "split1_test_score                                     0.670786   \n",
       "split2_test_score                                     0.642162   \n",
       "split3_test_score                                     0.766054   \n",
       "split4_test_score                                     0.552381   \n",
       "mean_test_score                                       0.666812   \n",
       "std_test_score                                       0.0705028   \n",
       "rank_test_score                                              6   \n",
       "split0_train_score                                    0.663595   \n",
       "split1_train_score                                    0.679726   \n",
       "split2_train_score                                    0.682745   \n",
       "split3_train_score                                    0.655013   \n",
       "split4_train_score                                    0.733096   \n",
       "mean_train_score                                      0.682835   \n",
       "std_train_score                                      0.0271298   \n",
       "\n",
       "                                                           39   \\\n",
       "mean_fit_time                                        0.0142592   \n",
       "std_fit_time                                        0.00048151   \n",
       "mean_score_time                                     0.00188818   \n",
       "std_score_time                                     3.58446e-05   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              0.001   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.702677   \n",
       "split1_test_score                                     0.670786   \n",
       "split2_test_score                                     0.642162   \n",
       "split3_test_score                                     0.766054   \n",
       "split4_test_score                                     0.552381   \n",
       "mean_test_score                                       0.666812   \n",
       "std_test_score                                       0.0705028   \n",
       "rank_test_score                                              6   \n",
       "split0_train_score                                    0.663595   \n",
       "split1_train_score                                    0.679726   \n",
       "split2_train_score                                    0.682745   \n",
       "split3_train_score                                    0.655013   \n",
       "split4_train_score                                    0.733096   \n",
       "mean_train_score                                      0.682835   \n",
       "std_train_score                                      0.0271298   \n",
       "\n",
       "                                                             84   \\\n",
       "mean_fit_time                                           0.016192   \n",
       "std_fit_time                                         0.000469374   \n",
       "mean_score_time                                       0.00183873   \n",
       "std_score_time                                       4.68861e-05   \n",
       "param_C                                                      100   \n",
       "param_gamma                                               0.0001   \n",
       "param_kernel                                                 rbf   \n",
       "params              {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                       0.699571   \n",
       "split1_test_score                                       0.660131   \n",
       "split2_test_score                                       0.626811   \n",
       "split3_test_score                                       0.766862   \n",
       "split4_test_score                                       0.540194   \n",
       "mean_test_score                                         0.658714   \n",
       "std_test_score                                         0.0754083   \n",
       "rank_test_score                                                8   \n",
       "split0_train_score                                       0.64982   \n",
       "split1_train_score                                      0.667884   \n",
       "split2_train_score                                      0.673328   \n",
       "split3_train_score                                      0.636395   \n",
       "split4_train_score                                      0.715606   \n",
       "mean_train_score                                        0.668607   \n",
       "std_train_score                                        0.0269156   \n",
       "\n",
       "                                                             105  \\\n",
       "mean_fit_time                                          0.0182946   \n",
       "std_fit_time                                          0.00264173   \n",
       "mean_score_time                                       0.00288639   \n",
       "std_score_time                                       0.000738247   \n",
       "param_C                                                     1000   \n",
       "param_gamma                                                1e-05   \n",
       "param_kernel                                                 rbf   \n",
       "params              {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}   \n",
       "split0_test_score                                       0.699717   \n",
       "split1_test_score                                       0.658089   \n",
       "split2_test_score                                       0.625292   \n",
       "split3_test_score                                       0.765125   \n",
       "split4_test_score                                       0.537911   \n",
       "mean_test_score                                         0.657227   \n",
       "std_test_score                                         0.0757683   \n",
       "rank_test_score                                                9   \n",
       "split0_train_score                                      0.648372   \n",
       "split1_train_score                                      0.666217   \n",
       "split2_train_score                                      0.671357   \n",
       "split3_train_score                                      0.632124   \n",
       "split4_train_score                                      0.712869   \n",
       "mean_train_score                                        0.666188   \n",
       "std_train_score                                        0.0271426   \n",
       "\n",
       "                                                             111  \\\n",
       "mean_fit_time                                            0.14539   \n",
       "std_fit_time                                           0.0137515   \n",
       "mean_score_time                                       0.00280948   \n",
       "std_score_time                                       0.000759274   \n",
       "param_C                                                     1000   \n",
       "param_gamma                                                0.001   \n",
       "param_kernel                                                 rbf   \n",
       "params              {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                       0.820067   \n",
       "split1_test_score                                       0.536616   \n",
       "split2_test_score                                       0.581822   \n",
       "split3_test_score                                       0.674953   \n",
       "split4_test_score                                       0.659863   \n",
       "mean_test_score                                         0.654664   \n",
       "std_test_score                                         0.0969927   \n",
       "rank_test_score                                               10   \n",
       "split0_train_score                                      0.769791   \n",
       "split1_train_score                                      0.867117   \n",
       "split2_train_score                                      0.848154   \n",
       "split3_train_score                                      0.832729   \n",
       "split4_train_score                                      0.868024   \n",
       "mean_train_score                                        0.837163   \n",
       "std_train_score                                         0.036136   \n",
       "\n",
       "                                                             7    \\\n",
       "mean_fit_time                                           0.070125   \n",
       "std_fit_time                                          0.00183719   \n",
       "mean_score_time                                        0.0014657   \n",
       "std_score_time                                       0.000258409   \n",
       "param_C                                                        1   \n",
       "param_gamma                                                1e-06   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 1, 'gamma': 1e-06, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710274   \n",
       "split1_test_score                                       0.658016   \n",
       "split2_test_score                                       0.606409   \n",
       "split3_test_score                                        0.76225   \n",
       "split4_test_score                                       0.535892   \n",
       "mean_test_score                                         0.654568   \n",
       "std_test_score                                         0.0788843   \n",
       "rank_test_score                                               11   \n",
       "split0_train_score                                      0.647353   \n",
       "split1_train_score                                       0.66934   \n",
       "split2_train_score                                       0.67664   \n",
       "split3_train_score                                      0.634906   \n",
       "split4_train_score                                      0.719431   \n",
       "mean_train_score                                        0.669534   \n",
       "std_train_score                                        0.0290906   \n",
       "\n",
       "                                                             16   \\\n",
       "mean_fit_time                                          0.0694604   \n",
       "std_fit_time                                          0.00535225   \n",
       "mean_score_time                                       0.00132537   \n",
       "std_score_time                                       3.88097e-05   \n",
       "param_C                                                        1   \n",
       "param_gamma                                                0.001   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710274   \n",
       "split1_test_score                                       0.658016   \n",
       "split2_test_score                                       0.606409   \n",
       "split3_test_score                                        0.76225   \n",
       "split4_test_score                                       0.535892   \n",
       "mean_test_score                                         0.654568   \n",
       "std_test_score                                         0.0788843   \n",
       "rank_test_score                                               11   \n",
       "split0_train_score                                      0.647353   \n",
       "split1_train_score                                       0.66934   \n",
       "split2_train_score                                       0.67664   \n",
       "split3_train_score                                      0.634906   \n",
       "split4_train_score                                      0.719431   \n",
       "mean_train_score                                        0.669534   \n",
       "std_train_score                                        0.0290906   \n",
       "\n",
       "                                                             4    \\\n",
       "mean_fit_time                                          0.0880497   \n",
       "std_fit_time                                           0.0258486   \n",
       "mean_score_time                                       0.00186453   \n",
       "std_score_time                                       0.000886416   \n",
       "param_C                                                        1   \n",
       "param_gamma                                                1e-07   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 1, 'gamma': 1e-07, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710274   \n",
       "split1_test_score                                       0.658016   \n",
       "split2_test_score                                       0.606409   \n",
       "split3_test_score                                        0.76225   \n",
       "split4_test_score                                       0.535892   \n",
       "mean_test_score                                         0.654568   \n",
       "std_test_score                                         0.0788843   \n",
       "rank_test_score                                               11   \n",
       "split0_train_score                                      0.647353   \n",
       "split1_train_score                                       0.66934   \n",
       "split2_train_score                                       0.67664   \n",
       "split3_train_score                                      0.634906   \n",
       "split4_train_score                                      0.719431   \n",
       "mean_train_score                                        0.669534   \n",
       "std_train_score                                        0.0290906   \n",
       "\n",
       "                                                             1    \\\n",
       "mean_fit_time                                          0.0744107   \n",
       "std_fit_time                                          0.00879387   \n",
       "mean_score_time                                       0.00157914   \n",
       "std_score_time                                       0.000505305   \n",
       "param_C                                                        1   \n",
       "param_gamma                                                1e-08   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 1, 'gamma': 1e-08, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710274   \n",
       "split1_test_score                                       0.658016   \n",
       "split2_test_score                                       0.606409   \n",
       "split3_test_score                                        0.76225   \n",
       "split4_test_score                                       0.535892   \n",
       "mean_test_score                                         0.654568   \n",
       "std_test_score                                         0.0788843   \n",
       "rank_test_score                                               11   \n",
       "split0_train_score                                      0.647353   \n",
       "split1_train_score                                       0.66934   \n",
       "split2_train_score                                       0.67664   \n",
       "split3_train_score                                      0.634906   \n",
       "split4_train_score                                      0.719431   \n",
       "mean_train_score                                        0.669534   \n",
       "std_train_score                                        0.0290906   \n",
       "\n",
       "                                                            19   \\\n",
       "mean_fit_time                                         0.0935681   \n",
       "std_fit_time                                          0.0231138   \n",
       "mean_score_time                                      0.00148621   \n",
       "std_score_time                                      0.000114694   \n",
       "param_C                                                       1   \n",
       "param_gamma                                                0.01   \n",
       "param_kernel                                             linear   \n",
       "params              {'C': 1, 'gamma': 0.01, 'kernel': 'linear'}   \n",
       "split0_test_score                                      0.710274   \n",
       "split1_test_score                                      0.658016   \n",
       "split2_test_score                                      0.606409   \n",
       "split3_test_score                                       0.76225   \n",
       "split4_test_score                                      0.535892   \n",
       "mean_test_score                                        0.654568   \n",
       "std_test_score                                        0.0788843   \n",
       "rank_test_score                                              11   \n",
       "split0_train_score                                     0.647353   \n",
       "split1_train_score                                      0.66934   \n",
       "split2_train_score                                      0.67664   \n",
       "split3_train_score                                     0.634906   \n",
       "split4_train_score                                     0.719431   \n",
       "mean_train_score                                       0.669534   \n",
       "std_train_score                                       0.0290906   \n",
       "\n",
       "                                                           22   \\\n",
       "mean_fit_time                                        0.0812947   \n",
       "std_fit_time                                         0.0107716   \n",
       "mean_score_time                                     0.00129399   \n",
       "std_score_time                                     5.59569e-05   \n",
       "param_C                                                      1   \n",
       "param_gamma                                                0.1   \n",
       "param_kernel                                            linear   \n",
       "params              {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "split0_test_score                                     0.710274   \n",
       "split1_test_score                                     0.658016   \n",
       "split2_test_score                                     0.606409   \n",
       "split3_test_score                                      0.76225   \n",
       "split4_test_score                                     0.535892   \n",
       "mean_test_score                                       0.654568   \n",
       "std_test_score                                       0.0788843   \n",
       "rank_test_score                                             11   \n",
       "split0_train_score                                    0.647353   \n",
       "split1_train_score                                     0.66934   \n",
       "split2_train_score                                     0.67664   \n",
       "split3_train_score                                    0.634906   \n",
       "split4_train_score                                    0.719431   \n",
       "mean_train_score                                      0.669534   \n",
       "std_train_score                                      0.0290906   \n",
       "\n",
       "                                                              13   \\\n",
       "mean_fit_time                                           0.0710156   \n",
       "std_fit_time                                            0.0053571   \n",
       "mean_score_time                                        0.00143094   \n",
       "std_score_time                                        0.000360204   \n",
       "param_C                                                         1   \n",
       "param_gamma                                                0.0001   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710274   \n",
       "split1_test_score                                        0.658016   \n",
       "split2_test_score                                        0.606409   \n",
       "split3_test_score                                         0.76225   \n",
       "split4_test_score                                        0.535892   \n",
       "mean_test_score                                          0.654568   \n",
       "std_test_score                                          0.0788843   \n",
       "rank_test_score                                                11   \n",
       "split0_train_score                                       0.647353   \n",
       "split1_train_score                                        0.66934   \n",
       "split2_train_score                                        0.67664   \n",
       "split3_train_score                                       0.634906   \n",
       "split4_train_score                                       0.719431   \n",
       "mean_train_score                                         0.669534   \n",
       "std_train_score                                         0.0290906   \n",
       "\n",
       "                                                             10   \\\n",
       "mean_fit_time                                          0.0834431   \n",
       "std_fit_time                                          0.00952521   \n",
       "mean_score_time                                       0.00147929   \n",
       "std_score_time                                       0.000387979   \n",
       "param_C                                                        1   \n",
       "param_gamma                                                1e-05   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 1, 'gamma': 1e-05, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710274   \n",
       "split1_test_score                                       0.658016   \n",
       "split2_test_score                                       0.606409   \n",
       "split3_test_score                                        0.76225   \n",
       "split4_test_score                                       0.535892   \n",
       "mean_test_score                                         0.654568   \n",
       "std_test_score                                         0.0788843   \n",
       "rank_test_score                                               11   \n",
       "split0_train_score                                      0.647353   \n",
       "split1_train_score                                       0.66934   \n",
       "split2_train_score                                       0.67664   \n",
       "split3_train_score                                      0.634906   \n",
       "split4_train_score                                      0.719431   \n",
       "mean_train_score                                        0.669534   \n",
       "std_train_score                                        0.0290906   \n",
       "\n",
       "                                                              91   \\\n",
       "mean_fit_time                                             4.65431   \n",
       "std_fit_time                                             0.435908   \n",
       "mean_score_time                                        0.00128617   \n",
       "std_score_time                                        3.93882e-05   \n",
       "param_C                                                       100   \n",
       "param_gamma                                                  0.01   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 100, 'gamma': 0.01, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710248   \n",
       "split1_test_score                                         0.65812   \n",
       "split2_test_score                                        0.606209   \n",
       "split3_test_score                                        0.762069   \n",
       "split4_test_score                                        0.535548   \n",
       "mean_test_score                                          0.654439   \n",
       "std_test_score                                          0.0789603   \n",
       "rank_test_score                                                19   \n",
       "split0_train_score                                       0.647354   \n",
       "split1_train_score                                       0.669384   \n",
       "split2_train_score                                        0.67645   \n",
       "split3_train_score                                       0.635116   \n",
       "split4_train_score                                       0.719502   \n",
       "mean_train_score                                         0.669561   \n",
       "std_train_score                                         0.0290557   \n",
       "\n",
       "                                                               73   \\\n",
       "mean_fit_time                                              5.15932   \n",
       "std_fit_time                                              0.407533   \n",
       "mean_score_time                                         0.00155287   \n",
       "std_score_time                                         0.000537116   \n",
       "param_C                                                        100   \n",
       "param_gamma                                                  1e-08   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 100, 'gamma': 1e-08, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710248   \n",
       "split1_test_score                                          0.65812   \n",
       "split2_test_score                                         0.606209   \n",
       "split3_test_score                                         0.762069   \n",
       "split4_test_score                                         0.535548   \n",
       "mean_test_score                                           0.654439   \n",
       "std_test_score                                           0.0789603   \n",
       "rank_test_score                                                 19   \n",
       "split0_train_score                                        0.647354   \n",
       "split1_train_score                                        0.669384   \n",
       "split2_train_score                                         0.67645   \n",
       "split3_train_score                                        0.635116   \n",
       "split4_train_score                                        0.719502   \n",
       "mean_train_score                                          0.669561   \n",
       "std_train_score                                          0.0290557   \n",
       "\n",
       "                                                               88   \\\n",
       "mean_fit_time                                              4.31739   \n",
       "std_fit_time                                              0.192384   \n",
       "mean_score_time                                          0.0013279   \n",
       "std_score_time                                         7.67981e-05   \n",
       "param_C                                                        100   \n",
       "param_gamma                                                  0.001   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710248   \n",
       "split1_test_score                                          0.65812   \n",
       "split2_test_score                                         0.606209   \n",
       "split3_test_score                                         0.762069   \n",
       "split4_test_score                                         0.535548   \n",
       "mean_test_score                                           0.654439   \n",
       "std_test_score                                           0.0789603   \n",
       "rank_test_score                                                 19   \n",
       "split0_train_score                                        0.647354   \n",
       "split1_train_score                                        0.669384   \n",
       "split2_train_score                                         0.67645   \n",
       "split3_train_score                                        0.635116   \n",
       "split4_train_score                                        0.719502   \n",
       "mean_train_score                                          0.669561   \n",
       "std_train_score                                          0.0290557   \n",
       "\n",
       "                                                               82   \\\n",
       "mean_fit_time                                              4.61293   \n",
       "std_fit_time                                              0.340457   \n",
       "mean_score_time                                          0.0012856   \n",
       "std_score_time                                         6.15545e-06   \n",
       "param_C                                                        100   \n",
       "param_gamma                                                  1e-05   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 100, 'gamma': 1e-05, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710248   \n",
       "split1_test_score                                          0.65812   \n",
       "split2_test_score                                         0.606209   \n",
       "split3_test_score                                         0.762069   \n",
       "split4_test_score                                         0.535548   \n",
       "mean_test_score                                           0.654439   \n",
       "std_test_score                                           0.0789603   \n",
       "rank_test_score                                                 19   \n",
       "split0_train_score                                        0.647354   \n",
       "split1_train_score                                        0.669384   \n",
       "split2_train_score                                         0.67645   \n",
       "split3_train_score                                        0.635116   \n",
       "split4_train_score                                        0.719502   \n",
       "mean_train_score                                          0.669561   \n",
       "std_train_score                                          0.0290557   \n",
       "\n",
       "                                                                85   \\\n",
       "mean_fit_time                                               4.38332   \n",
       "std_fit_time                                               0.176659   \n",
       "mean_score_time                                          0.00125957   \n",
       "std_score_time                                          5.40181e-05   \n",
       "param_C                                                         100   \n",
       "param_gamma                                                  0.0001   \n",
       "param_kernel                                                 linear   \n",
       "params              {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "split0_test_score                                          0.710248   \n",
       "split1_test_score                                           0.65812   \n",
       "split2_test_score                                          0.606209   \n",
       "split3_test_score                                          0.762069   \n",
       "split4_test_score                                          0.535548   \n",
       "mean_test_score                                            0.654439   \n",
       "std_test_score                                            0.0789603   \n",
       "rank_test_score                                                  19   \n",
       "split0_train_score                                         0.647354   \n",
       "split1_train_score                                         0.669384   \n",
       "split2_train_score                                          0.67645   \n",
       "split3_train_score                                         0.635116   \n",
       "split4_train_score                                         0.719502   \n",
       "mean_train_score                                           0.669561   \n",
       "std_train_score                                           0.0290557   \n",
       "\n",
       "                                                               76   \\\n",
       "mean_fit_time                                              4.60068   \n",
       "std_fit_time                                              0.428783   \n",
       "mean_score_time                                         0.00127721   \n",
       "std_score_time                                         2.02012e-05   \n",
       "param_C                                                        100   \n",
       "param_gamma                                                  1e-07   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 100, 'gamma': 1e-07, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710248   \n",
       "split1_test_score                                          0.65812   \n",
       "split2_test_score                                         0.606209   \n",
       "split3_test_score                                         0.762069   \n",
       "split4_test_score                                         0.535548   \n",
       "mean_test_score                                           0.654439   \n",
       "std_test_score                                           0.0789603   \n",
       "rank_test_score                                                 19   \n",
       "split0_train_score                                        0.647354   \n",
       "split1_train_score                                        0.669384   \n",
       "split2_train_score                                         0.67645   \n",
       "split3_train_score                                        0.635116   \n",
       "split4_train_score                                        0.719502   \n",
       "mean_train_score                                          0.669561   \n",
       "std_train_score                                          0.0290557   \n",
       "\n",
       "                                                             94   \\\n",
       "mean_fit_time                                            4.61448   \n",
       "std_fit_time                                            0.413085   \n",
       "mean_score_time                                       0.00132594   \n",
       "std_score_time                                       0.000116465   \n",
       "param_C                                                      100   \n",
       "param_gamma                                                  0.1   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710248   \n",
       "split1_test_score                                        0.65812   \n",
       "split2_test_score                                       0.606209   \n",
       "split3_test_score                                       0.762069   \n",
       "split4_test_score                                       0.535548   \n",
       "mean_test_score                                         0.654439   \n",
       "std_test_score                                         0.0789603   \n",
       "rank_test_score                                               19   \n",
       "split0_train_score                                      0.647354   \n",
       "split1_train_score                                      0.669384   \n",
       "split2_train_score                                       0.67645   \n",
       "split3_train_score                                      0.635116   \n",
       "split4_train_score                                      0.719502   \n",
       "mean_train_score                                        0.669561   \n",
       "std_train_score                                        0.0290557   \n",
       "\n",
       "                                                               79   \\\n",
       "mean_fit_time                                              4.84876   \n",
       "std_fit_time                                              0.693874   \n",
       "mean_score_time                                         0.00133123   \n",
       "std_score_time                                         5.04314e-05   \n",
       "param_C                                                        100   \n",
       "param_gamma                                                  1e-06   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 100, 'gamma': 1e-06, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710248   \n",
       "split1_test_score                                          0.65812   \n",
       "split2_test_score                                         0.606209   \n",
       "split3_test_score                                         0.762069   \n",
       "split4_test_score                                         0.535548   \n",
       "mean_test_score                                           0.654439   \n",
       "std_test_score                                           0.0789603   \n",
       "rank_test_score                                                 19   \n",
       "split0_train_score                                        0.647354   \n",
       "split1_train_score                                        0.669384   \n",
       "split2_train_score                                         0.67645   \n",
       "split3_train_score                                        0.635116   \n",
       "split4_train_score                                        0.719502   \n",
       "mean_train_score                                          0.669561   \n",
       "std_train_score                                          0.0290557   \n",
       "\n",
       "                                                              49   \\\n",
       "mean_fit_time                                            0.533924   \n",
       "std_fit_time                                            0.0475813   \n",
       "mean_score_time                                        0.00145121   \n",
       "std_score_time                                        0.000407121   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-08   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-08, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                              40   \\\n",
       "mean_fit_time                                            0.546842   \n",
       "std_fit_time                                            0.0314261   \n",
       "mean_score_time                                        0.00152264   \n",
       "std_score_time                                         0.00039012   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 0.001   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                             43   \\\n",
       "mean_fit_time                                           0.537461   \n",
       "std_fit_time                                           0.0596602   \n",
       "mean_score_time                                       0.00151711   \n",
       "std_score_time                                       0.000493674   \n",
       "param_C                                                       10   \n",
       "param_gamma                                                 0.01   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710335   \n",
       "split1_test_score                                       0.658116   \n",
       "split2_test_score                                       0.604796   \n",
       "split3_test_score                                       0.762241   \n",
       "split4_test_score                                       0.535585   \n",
       "mean_test_score                                         0.654215   \n",
       "std_test_score                                         0.0791826   \n",
       "rank_test_score                                               27   \n",
       "split0_train_score                                      0.647393   \n",
       "split1_train_score                                      0.669388   \n",
       "split2_train_score                                      0.676471   \n",
       "split3_train_score                                      0.634879   \n",
       "split4_train_score                                      0.719426   \n",
       "mean_train_score                                        0.669512   \n",
       "std_train_score                                         0.029081   \n",
       "\n",
       "                                                            70   \\\n",
       "mean_fit_time                                          0.701497   \n",
       "std_fit_time                                           0.171229   \n",
       "mean_score_time                                      0.00129013   \n",
       "std_score_time                                      6.77779e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                                 0.1   \n",
       "param_kernel                                             linear   \n",
       "params              {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "split0_test_score                                      0.710335   \n",
       "split1_test_score                                      0.658116   \n",
       "split2_test_score                                      0.604796   \n",
       "split3_test_score                                      0.762241   \n",
       "split4_test_score                                      0.535585   \n",
       "mean_test_score                                        0.654215   \n",
       "std_test_score                                        0.0791826   \n",
       "rank_test_score                                              27   \n",
       "split0_train_score                                     0.647393   \n",
       "split1_train_score                                     0.669388   \n",
       "split2_train_score                                     0.676471   \n",
       "split3_train_score                                     0.634879   \n",
       "split4_train_score                                     0.719426   \n",
       "mean_train_score                                       0.669512   \n",
       "std_train_score                                        0.029081   \n",
       "\n",
       "                                                              52   \\\n",
       "mean_fit_time                                            0.633267   \n",
       "std_fit_time                                             0.164686   \n",
       "mean_score_time                                        0.00151057   \n",
       "std_score_time                                        0.000363397   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-07   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-07, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                              55   \\\n",
       "mean_fit_time                                            0.638852   \n",
       "std_fit_time                                             0.111283   \n",
       "mean_score_time                                        0.00155487   \n",
       "std_score_time                                        0.000573748   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-06   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-06, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                             67   \\\n",
       "mean_fit_time                                           0.769737   \n",
       "std_fit_time                                            0.134538   \n",
       "mean_score_time                                        0.0030632   \n",
       "std_score_time                                        0.00345975   \n",
       "param_C                                                       10   \n",
       "param_gamma                                                 0.01   \n",
       "param_kernel                                              linear   \n",
       "params              {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}   \n",
       "split0_test_score                                       0.710335   \n",
       "split1_test_score                                       0.658116   \n",
       "split2_test_score                                       0.604796   \n",
       "split3_test_score                                       0.762241   \n",
       "split4_test_score                                       0.535585   \n",
       "mean_test_score                                         0.654215   \n",
       "std_test_score                                         0.0791826   \n",
       "rank_test_score                                               27   \n",
       "split0_train_score                                      0.647393   \n",
       "split1_train_score                                      0.669388   \n",
       "split2_train_score                                      0.676471   \n",
       "split3_train_score                                      0.634879   \n",
       "split4_train_score                                      0.719426   \n",
       "mean_train_score                                        0.669512   \n",
       "std_train_score                                         0.029081   \n",
       "\n",
       "                                                               61   \\\n",
       "mean_fit_time                                              0.67046   \n",
       "std_fit_time                                              0.149595   \n",
       "mean_score_time                                         0.00154591   \n",
       "std_score_time                                         0.000350249   \n",
       "param_C                                                         10   \n",
       "param_gamma                                                 0.0001   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710335   \n",
       "split1_test_score                                         0.658116   \n",
       "split2_test_score                                         0.604796   \n",
       "split3_test_score                                         0.762241   \n",
       "split4_test_score                                         0.535585   \n",
       "mean_test_score                                           0.654215   \n",
       "std_test_score                                           0.0791826   \n",
       "rank_test_score                                                 27   \n",
       "split0_train_score                                        0.647393   \n",
       "split1_train_score                                        0.669388   \n",
       "split2_train_score                                        0.676471   \n",
       "split3_train_score                                        0.634879   \n",
       "split4_train_score                                        0.719426   \n",
       "mean_train_score                                          0.669512   \n",
       "std_train_score                                           0.029081   \n",
       "\n",
       "                                                              64   \\\n",
       "mean_fit_time                                            0.827334   \n",
       "std_fit_time                                            0.0245847   \n",
       "mean_score_time                                        0.00288935   \n",
       "std_score_time                                          0.0017992   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 0.001   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                               37   \\\n",
       "mean_fit_time                                             0.583702   \n",
       "std_fit_time                                              0.128061   \n",
       "mean_score_time                                         0.00131021   \n",
       "std_score_time                                         8.64011e-05   \n",
       "param_C                                                         10   \n",
       "param_gamma                                                 0.0001   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710335   \n",
       "split1_test_score                                         0.658116   \n",
       "split2_test_score                                         0.604796   \n",
       "split3_test_score                                         0.762241   \n",
       "split4_test_score                                         0.535585   \n",
       "mean_test_score                                           0.654215   \n",
       "std_test_score                                           0.0791826   \n",
       "rank_test_score                                                 27   \n",
       "split0_train_score                                        0.647393   \n",
       "split1_train_score                                        0.669388   \n",
       "split2_train_score                                        0.676471   \n",
       "split3_train_score                                        0.634879   \n",
       "split4_train_score                                        0.719426   \n",
       "mean_train_score                                          0.669512   \n",
       "std_train_score                                           0.029081   \n",
       "\n",
       "                                                              58   \\\n",
       "mean_fit_time                                            0.574692   \n",
       "std_fit_time                                             0.120773   \n",
       "mean_score_time                                        0.00163736   \n",
       "std_score_time                                        0.000569647   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-05   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-05, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                            46   \\\n",
       "mean_fit_time                                          0.666681   \n",
       "std_fit_time                                           0.184932   \n",
       "mean_score_time                                      0.00123806   \n",
       "std_score_time                                      4.47383e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                                 0.1   \n",
       "param_kernel                                             linear   \n",
       "params              {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "split0_test_score                                      0.710335   \n",
       "split1_test_score                                      0.658116   \n",
       "split2_test_score                                      0.604796   \n",
       "split3_test_score                                      0.762241   \n",
       "split4_test_score                                      0.535585   \n",
       "mean_test_score                                        0.654215   \n",
       "std_test_score                                        0.0791826   \n",
       "rank_test_score                                              27   \n",
       "split0_train_score                                     0.647393   \n",
       "split1_train_score                                     0.669388   \n",
       "split2_train_score                                     0.676471   \n",
       "split3_train_score                                     0.634879   \n",
       "split4_train_score                                     0.719426   \n",
       "mean_train_score                                       0.669512   \n",
       "std_train_score                                        0.029081   \n",
       "\n",
       "                                                              28   \\\n",
       "mean_fit_time                                            0.517427   \n",
       "std_fit_time                                            0.0327956   \n",
       "mean_score_time                                        0.00133476   \n",
       "std_score_time                                         8.8522e-05   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-07   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-07, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                              34   \\\n",
       "mean_fit_time                                              0.6226   \n",
       "std_fit_time                                            0.0439848   \n",
       "mean_score_time                                        0.00162663   \n",
       "std_score_time                                        2.58737e-05   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-05   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-05, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                              31   \\\n",
       "mean_fit_time                                            0.600311   \n",
       "std_fit_time                                            0.0559463   \n",
       "mean_score_time                                        0.00154366   \n",
       "std_score_time                                        0.000149913   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-06   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-06, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                              25   \\\n",
       "mean_fit_time                                            0.696395   \n",
       "std_fit_time                                             0.154638   \n",
       "mean_score_time                                         0.0014246   \n",
       "std_score_time                                        0.000210653   \n",
       "param_C                                                        10   \n",
       "param_gamma                                                 1e-08   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 10, 'gamma': 1e-08, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710335   \n",
       "split1_test_score                                        0.658116   \n",
       "split2_test_score                                        0.604796   \n",
       "split3_test_score                                        0.762241   \n",
       "split4_test_score                                        0.535585   \n",
       "mean_test_score                                          0.654215   \n",
       "std_test_score                                          0.0791826   \n",
       "rank_test_score                                                27   \n",
       "split0_train_score                                       0.647393   \n",
       "split1_train_score                                       0.669388   \n",
       "split2_train_score                                       0.676471   \n",
       "split3_train_score                                       0.634879   \n",
       "split4_train_score                                       0.719426   \n",
       "mean_train_score                                         0.669512   \n",
       "std_train_score                                          0.029081   \n",
       "\n",
       "                                                                 109  \\\n",
       "mean_fit_time                                                53.8709   \n",
       "std_fit_time                                                 3.53656   \n",
       "mean_score_time                                            0.0013875   \n",
       "std_score_time                                           0.000214218   \n",
       "param_C                                                         1000   \n",
       "param_gamma                                                   0.0001   \n",
       "param_kernel                                                  linear   \n",
       "params              {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "split0_test_score                                           0.710443   \n",
       "split1_test_score                                           0.657969   \n",
       "split2_test_score                                           0.602269   \n",
       "split3_test_score                                           0.760589   \n",
       "split4_test_score                                           0.536119   \n",
       "mean_test_score                                             0.653478   \n",
       "std_test_score                                             0.0789093   \n",
       "rank_test_score                                                   43   \n",
       "split0_train_score                                          0.647413   \n",
       "split1_train_score                                          0.669211   \n",
       "split2_train_score                                          0.676509   \n",
       "split3_train_score                                          0.635386   \n",
       "split4_train_score                                          0.719527   \n",
       "mean_train_score                                            0.669609   \n",
       "std_train_score                                            0.0289947   \n",
       "\n",
       "                                                              118  \\\n",
       "mean_fit_time                                             54.6516   \n",
       "std_fit_time                                              15.5897   \n",
       "mean_score_time                                         0.0014225   \n",
       "std_score_time                                        0.000216009   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                   0.1   \n",
       "param_kernel                                               linear   \n",
       "params              {'C': 1000, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "split0_test_score                                        0.710443   \n",
       "split1_test_score                                        0.657969   \n",
       "split2_test_score                                        0.602269   \n",
       "split3_test_score                                        0.760589   \n",
       "split4_test_score                                        0.536119   \n",
       "mean_test_score                                          0.653478   \n",
       "std_test_score                                          0.0789093   \n",
       "rank_test_score                                                43   \n",
       "split0_train_score                                       0.647413   \n",
       "split1_train_score                                       0.669211   \n",
       "split2_train_score                                       0.676509   \n",
       "split3_train_score                                       0.635386   \n",
       "split4_train_score                                       0.719527   \n",
       "mean_train_score                                         0.669609   \n",
       "std_train_score                                         0.0289947   \n",
       "\n",
       "                                                               115  \\\n",
       "mean_fit_time                                              54.2465   \n",
       "std_fit_time                                               8.63987   \n",
       "mean_score_time                                         0.00158963   \n",
       "std_score_time                                         0.000588735   \n",
       "param_C                                                       1000   \n",
       "param_gamma                                                   0.01   \n",
       "param_kernel                                                linear   \n",
       "params              {'C': 1000, 'gamma': 0.01, 'kernel': 'linear'}   \n",
       "split0_test_score                                         0.710443   \n",
       "split1_test_score                                         0.657969   \n",
       "split2_test_score                                         0.602269   \n",
       "split3_test_score                                         0.760589   \n",
       "split4_test_score                                         0.536119   \n",
       "mean_test_score                                           0.653478   \n",
       "std_test_score                                           0.0789093   \n",
       "rank_test_score                                                 43   \n",
       "split0_train_score                                        0.647413   \n",
       "split1_train_score                                        0.669211   \n",
       "split2_train_score                                        0.676509   \n",
       "split3_train_score                                        0.635386   \n",
       "split4_train_score                                        0.719527   \n",
       "mean_train_score                                          0.669609   \n",
       "std_train_score                                          0.0289947   \n",
       "\n",
       "                                                                97   \\\n",
       "mean_fit_time                                               49.8976   \n",
       "std_fit_time                                                3.27656   \n",
       "mean_score_time                                          0.00132098   \n",
       "std_score_time                                          6.19955e-05   \n",
       "param_C                                                        1000   \n",
       "param_gamma                                                   1e-08   \n",
       "param_kernel                                                 linear   \n",
       "params              {'C': 1000, 'gamma': 1e-08, 'kernel': 'linear'}   \n",
       "split0_test_score                                          0.710443   \n",
       "split1_test_score                                          0.657969   \n",
       "split2_test_score                                          0.602269   \n",
       "split3_test_score                                          0.760589   \n",
       "split4_test_score                                          0.536119   \n",
       "mean_test_score                                            0.653478   \n",
       "std_test_score                                            0.0789093   \n",
       "rank_test_score                                                  43   \n",
       "split0_train_score                                         0.647413   \n",
       "split1_train_score                                         0.669211   \n",
       "split2_train_score                                         0.676509   \n",
       "split3_train_score                                         0.635386   \n",
       "split4_train_score                                         0.719527   \n",
       "mean_train_score                                           0.669609   \n",
       "std_train_score                                           0.0289947   \n",
       "\n",
       "                                                                100  \\\n",
       "mean_fit_time                                               56.3514   \n",
       "std_fit_time                                                20.0378   \n",
       "mean_score_time                                          0.00238028   \n",
       "std_score_time                                           0.00218637   \n",
       "param_C                                                        1000   \n",
       "param_gamma                                                   1e-07   \n",
       "param_kernel                                                 linear   \n",
       "params              {'C': 1000, 'gamma': 1e-07, 'kernel': 'linear'}   \n",
       "split0_test_score                                          0.710443   \n",
       "split1_test_score                                          0.657969   \n",
       "split2_test_score                                          0.602269   \n",
       "split3_test_score                                          0.760589   \n",
       "split4_test_score                                          0.536119   \n",
       "mean_test_score                                            0.653478   \n",
       "std_test_score                                            0.0789093   \n",
       "rank_test_score                                                  43   \n",
       "split0_train_score                                         0.647413   \n",
       "split1_train_score                                         0.669211   \n",
       "split2_train_score                                         0.676509   \n",
       "split3_train_score                                         0.635386   \n",
       "split4_train_score                                         0.719527   \n",
       "mean_train_score                                           0.669609   \n",
       "std_train_score                                           0.0289947   \n",
       "\n",
       "                                                                106  \\\n",
       "mean_fit_time                                               61.3915   \n",
       "std_fit_time                                                2.02172   \n",
       "mean_score_time                                          0.00254021   \n",
       "std_score_time                                           0.00191665   \n",
       "param_C                                                        1000   \n",
       "param_gamma                                                   1e-05   \n",
       "param_kernel                                                 linear   \n",
       "params              {'C': 1000, 'gamma': 1e-05, 'kernel': 'linear'}   \n",
       "split0_test_score                                          0.710443   \n",
       "split1_test_score                                          0.657969   \n",
       "split2_test_score                                          0.602269   \n",
       "split3_test_score                                          0.760589   \n",
       "split4_test_score                                          0.536119   \n",
       "mean_test_score                                            0.653478   \n",
       "std_test_score                                            0.0789093   \n",
       "rank_test_score                                                  43   \n",
       "split0_train_score                                         0.647413   \n",
       "split1_train_score                                         0.669211   \n",
       "split2_train_score                                         0.676509   \n",
       "split3_train_score                                         0.635386   \n",
       "split4_train_score                                         0.719527   \n",
       "mean_train_score                                           0.669609   \n",
       "std_train_score                                           0.0289947   \n",
       "\n",
       "                                                                103  \\\n",
       "mean_fit_time                                               57.9363   \n",
       "std_fit_time                                                8.64163   \n",
       "mean_score_time                                          0.00179257   \n",
       "std_score_time                                          0.000299617   \n",
       "param_C                                                        1000   \n",
       "param_gamma                                                   1e-06   \n",
       "param_kernel                                                 linear   \n",
       "params              {'C': 1000, 'gamma': 1e-06, 'kernel': 'linear'}   \n",
       "split0_test_score                                          0.710443   \n",
       "split1_test_score                                          0.657969   \n",
       "split2_test_score                                          0.602269   \n",
       "split3_test_score                                          0.760589   \n",
       "split4_test_score                                          0.536119   \n",
       "mean_test_score                                            0.653478   \n",
       "std_test_score                                            0.0789093   \n",
       "rank_test_score                                                  43   \n",
       "split0_train_score                                         0.647413   \n",
       "split1_train_score                                         0.669211   \n",
       "split2_train_score                                         0.676509   \n",
       "split3_train_score                                         0.635386   \n",
       "split4_train_score                                         0.719527   \n",
       "mean_train_score                                           0.669609   \n",
       "std_train_score                                           0.0289947   \n",
       "\n",
       "                                                                112  \\\n",
       "mean_fit_time                                               57.5316   \n",
       "std_fit_time                                                4.65092   \n",
       "mean_score_time                                           0.0016665   \n",
       "std_score_time                                          0.000438401   \n",
       "param_C                                                        1000   \n",
       "param_gamma                                                   0.001   \n",
       "param_kernel                                                 linear   \n",
       "params              {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'}   \n",
       "split0_test_score                                          0.710443   \n",
       "split1_test_score                                          0.657969   \n",
       "split2_test_score                                          0.602269   \n",
       "split3_test_score                                          0.760589   \n",
       "split4_test_score                                          0.536119   \n",
       "mean_test_score                                            0.653478   \n",
       "std_test_score                                            0.0789093   \n",
       "rank_test_score                                                  43   \n",
       "split0_train_score                                         0.647413   \n",
       "split1_train_score                                         0.669211   \n",
       "split2_train_score                                         0.676509   \n",
       "split3_train_score                                         0.635386   \n",
       "split4_train_score                                         0.719527   \n",
       "mean_train_score                                           0.669609   \n",
       "std_train_score                                           0.0289947   \n",
       "\n",
       "                                                             102  \\\n",
       "mean_fit_time                                           0.010939   \n",
       "std_fit_time                                          0.00194577   \n",
       "mean_score_time                                       0.00220566   \n",
       "std_score_time                                       0.000520825   \n",
       "param_C                                                     1000   \n",
       "param_gamma                                                1e-06   \n",
       "param_kernel                                                 rbf   \n",
       "params              {'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'}   \n",
       "split0_test_score                                       0.601747   \n",
       "split1_test_score                                       0.624256   \n",
       "split2_test_score                                       0.609495   \n",
       "split3_test_score                                       0.688221   \n",
       "split4_test_score                                       0.488625   \n",
       "mean_test_score                                         0.602469   \n",
       "std_test_score                                         0.0645575   \n",
       "rank_test_score                                               51   \n",
       "split0_train_score                                      0.592227   \n",
       "split1_train_score                                      0.585052   \n",
       "split2_train_score                                      0.605033   \n",
       "split3_train_score                                      0.551188   \n",
       "split4_train_score                                      0.651844   \n",
       "mean_train_score                                        0.597069   \n",
       "std_train_score                                        0.0326699   \n",
       "\n",
       "                                                            81   \\\n",
       "mean_fit_time                                         0.0096786   \n",
       "std_fit_time                                        0.000232715   \n",
       "mean_score_time                                      0.00191956   \n",
       "std_score_time                                      6.84391e-05   \n",
       "param_C                                                     100   \n",
       "param_gamma                                               1e-05   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}   \n",
       "split0_test_score                                      0.601704   \n",
       "split1_test_score                                      0.624133   \n",
       "split2_test_score                                       0.60952   \n",
       "split3_test_score                                      0.688124   \n",
       "split4_test_score                                      0.488596   \n",
       "mean_test_score                                        0.602416   \n",
       "std_test_score                                        0.0645347   \n",
       "rank_test_score                                              52   \n",
       "split0_train_score                                     0.592191   \n",
       "split1_train_score                                     0.584999   \n",
       "split2_train_score                                     0.605019   \n",
       "split3_train_score                                     0.551095   \n",
       "split4_train_score                                     0.651827   \n",
       "mean_train_score                                       0.597026   \n",
       "std_train_score                                       0.0326947   \n",
       "\n",
       "                                                            36   \\\n",
       "mean_fit_time                                         0.0128288   \n",
       "std_fit_time                                         0.00142636   \n",
       "mean_score_time                                      0.00307374   \n",
       "std_score_time                                       0.00109435   \n",
       "param_C                                                      10   \n",
       "param_gamma                                              0.0001   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                      0.600582   \n",
       "split1_test_score                                      0.624413   \n",
       "split2_test_score                                      0.610046   \n",
       "split3_test_score                                      0.687887   \n",
       "split4_test_score                                      0.487511   \n",
       "mean_test_score                                        0.602088   \n",
       "std_test_score                                        0.0648895   \n",
       "rank_test_score                                              53   \n",
       "split0_train_score                                     0.591718   \n",
       "split1_train_score                                     0.585177   \n",
       "split2_train_score                                     0.604431   \n",
       "split3_train_score                                     0.550408   \n",
       "split4_train_score                                      0.65145   \n",
       "mean_train_score                                       0.596637   \n",
       "std_train_score                                        0.032735   \n",
       "\n",
       "                                                            60   \\\n",
       "mean_fit_time                                        0.00963945   \n",
       "std_fit_time                                        0.000176837   \n",
       "mean_score_time                                      0.00194988   \n",
       "std_score_time                                      7.93104e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                              0.0001   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                      0.600582   \n",
       "split1_test_score                                      0.624413   \n",
       "split2_test_score                                      0.610046   \n",
       "split3_test_score                                      0.687887   \n",
       "split4_test_score                                      0.487511   \n",
       "mean_test_score                                        0.602088   \n",
       "std_test_score                                        0.0648895   \n",
       "rank_test_score                                              53   \n",
       "split0_train_score                                     0.591718   \n",
       "split1_train_score                                     0.585177   \n",
       "split2_train_score                                     0.604431   \n",
       "split3_train_score                                     0.550408   \n",
       "split4_train_score                                      0.65145   \n",
       "mean_train_score                                       0.596637   \n",
       "std_train_score                                        0.032735   \n",
       "\n",
       "                                                          15   \\\n",
       "mean_fit_time                                       0.0119952   \n",
       "std_fit_time                                       0.00275842   \n",
       "mean_score_time                                    0.00201116   \n",
       "std_score_time                                    0.000111726   \n",
       "param_C                                                     1   \n",
       "param_gamma                                             0.001   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                    0.588835   \n",
       "split1_test_score                                    0.626915   \n",
       "split2_test_score                                    0.615747   \n",
       "split3_test_score                                    0.685008   \n",
       "split4_test_score                                    0.480609   \n",
       "mean_test_score                                      0.599423   \n",
       "std_test_score                                       0.067195   \n",
       "rank_test_score                                            55   \n",
       "split0_train_score                                   0.587692   \n",
       "split1_train_score                                    0.58307   \n",
       "split2_train_score                                   0.599671   \n",
       "split3_train_score                                   0.544759   \n",
       "split4_train_score                                   0.649127   \n",
       "mean_train_score                                     0.592864   \n",
       "std_train_score                                     0.0336115   \n",
       "\n",
       "                                                           90   \\\n",
       "mean_fit_time                                        0.0825444   \n",
       "std_fit_time                                        0.00515297   \n",
       "mean_score_time                                     0.00215025   \n",
       "std_score_time                                     0.000371346   \n",
       "param_C                                                    100   \n",
       "param_gamma                                               0.01   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.872598   \n",
       "split1_test_score                                      0.21817   \n",
       "split2_test_score                                     0.428369   \n",
       "split3_test_score                                     0.651112   \n",
       "split4_test_score                                     0.650916   \n",
       "mean_test_score                                       0.564233   \n",
       "std_test_score                                        0.222876   \n",
       "rank_test_score                                             56   \n",
       "split0_train_score                                    0.910485   \n",
       "split1_train_score                                    0.938649   \n",
       "split2_train_score                                    0.949865   \n",
       "split3_train_score                                    0.934242   \n",
       "split4_train_score                                    0.921044   \n",
       "mean_train_score                                      0.930857   \n",
       "std_train_score                                      0.0137465   \n",
       "\n",
       "                                                           44   \\\n",
       "mean_fit_time                                        0.0162938   \n",
       "std_fit_time                                         0.0036547   \n",
       "mean_score_time                                     0.00312042   \n",
       "std_score_time                                      0.00142066   \n",
       "param_C                                                     10   \n",
       "param_gamma                                               0.01   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "split0_test_score                                     0.739859   \n",
       "split1_test_score                                     0.506188   \n",
       "split2_test_score                                     0.327066   \n",
       "split3_test_score                                     0.540821   \n",
       "split4_test_score                                      0.61718   \n",
       "mean_test_score                                       0.546223   \n",
       "std_test_score                                        0.135788   \n",
       "rank_test_score                                             57   \n",
       "split0_train_score                                    0.637966   \n",
       "split1_train_score                                    0.728881   \n",
       "split2_train_score                                    0.735222   \n",
       "split3_train_score                                    0.713349   \n",
       "split4_train_score                                    0.711785   \n",
       "mean_train_score                                      0.705441   \n",
       "std_train_score                                      0.0349054   \n",
       "\n",
       "                                                           68   \\\n",
       "mean_fit_time                                        0.0124546   \n",
       "std_fit_time                                       0.000704902   \n",
       "mean_score_time                                     0.00192485   \n",
       "std_score_time                                     0.000231268   \n",
       "param_C                                                     10   \n",
       "param_gamma                                               0.01   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "split0_test_score                                     0.739859   \n",
       "split1_test_score                                     0.506188   \n",
       "split2_test_score                                     0.327066   \n",
       "split3_test_score                                     0.540821   \n",
       "split4_test_score                                      0.61718   \n",
       "mean_test_score                                       0.546223   \n",
       "std_test_score                                        0.135788   \n",
       "rank_test_score                                             57   \n",
       "split0_train_score                                    0.637966   \n",
       "split1_train_score                                    0.728881   \n",
       "split2_train_score                                    0.735222   \n",
       "split3_train_score                                    0.713349   \n",
       "split4_train_score                                    0.711785   \n",
       "mean_train_score                                      0.705441   \n",
       "std_train_score                                      0.0349054   \n",
       "\n",
       "                                                         69   \\\n",
       "mean_fit_time                                      0.0268692   \n",
       "std_fit_time                                      0.00346891   \n",
       "mean_score_time                                   0.00217791   \n",
       "std_score_time                                   0.000334487   \n",
       "param_C                                                   10   \n",
       "param_gamma                                              0.1   \n",
       "param_kernel                                             rbf   \n",
       "params              {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   0.435204   \n",
       "split1_test_score                                   0.609772   \n",
       "split2_test_score                                    0.53228   \n",
       "split3_test_score                                   0.670794   \n",
       "split4_test_score                                   0.390332   \n",
       "mean_test_score                                     0.527676   \n",
       "std_test_score                                      0.104554   \n",
       "rank_test_score                                           59   \n",
       "split0_train_score                                  0.971445   \n",
       "split1_train_score                                  0.980372   \n",
       "split2_train_score                                  0.986909   \n",
       "split3_train_score                                  0.975678   \n",
       "split4_train_score                                  0.981483   \n",
       "mean_train_score                                    0.979178   \n",
       "std_train_score                                   0.00526436   \n",
       "\n",
       "                                                         45   \\\n",
       "mean_fit_time                                       0.054113   \n",
       "std_fit_time                                       0.0136564   \n",
       "mean_score_time                                   0.00569782   \n",
       "std_score_time                                    0.00240317   \n",
       "param_C                                                   10   \n",
       "param_gamma                                              0.1   \n",
       "param_kernel                                             rbf   \n",
       "params              {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   0.435204   \n",
       "split1_test_score                                   0.609772   \n",
       "split2_test_score                                    0.53228   \n",
       "split3_test_score                                   0.670794   \n",
       "split4_test_score                                   0.390332   \n",
       "mean_test_score                                     0.527676   \n",
       "std_test_score                                      0.104554   \n",
       "rank_test_score                                           59   \n",
       "split0_train_score                                  0.971445   \n",
       "split1_train_score                                  0.980372   \n",
       "split2_train_score                                  0.986909   \n",
       "split3_train_score                                  0.975678   \n",
       "split4_train_score                                  0.981483   \n",
       "mean_train_score                                    0.979178   \n",
       "std_train_score                                   0.00526436   \n",
       "\n",
       "                                                        21   \\\n",
       "mean_fit_time                                     0.0153872   \n",
       "std_fit_time                                    0.000800545   \n",
       "mean_score_time                                  0.00210361   \n",
       "std_score_time                                  0.000293451   \n",
       "param_C                                                   1   \n",
       "param_gamma                                             0.1   \n",
       "param_kernel                                            rbf   \n",
       "params              {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "split0_test_score                                  0.355729   \n",
       "split1_test_score                                  0.639574   \n",
       "split2_test_score                                  0.584508   \n",
       "split3_test_score                                  0.664282   \n",
       "split4_test_score                                   0.38628   \n",
       "mean_test_score                                    0.526075   \n",
       "std_test_score                                     0.129582   \n",
       "rank_test_score                                          61   \n",
       "split0_train_score                                 0.739797   \n",
       "split1_train_score                                  0.67069   \n",
       "split2_train_score                                  0.68368   \n",
       "split3_train_score                                 0.667803   \n",
       "split4_train_score                                 0.763858   \n",
       "mean_train_score                                   0.705166   \n",
       "std_train_score                                   0.0392182   \n",
       "\n",
       "                                                            92   \\\n",
       "mean_fit_time                                         0.0155282   \n",
       "std_fit_time                                        0.000565562   \n",
       "mean_score_time                                      0.00139203   \n",
       "std_score_time                                      1.47508e-05   \n",
       "param_C                                                     100   \n",
       "param_gamma                                                0.01   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "split0_test_score                                        0.7155   \n",
       "split1_test_score                                      0.381934   \n",
       "split2_test_score                                      0.174701   \n",
       "split3_test_score                                      0.684936   \n",
       "split4_test_score                                      0.589428   \n",
       "mean_test_score                                          0.5093   \n",
       "std_test_score                                         0.203944   \n",
       "rank_test_score                                              62   \n",
       "split0_train_score                                     0.869933   \n",
       "split1_train_score                                     0.905785   \n",
       "split2_train_score                                     0.914233   \n",
       "split3_train_score                                     0.895889   \n",
       "split4_train_score                                     0.881388   \n",
       "mean_train_score                                       0.893446   \n",
       "std_train_score                                       0.0160537   \n",
       "\n",
       "                                                          93   \\\n",
       "mean_fit_time                                       0.0333967   \n",
       "std_fit_time                                       0.00356275   \n",
       "mean_score_time                                     0.0021246   \n",
       "std_score_time                                    0.000206216   \n",
       "param_C                                                   100   \n",
       "param_gamma                                               0.1   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "split0_test_score                                    0.428705   \n",
       "split1_test_score                                    0.565684   \n",
       "split2_test_score                                    0.505444   \n",
       "split3_test_score                                     0.60629   \n",
       "split4_test_score                                    0.364684   \n",
       "mean_test_score                                      0.494161   \n",
       "std_test_score                                      0.0881641   \n",
       "rank_test_score                                            63   \n",
       "split0_train_score                                   0.988381   \n",
       "split1_train_score                                   0.991501   \n",
       "split2_train_score                                   0.992268   \n",
       "split3_train_score                                   0.990185   \n",
       "split4_train_score                                   0.989694   \n",
       "mean_train_score                                     0.990406   \n",
       "std_train_score                                    0.00136558   \n",
       "\n",
       "                                                           117  \\\n",
       "mean_fit_time                                        0.0371149   \n",
       "std_fit_time                                        0.00410219   \n",
       "mean_score_time                                     0.00211377   \n",
       "std_score_time                                     0.000244468   \n",
       "param_C                                                   1000   \n",
       "param_gamma                                                0.1   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.428349   \n",
       "split1_test_score                                     0.547433   \n",
       "split2_test_score                                     0.505444   \n",
       "split3_test_score                                     0.614475   \n",
       "split4_test_score                                     0.361879   \n",
       "mean_test_score                                       0.491516   \n",
       "std_test_score                                        0.088584   \n",
       "rank_test_score                                             64   \n",
       "split0_train_score                                     0.99053   \n",
       "split1_train_score                                    0.992085   \n",
       "split2_train_score                                    0.992268   \n",
       "split3_train_score                                     0.99182   \n",
       "split4_train_score                                    0.989842   \n",
       "mean_train_score                                      0.991309   \n",
       "std_train_score                                     0.00095294   \n",
       "\n",
       "                                                            114  \\\n",
       "mean_fit_time                                           0.51129   \n",
       "std_fit_time                                          0.0464602   \n",
       "mean_score_time                                      0.00201344   \n",
       "std_score_time                                      4.90927e-05   \n",
       "param_C                                                    1000   \n",
       "param_gamma                                                0.01   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "split0_test_score                                      0.789621   \n",
       "split1_test_score                                      0.127063   \n",
       "split2_test_score                                      0.103674   \n",
       "split3_test_score                                      0.557753   \n",
       "split4_test_score                                      0.465256   \n",
       "mean_test_score                                        0.408673   \n",
       "std_test_score                                         0.261869   \n",
       "rank_test_score                                              65   \n",
       "split0_train_score                                      0.95171   \n",
       "split1_train_score                                      0.96656   \n",
       "split2_train_score                                     0.969074   \n",
       "split3_train_score                                     0.956054   \n",
       "split4_train_score                                     0.962414   \n",
       "mean_train_score                                       0.961162   \n",
       "std_train_score                                      0.00646102   \n",
       "\n",
       "                                                          20   \\\n",
       "mean_fit_time                                       0.0114686   \n",
       "std_fit_time                                       0.00180258   \n",
       "mean_score_time                                    0.00162678   \n",
       "std_score_time                                    5.12265e-05   \n",
       "param_C                                                     1   \n",
       "param_gamma                                              0.01   \n",
       "param_kernel                                             poly   \n",
       "params              {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "split0_test_score                                    0.462861   \n",
       "split1_test_score                                    0.406009   \n",
       "split2_test_score                                    0.236573   \n",
       "split3_test_score                                    0.358814   \n",
       "split4_test_score                                    0.446391   \n",
       "mean_test_score                                      0.382129   \n",
       "std_test_score                                      0.0811758   \n",
       "rank_test_score                                            66   \n",
       "split0_train_score                                   0.399571   \n",
       "split1_train_score                                   0.458646   \n",
       "split2_train_score                                   0.465686   \n",
       "split3_train_score                                   0.461254   \n",
       "split4_train_score                                   0.433699   \n",
       "mean_train_score                                     0.443771   \n",
       "std_train_score                                     0.0247479   \n",
       "\n",
       "                                                              113  \\\n",
       "mean_fit_time                                           0.0099514   \n",
       "std_fit_time                                           0.00106359   \n",
       "mean_score_time                                        0.00189443   \n",
       "std_score_time                                        0.000415294   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                 0.001   \n",
       "param_kernel                                                 poly   \n",
       "params              {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}   \n",
       "split0_test_score                                        0.462871   \n",
       "split1_test_score                                        0.406009   \n",
       "split2_test_score                                        0.236579   \n",
       "split3_test_score                                        0.358749   \n",
       "split4_test_score                                        0.446391   \n",
       "mean_test_score                                           0.38212   \n",
       "std_test_score                                          0.0811795   \n",
       "rank_test_score                                                67   \n",
       "split0_train_score                                       0.399578   \n",
       "split1_train_score                                       0.458646   \n",
       "split2_train_score                                       0.465692   \n",
       "split3_train_score                                       0.461202   \n",
       "split4_train_score                                         0.4337   \n",
       "mean_train_score                                         0.443763   \n",
       "std_train_score                                         0.0247392   \n",
       "\n",
       "                                                             99   \\\n",
       "mean_fit_time                                          0.0109783   \n",
       "std_fit_time                                         0.000220194   \n",
       "mean_score_time                                       0.00212893   \n",
       "std_score_time                                       5.49828e-05   \n",
       "param_C                                                     1000   \n",
       "param_gamma                                                1e-07   \n",
       "param_kernel                                                 rbf   \n",
       "params              {'C': 1000, 'gamma': 1e-07, 'kernel': 'rbf'}   \n",
       "split0_test_score                                       0.209262   \n",
       "split1_test_score                                       0.307656   \n",
       "split2_test_score                                       0.318283   \n",
       "split3_test_score                                       0.286452   \n",
       "split4_test_score                                       0.187067   \n",
       "mean_test_score                                         0.261744   \n",
       "std_test_score                                          0.053378   \n",
       "rank_test_score                                               68   \n",
       "split0_train_score                                      0.247978   \n",
       "split1_train_score                                      0.250188   \n",
       "split2_train_score                                       0.23653   \n",
       "split3_train_score                                      0.237407   \n",
       "split4_train_score                                      0.271125   \n",
       "mean_train_score                                        0.248646   \n",
       "std_train_score                                        0.0124999   \n",
       "\n",
       "                                                            78   \\\n",
       "mean_fit_time                                         0.0115071   \n",
       "std_fit_time                                         0.00119505   \n",
       "mean_score_time                                       0.0020956   \n",
       "std_score_time                                      6.48994e-05   \n",
       "param_C                                                     100   \n",
       "param_gamma                                               1e-06   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'}   \n",
       "split0_test_score                                       0.20929   \n",
       "split1_test_score                                      0.307486   \n",
       "split2_test_score                                      0.318587   \n",
       "split3_test_score                                      0.286178   \n",
       "split4_test_score                                      0.186997   \n",
       "mean_test_score                                        0.261708   \n",
       "std_test_score                                        0.0534023   \n",
       "rank_test_score                                              69   \n",
       "split0_train_score                                      0.24801   \n",
       "split1_train_score                                     0.250033   \n",
       "split2_train_score                                     0.236751   \n",
       "split3_train_score                                     0.237231   \n",
       "split4_train_score                                     0.270998   \n",
       "mean_train_score                                       0.248604   \n",
       "std_train_score                                       0.0124396   \n",
       "\n",
       "                                                           33   \\\n",
       "mean_fit_time                                        0.0141219   \n",
       "std_fit_time                                         0.0015622   \n",
       "mean_score_time                                     0.00290451   \n",
       "std_score_time                                     0.000466074   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-05   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.209252   \n",
       "split1_test_score                                      0.30733   \n",
       "split2_test_score                                     0.318505   \n",
       "split3_test_score                                     0.286017   \n",
       "split4_test_score                                     0.187002   \n",
       "mean_test_score                                       0.261621   \n",
       "std_test_score                                       0.0533495   \n",
       "rank_test_score                                             70   \n",
       "split0_train_score                                     0.24799   \n",
       "split1_train_score                                    0.249858   \n",
       "split2_train_score                                    0.236633   \n",
       "split3_train_score                                    0.237089   \n",
       "split4_train_score                                    0.271054   \n",
       "mean_train_score                                      0.248525   \n",
       "std_train_score                                      0.0125045   \n",
       "\n",
       "                                                           57   \\\n",
       "mean_fit_time                                        0.0113552   \n",
       "std_fit_time                                        0.00099134   \n",
       "mean_score_time                                     0.00211339   \n",
       "std_score_time                                     1.97064e-05   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-05   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.209252   \n",
       "split1_test_score                                      0.30733   \n",
       "split2_test_score                                     0.318505   \n",
       "split3_test_score                                     0.286017   \n",
       "split4_test_score                                     0.187002   \n",
       "mean_test_score                                       0.261621   \n",
       "std_test_score                                       0.0533495   \n",
       "rank_test_score                                             70   \n",
       "split0_train_score                                     0.24799   \n",
       "split1_train_score                                    0.249858   \n",
       "split2_train_score                                    0.236633   \n",
       "split3_train_score                                    0.237089   \n",
       "split4_train_score                                    0.271054   \n",
       "mean_train_score                                      0.248525   \n",
       "std_train_score                                      0.0125045   \n",
       "\n",
       "                                                           12   \\\n",
       "mean_fit_time                                        0.0107738   \n",
       "std_fit_time                                       0.000246801   \n",
       "mean_score_time                                     0.00206981   \n",
       "std_score_time                                     2.55936e-05   \n",
       "param_C                                                      1   \n",
       "param_gamma                                             0.0001   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     0.207828   \n",
       "split1_test_score                                     0.306075   \n",
       "split2_test_score                                     0.317609   \n",
       "split3_test_score                                      0.28462   \n",
       "split4_test_score                                     0.185961   \n",
       "mean_test_score                                       0.260419   \n",
       "std_test_score                                       0.0533865   \n",
       "rank_test_score                                             72   \n",
       "split0_train_score                                    0.246852   \n",
       "split1_train_score                                    0.248389   \n",
       "split2_train_score                                    0.235399   \n",
       "split3_train_score                                    0.235801   \n",
       "split4_train_score                                    0.269974   \n",
       "mean_train_score                                      0.247283   \n",
       "std_train_score                                      0.0125649   \n",
       "\n",
       "                                                             89   \\\n",
       "mean_fit_time                                         0.00866957   \n",
       "std_fit_time                                         0.000250648   \n",
       "mean_score_time                                       0.00160341   \n",
       "std_score_time                                       4.90256e-05   \n",
       "param_C                                                      100   \n",
       "param_gamma                                                0.001   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}   \n",
       "split0_test_score                                      0.0224603   \n",
       "split1_test_score                                      0.0637379   \n",
       "split2_test_score                                      0.0248847   \n",
       "split3_test_score                                      0.0123317   \n",
       "split4_test_score                                      0.0709321   \n",
       "mean_test_score                                        0.0388694   \n",
       "std_test_score                                         0.0237299   \n",
       "rank_test_score                                               73   \n",
       "split0_train_score                                     0.0781266   \n",
       "split1_train_score                                     0.0818926   \n",
       "split2_train_score                                     0.0942315   \n",
       "split3_train_score                                     0.0706144   \n",
       "split4_train_score                                     0.0537512   \n",
       "mean_train_score                                       0.0757232   \n",
       "std_train_score                                         0.013381   \n",
       "\n",
       "                                                             96   \\\n",
       "mean_fit_time                                          0.0119676   \n",
       "std_fit_time                                         0.000357338   \n",
       "mean_score_time                                        0.0024282   \n",
       "std_score_time                                       0.000226417   \n",
       "param_C                                                     1000   \n",
       "param_gamma                                                1e-08   \n",
       "param_kernel                                                 rbf   \n",
       "params              {'C': 1000, 'gamma': 1e-08, 'kernel': 'rbf'}   \n",
       "split0_test_score                                     -0.0406104   \n",
       "split1_test_score                                      0.0185972   \n",
       "split2_test_score                                     0.00850148   \n",
       "split3_test_score                                      -0.038756   \n",
       "split4_test_score                                     0.00471727   \n",
       "mean_test_score                                       -0.0095101   \n",
       "std_test_score                                         0.0250576   \n",
       "rank_test_score                                               74   \n",
       "split0_train_score                                   -0.00869535   \n",
       "split1_train_score                                   -0.00320676   \n",
       "split2_train_score                                   -0.00945768   \n",
       "split3_train_score                                   -0.00372862   \n",
       "split4_train_score                                   -0.00740829   \n",
       "mean_train_score                                     -0.00649934   \n",
       "std_train_score                                       0.00256587   \n",
       "\n",
       "                                                           54   \\\n",
       "mean_fit_time                                        0.0162487   \n",
       "std_fit_time                                        0.00175414   \n",
       "mean_score_time                                     0.00497398   \n",
       "std_score_time                                      0.00128642   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-06   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.0406615   \n",
       "split1_test_score                                    0.0187665   \n",
       "split2_test_score                                   0.00858414   \n",
       "split3_test_score                                   -0.0388902   \n",
       "split4_test_score                                   0.00464025   \n",
       "mean_test_score                                    -0.00951217   \n",
       "std_test_score                                       0.0251428   \n",
       "rank_test_score                                             75   \n",
       "split0_train_score                                 -0.00869177   \n",
       "split1_train_score                                 -0.00304668   \n",
       "split2_train_score                                 -0.00938972   \n",
       "split3_train_score                                 -0.00380458   \n",
       "split4_train_score                                 -0.00754216   \n",
       "mean_train_score                                   -0.00649498   \n",
       "std_train_score                                     0.00258577   \n",
       "\n",
       "                                                           30   \\\n",
       "mean_fit_time                                        0.0152688   \n",
       "std_fit_time                                        0.00392153   \n",
       "mean_score_time                                     0.00273275   \n",
       "std_score_time                                     0.000575175   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-06   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.0406615   \n",
       "split1_test_score                                    0.0187665   \n",
       "split2_test_score                                   0.00858414   \n",
       "split3_test_score                                   -0.0388902   \n",
       "split4_test_score                                   0.00464025   \n",
       "mean_test_score                                    -0.00951217   \n",
       "std_test_score                                       0.0251428   \n",
       "rank_test_score                                             75   \n",
       "split0_train_score                                 -0.00869177   \n",
       "split1_train_score                                 -0.00304668   \n",
       "split2_train_score                                 -0.00938972   \n",
       "split3_train_score                                 -0.00380458   \n",
       "split4_train_score                                 -0.00754216   \n",
       "mean_train_score                                   -0.00649498   \n",
       "std_train_score                                     0.00258577   \n",
       "\n",
       "                                                            75   \\\n",
       "mean_fit_time                                         0.0121399   \n",
       "std_fit_time                                        0.000787357   \n",
       "mean_score_time                                      0.00272908   \n",
       "std_score_time                                      0.000831464   \n",
       "param_C                                                     100   \n",
       "param_gamma                                               1e-07   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}   \n",
       "split0_test_score                                    -0.0406738   \n",
       "split1_test_score                                     0.0187646   \n",
       "split2_test_score                                     0.0086102   \n",
       "split3_test_score                                    -0.0389045   \n",
       "split4_test_score                                    0.00464004   \n",
       "mean_test_score                                      -0.0095127   \n",
       "std_test_score                                        0.0251525   \n",
       "rank_test_score                                              77   \n",
       "split0_train_score                                  -0.00875644   \n",
       "split1_train_score                                  -0.00304825   \n",
       "split2_train_score                                  -0.00936795   \n",
       "split3_train_score                                  -0.00381185   \n",
       "split4_train_score                                  -0.00754399   \n",
       "mean_train_score                                     -0.0065057   \n",
       "std_train_score                                      0.00259026   \n",
       "\n",
       "                                                          9    \\\n",
       "mean_fit_time                                       0.0132773   \n",
       "std_fit_time                                       0.00214403   \n",
       "mean_score_time                                    0.00229859   \n",
       "std_score_time                                    8.67696e-05   \n",
       "param_C                                                     1   \n",
       "param_gamma                                             1e-05   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.040687   \n",
       "split1_test_score                                   0.0187454   \n",
       "split2_test_score                                  0.00856116   \n",
       "split3_test_score                                  -0.0389132   \n",
       "split4_test_score                                  0.00462365   \n",
       "mean_test_score                                   -0.00953401   \n",
       "std_test_score                                      0.0251446   \n",
       "rank_test_score                                            78   \n",
       "split0_train_score                                -0.00871477   \n",
       "split1_train_score                                -0.00306835   \n",
       "split2_train_score                                -0.00941117   \n",
       "split3_train_score                                -0.00382536   \n",
       "split4_train_score                                -0.00756198   \n",
       "mean_train_score                                  -0.00651633   \n",
       "std_train_score                                    0.00258598   \n",
       "\n",
       "                                                            41   \\\n",
       "mean_fit_time                                        0.00845895   \n",
       "std_fit_time                                        0.000104217   \n",
       "mean_score_time                                      0.00159845   \n",
       "std_score_time                                      2.08785e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               0.001   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.0646869   \n",
       "split1_test_score                                    -0.0148211   \n",
       "split2_test_score                                    -0.0333825   \n",
       "split3_test_score                                    -0.0730773   \n",
       "split4_test_score                                    -0.0120532   \n",
       "mean_test_score                                      -0.0396042   \n",
       "std_test_score                                        0.0251458   \n",
       "rank_test_score                                              79   \n",
       "split0_train_score                                   -0.0271169   \n",
       "split1_train_score                                   -0.0219565   \n",
       "split2_train_score                                   -0.0294688   \n",
       "split3_train_score                                   -0.0224293   \n",
       "split4_train_score                                   -0.0333662   \n",
       "mean_train_score                                     -0.0268675   \n",
       "std_train_score                                      0.00430992   \n",
       "\n",
       "                                                            65   \\\n",
       "mean_fit_time                                        0.00883474   \n",
       "std_fit_time                                        0.000285163   \n",
       "mean_score_time                                      0.00168376   \n",
       "std_score_time                                      5.65076e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               0.001   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.0646869   \n",
       "split1_test_score                                    -0.0148211   \n",
       "split2_test_score                                    -0.0333825   \n",
       "split3_test_score                                    -0.0730773   \n",
       "split4_test_score                                    -0.0120532   \n",
       "mean_test_score                                      -0.0396042   \n",
       "std_test_score                                        0.0251458   \n",
       "rank_test_score                                              79   \n",
       "split0_train_score                                   -0.0271169   \n",
       "split1_train_score                                   -0.0219565   \n",
       "split2_train_score                                   -0.0294688   \n",
       "split3_train_score                                   -0.0224293   \n",
       "split4_train_score                                   -0.0333662   \n",
       "mean_train_score                                     -0.0268675   \n",
       "std_train_score                                      0.00430992   \n",
       "\n",
       "                                                            72   \\\n",
       "mean_fit_time                                         0.0116817   \n",
       "std_fit_time                                        0.000408853   \n",
       "mean_score_time                                       0.0021924   \n",
       "std_score_time                                      5.31877e-05   \n",
       "param_C                                                     100   \n",
       "param_gamma                                               1e-08   \n",
       "param_kernel                                                rbf   \n",
       "params              {'C': 100, 'gamma': 1e-08, 'kernel': 'rbf'}   \n",
       "split0_test_score                                    -0.0711034   \n",
       "split1_test_score                                     -0.018419   \n",
       "split2_test_score                                    -0.0358528   \n",
       "split3_test_score                                    -0.0799358   \n",
       "split4_test_score                                    -0.0187114   \n",
       "mean_test_score                                      -0.0448045   \n",
       "std_test_score                                        0.0260116   \n",
       "rank_test_score                                              81   \n",
       "split0_train_score                                   -0.0418348   \n",
       "split1_train_score                                    -0.034148   \n",
       "split2_train_score                                   -0.0422564   \n",
       "split3_train_score                                   -0.0351291   \n",
       "split4_train_score                                   -0.0434699   \n",
       "mean_train_score                                     -0.0393676   \n",
       "std_train_score                                      0.00391076   \n",
       "\n",
       "                                                           27   \\\n",
       "mean_fit_time                                        0.0122523   \n",
       "std_fit_time                                        0.00114588   \n",
       "mean_score_time                                     0.00217552   \n",
       "std_score_time                                     5.44387e-05   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-07   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.0710787   \n",
       "split1_test_score                                   -0.0184238   \n",
       "split2_test_score                                   -0.0358706   \n",
       "split3_test_score                                   -0.0799505   \n",
       "split4_test_score                                   -0.0187188   \n",
       "mean_test_score                                     -0.0448085   \n",
       "std_test_score                                       0.0260069   \n",
       "rank_test_score                                             82   \n",
       "split0_train_score                                  -0.0418113   \n",
       "split1_train_score                                  -0.0341527   \n",
       "split2_train_score                                  -0.0422712   \n",
       "split3_train_score                                  -0.0351372   \n",
       "split4_train_score                                  -0.0434851   \n",
       "mean_train_score                                    -0.0393715   \n",
       "std_train_score                                     0.00391021   \n",
       "\n",
       "                                                           51   \\\n",
       "mean_fit_time                                         0.022256   \n",
       "std_fit_time                                        0.00865037   \n",
       "mean_score_time                                     0.00398846   \n",
       "std_score_time                                      0.00165318   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-07   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.0710787   \n",
       "split1_test_score                                   -0.0184238   \n",
       "split2_test_score                                   -0.0358706   \n",
       "split3_test_score                                   -0.0799505   \n",
       "split4_test_score                                   -0.0187188   \n",
       "mean_test_score                                     -0.0448085   \n",
       "std_test_score                                       0.0260069   \n",
       "rank_test_score                                             82   \n",
       "split0_train_score                                  -0.0418113   \n",
       "split1_train_score                                  -0.0341527   \n",
       "split2_train_score                                  -0.0422712   \n",
       "split3_train_score                                  -0.0351372   \n",
       "split4_train_score                                  -0.0434851   \n",
       "mean_train_score                                    -0.0393715   \n",
       "std_train_score                                     0.00391021   \n",
       "\n",
       "                                                          6    \\\n",
       "mean_fit_time                                         0.01385   \n",
       "std_fit_time                                       0.00215134   \n",
       "mean_score_time                                    0.00286012   \n",
       "std_score_time                                    0.000653895   \n",
       "param_C                                                     1   \n",
       "param_gamma                                             1e-06   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}   \n",
       "split0_test_score                                  -0.0710784   \n",
       "split1_test_score                                  -0.0184247   \n",
       "split2_test_score                                  -0.0358714   \n",
       "split3_test_score                                  -0.0799506   \n",
       "split4_test_score                                   -0.018719   \n",
       "mean_test_score                                    -0.0448088   \n",
       "std_test_score                                      0.0260066   \n",
       "rank_test_score                                            84   \n",
       "split0_train_score                                  -0.041811   \n",
       "split1_train_score                                 -0.0341536   \n",
       "split2_train_score                                 -0.0422719   \n",
       "split3_train_score                                 -0.0351374   \n",
       "split4_train_score                                 -0.0434854   \n",
       "mean_train_score                                   -0.0393719   \n",
       "std_train_score                                    0.00391003   \n",
       "\n",
       "                                                           17   \\\n",
       "mean_fit_time                                       0.00917768   \n",
       "std_fit_time                                        0.00117965   \n",
       "mean_score_time                                     0.00159574   \n",
       "std_score_time                                     3.30813e-05   \n",
       "param_C                                                      1   \n",
       "param_gamma                                              0.001   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}   \n",
       "split0_test_score                                   -0.0741832   \n",
       "split1_test_score                                   -0.0224651   \n",
       "split2_test_score                                   -0.0396589   \n",
       "split3_test_score                                   -0.0825685   \n",
       "split4_test_score                                   -0.0207454   \n",
       "mean_test_score                                     -0.0479242   \n",
       "std_test_score                                       0.0258648   \n",
       "rank_test_score                                             85   \n",
       "split0_train_score                                  -0.0435839   \n",
       "split1_train_score                                  -0.0360456   \n",
       "split2_train_score                                  -0.0438874   \n",
       "split3_train_score                                  -0.0359387   \n",
       "split4_train_score                                  -0.0459806   \n",
       "mean_train_score                                    -0.0410872   \n",
       "std_train_score                                     0.00424133   \n",
       "\n",
       "                                                               110  \\\n",
       "mean_fit_time                                            0.0101625   \n",
       "std_fit_time                                            0.00216352   \n",
       "mean_score_time                                         0.00189486   \n",
       "std_score_time                                         0.000311928   \n",
       "param_C                                                       1000   \n",
       "param_gamma                                                 0.0001   \n",
       "param_kernel                                                  poly   \n",
       "params              {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "split0_test_score                                       -0.0741832   \n",
       "split1_test_score                                       -0.0224651   \n",
       "split2_test_score                                       -0.0396589   \n",
       "split3_test_score                                       -0.0825685   \n",
       "split4_test_score                                       -0.0207454   \n",
       "mean_test_score                                         -0.0479242   \n",
       "std_test_score                                           0.0258648   \n",
       "rank_test_score                                                 86   \n",
       "split0_train_score                                      -0.0435839   \n",
       "split1_train_score                                      -0.0360456   \n",
       "split2_train_score                                      -0.0438874   \n",
       "split3_train_score                                      -0.0359387   \n",
       "split4_train_score                                      -0.0459806   \n",
       "mean_train_score                                        -0.0410872   \n",
       "std_train_score                                         0.00424133   \n",
       "\n",
       "                                                           48   \\\n",
       "mean_fit_time                                        0.0134258   \n",
       "std_fit_time                                        0.00288659   \n",
       "mean_score_time                                     0.00260062   \n",
       "std_score_time                                      0.00058165   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-08   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.0748417   \n",
       "split1_test_score                                    -0.022919   \n",
       "split2_test_score                                   -0.0399328   \n",
       "split3_test_score                                   -0.0832376   \n",
       "split4_test_score                                   -0.0214321   \n",
       "mean_test_score                                     -0.0484726   \n",
       "std_test_score                                        0.025927   \n",
       "rank_test_score                                             87   \n",
       "split0_train_score                                  -0.0458417   \n",
       "split1_train_score                                  -0.0379867   \n",
       "split2_train_score                                  -0.0452058   \n",
       "split3_train_score                                  -0.0378425   \n",
       "split4_train_score                                   -0.047834   \n",
       "mean_train_score                                    -0.0429422   \n",
       "std_train_score                                     0.00419582   \n",
       "\n",
       "                                                           24   \\\n",
       "mean_fit_time                                         0.013322   \n",
       "std_fit_time                                        0.00155402   \n",
       "mean_score_time                                     0.00247021   \n",
       "std_score_time                                     0.000341341   \n",
       "param_C                                                     10   \n",
       "param_gamma                                              1e-08   \n",
       "param_kernel                                               rbf   \n",
       "params              {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}   \n",
       "split0_test_score                                   -0.0748417   \n",
       "split1_test_score                                    -0.022919   \n",
       "split2_test_score                                   -0.0399328   \n",
       "split3_test_score                                   -0.0832376   \n",
       "split4_test_score                                   -0.0214321   \n",
       "mean_test_score                                     -0.0484726   \n",
       "std_test_score                                        0.025927   \n",
       "rank_test_score                                             87   \n",
       "split0_train_score                                  -0.0458417   \n",
       "split1_train_score                                  -0.0379867   \n",
       "split2_train_score                                  -0.0452058   \n",
       "split3_train_score                                  -0.0378425   \n",
       "split4_train_score                                   -0.047834   \n",
       "mean_train_score                                    -0.0429422   \n",
       "std_train_score                                     0.00419582   \n",
       "\n",
       "                                                          3    \\\n",
       "mean_fit_time                                        0.017822   \n",
       "std_fit_time                                       0.00470855   \n",
       "mean_score_time                                    0.00351958   \n",
       "std_score_time                                     0.00120278   \n",
       "param_C                                                     1   \n",
       "param_gamma                                             1e-07   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 1, 'gamma': 1e-07, 'kernel': 'rbf'}   \n",
       "split0_test_score                                  -0.0748393   \n",
       "split1_test_score                                  -0.0229194   \n",
       "split2_test_score                                  -0.0399346   \n",
       "split3_test_score                                  -0.0832391   \n",
       "split4_test_score                                  -0.0214328   \n",
       "mean_test_score                                    -0.0484731   \n",
       "std_test_score                                      0.0259265   \n",
       "rank_test_score                                            89   \n",
       "split0_train_score                                 -0.0458394   \n",
       "split1_train_score                                 -0.0379872   \n",
       "split2_train_score                                 -0.0452074   \n",
       "split3_train_score                                 -0.0378434   \n",
       "split4_train_score                                 -0.0478355   \n",
       "mean_train_score                                   -0.0429426   \n",
       "std_train_score                                     0.0041957   \n",
       "\n",
       "                                                         23   \\\n",
       "mean_fit_time                                      0.0428481   \n",
       "std_fit_time                                      0.00782124   \n",
       "mean_score_time                                   0.00162797   \n",
       "std_score_time                                   0.000174497   \n",
       "param_C                                                    1   \n",
       "param_gamma                                              0.1   \n",
       "param_kernel                                            poly   \n",
       "params              {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "split0_test_score                                   0.207179   \n",
       "split1_test_score                                   0.199718   \n",
       "split2_test_score                                  -0.665647   \n",
       "split3_test_score                                   0.437063   \n",
       "split4_test_score                                  -0.420811   \n",
       "mean_test_score                                   -0.0484995   \n",
       "std_test_score                                      0.420057   \n",
       "rank_test_score                                           90   \n",
       "split0_train_score                                  0.936629   \n",
       "split1_train_score                                  0.960848   \n",
       "split2_train_score                                  0.959221   \n",
       "split3_train_score                                   0.94876   \n",
       "split4_train_score                                  0.950617   \n",
       "mean_train_score                                    0.951215   \n",
       "std_train_score                                   0.00867213   \n",
       "\n",
       "                                                             116  \\\n",
       "mean_fit_time                                          0.0495638   \n",
       "std_fit_time                                           0.0124921   \n",
       "mean_score_time                                       0.00159678   \n",
       "std_score_time                                       8.67851e-05   \n",
       "param_C                                                     1000   \n",
       "param_gamma                                                 0.01   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'}   \n",
       "split0_test_score                                       0.207236   \n",
       "split1_test_score                                       0.199733   \n",
       "split2_test_score                                      -0.665923   \n",
       "split3_test_score                                       0.436967   \n",
       "split4_test_score                                      -0.420997   \n",
       "mean_test_score                                       -0.0485968   \n",
       "std_test_score                                          0.420158   \n",
       "rank_test_score                                               91   \n",
       "split0_train_score                                       0.93663   \n",
       "split1_train_score                                      0.960849   \n",
       "split2_train_score                                      0.959221   \n",
       "split3_train_score                                      0.948765   \n",
       "split4_train_score                                      0.950617   \n",
       "mean_train_score                                        0.951217   \n",
       "std_train_score                                       0.00867172   \n",
       "\n",
       "                                                              86   \\\n",
       "mean_fit_time                                          0.00837646   \n",
       "std_fit_time                                          0.000181587   \n",
       "mean_score_time                                        0.00158491   \n",
       "std_score_time                                        5.68614e-05   \n",
       "param_C                                                       100   \n",
       "param_gamma                                                0.0001   \n",
       "param_kernel                                                 poly   \n",
       "params              {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "split0_test_score                                      -0.0751064   \n",
       "split1_test_score                                      -0.0233246   \n",
       "split2_test_score                                       -0.040279   \n",
       "split3_test_score                                      -0.0835398   \n",
       "split4_test_score                                      -0.0216359   \n",
       "mean_test_score                                        -0.0487771   \n",
       "std_test_score                                          0.0259167   \n",
       "rank_test_score                                                92   \n",
       "split0_train_score                                     -0.0459673   \n",
       "split1_train_score                                     -0.0381701   \n",
       "split2_train_score                                     -0.0453396   \n",
       "split3_train_score                                     -0.0379382   \n",
       "split4_train_score                                     -0.0480769   \n",
       "mean_train_score                                       -0.0430984   \n",
       "std_train_score                                        0.00421793   \n",
       "\n",
       "                                                          0    \\\n",
       "mean_fit_time                                       0.0145412   \n",
       "std_fit_time                                       0.00155143   \n",
       "mean_score_time                                    0.00316119   \n",
       "std_score_time                                     0.00149598   \n",
       "param_C                                                     1   \n",
       "param_gamma                                             1e-08   \n",
       "param_kernel                                              rbf   \n",
       "params              {'C': 1, 'gamma': 1e-08, 'kernel': 'rbf'}   \n",
       "split0_test_score                                  -0.0751722   \n",
       "split1_test_score                                    -0.02337   \n",
       "split2_test_score                                  -0.0403064   \n",
       "split3_test_score                                  -0.0836068   \n",
       "split4_test_score                                  -0.0217046   \n",
       "mean_test_score                                     -0.048832   \n",
       "std_test_score                                      0.0259229   \n",
       "rank_test_score                                            93   \n",
       "split0_train_score                                 -0.0462016   \n",
       "split1_train_score                                 -0.0383714   \n",
       "split2_train_score                                 -0.0454716   \n",
       "split3_train_score                                 -0.0381357   \n",
       "split4_train_score                                 -0.0482713   \n",
       "mean_train_score                                   -0.0432903   \n",
       "std_train_score                                    0.00421448   \n",
       "\n",
       "                                                             38   \\\n",
       "mean_fit_time                                         0.00888281   \n",
       "std_fit_time                                         0.000505284   \n",
       "mean_score_time                                        0.0017004   \n",
       "std_score_time                                       5.49529e-05   \n",
       "param_C                                                       10   \n",
       "param_gamma                                               0.0001   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.0751987   \n",
       "split1_test_score                                     -0.0234106   \n",
       "split2_test_score                                     -0.0403411   \n",
       "split3_test_score                                     -0.0836371   \n",
       "split4_test_score                                      -0.021725   \n",
       "mean_test_score                                       -0.0488625   \n",
       "std_test_score                                         0.0259219   \n",
       "rank_test_score                                               94   \n",
       "split0_train_score                                     -0.046214   \n",
       "split1_train_score                                    -0.0383896   \n",
       "split2_train_score                                     -0.045485   \n",
       "split3_train_score                                    -0.0381452   \n",
       "split4_train_score                                    -0.0482955   \n",
       "mean_train_score                                      -0.0433059   \n",
       "std_train_score                                       0.00421672   \n",
       "\n",
       "                                                             62   \\\n",
       "mean_fit_time                                          0.0142863   \n",
       "std_fit_time                                         0.000651284   \n",
       "mean_score_time                                       0.00346417   \n",
       "std_score_time                                        0.00168479   \n",
       "param_C                                                       10   \n",
       "param_gamma                                               0.0001   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.0751987   \n",
       "split1_test_score                                     -0.0234106   \n",
       "split2_test_score                                     -0.0403411   \n",
       "split3_test_score                                     -0.0836371   \n",
       "split4_test_score                                      -0.021725   \n",
       "mean_test_score                                       -0.0488625   \n",
       "std_test_score                                         0.0259219   \n",
       "rank_test_score                                               94   \n",
       "split0_train_score                                     -0.046214   \n",
       "split1_train_score                                    -0.0383896   \n",
       "split2_train_score                                     -0.045485   \n",
       "split3_train_score                                    -0.0381452   \n",
       "split4_train_score                                    -0.0482955   \n",
       "mean_train_score                                      -0.0433059   \n",
       "std_train_score                                       0.00421672   \n",
       "\n",
       "                                                              107  \\\n",
       "mean_fit_time                                           0.0151299   \n",
       "std_fit_time                                           0.00342157   \n",
       "mean_score_time                                          0.003196   \n",
       "std_score_time                                        0.000389369   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                 1e-05   \n",
       "param_kernel                                                 poly   \n",
       "params              {'C': 1000, 'gamma': 1e-05, 'kernel': 'poly'}   \n",
       "split0_test_score                                      -0.0752079   \n",
       "split1_test_score                                      -0.0234192   \n",
       "split2_test_score                                      -0.0403473   \n",
       "split3_test_score                                      -0.0836468   \n",
       "split4_test_score                                      -0.0217339   \n",
       "mean_test_score                                         -0.048871   \n",
       "std_test_score                                          0.0259224   \n",
       "rank_test_score                                                96   \n",
       "split0_train_score                                     -0.0462388   \n",
       "split1_train_score                                     -0.0384117   \n",
       "split2_train_score                                     -0.0454995   \n",
       "split3_train_score                                      -0.038166   \n",
       "split4_train_score                                     -0.0483174   \n",
       "mean_train_score                                       -0.0433267   \n",
       "std_train_score                                        0.00421661   \n",
       "\n",
       "                                                            14   \\\n",
       "mean_fit_time                                        0.00847254   \n",
       "std_fit_time                                        0.000403908   \n",
       "mean_score_time                                      0.00159245   \n",
       "std_score_time                                      3.46098e-05   \n",
       "param_C                                                       1   \n",
       "param_gamma                                              0.0001   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.0752079   \n",
       "split1_test_score                                    -0.0234192   \n",
       "split2_test_score                                    -0.0403473   \n",
       "split3_test_score                                    -0.0836468   \n",
       "split4_test_score                                    -0.0217339   \n",
       "mean_test_score                                       -0.048871   \n",
       "std_test_score                                        0.0259224   \n",
       "rank_test_score                                              97   \n",
       "split0_train_score                                   -0.0462388   \n",
       "split1_train_score                                   -0.0384117   \n",
       "split2_train_score                                   -0.0454995   \n",
       "split3_train_score                                    -0.038166   \n",
       "split4_train_score                                   -0.0483174   \n",
       "mean_train_score                                     -0.0433267   \n",
       "std_train_score                                      0.00421661   \n",
       "\n",
       "                                                             83   \\\n",
       "mean_fit_time                                         0.00833464   \n",
       "std_fit_time                                         0.000106425   \n",
       "mean_score_time                                       0.00157757   \n",
       "std_score_time                                       2.15187e-05   \n",
       "param_C                                                      100   \n",
       "param_gamma                                                1e-05   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 100, 'gamma': 1e-05, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.0752089   \n",
       "split1_test_score                                       -0.02342   \n",
       "split2_test_score                                     -0.0403479   \n",
       "split3_test_score                                     -0.0836477   \n",
       "split4_test_score                                     -0.0217348   \n",
       "mean_test_score                                       -0.0488719   \n",
       "std_test_score                                         0.0259225   \n",
       "rank_test_score                                               98   \n",
       "split0_train_score                                    -0.0462413   \n",
       "split1_train_score                                    -0.0384139   \n",
       "split2_train_score                                     -0.045501   \n",
       "split3_train_score                                    -0.0381681   \n",
       "split4_train_score                                    -0.0483196   \n",
       "mean_train_score                                      -0.0433288   \n",
       "std_train_score                                        0.0042166   \n",
       "\n",
       "                                                            59   \\\n",
       "mean_fit_time                                         0.0109859   \n",
       "std_fit_time                                          0.0034197   \n",
       "mean_score_time                                      0.00390654   \n",
       "std_score_time                                       0.00364171   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-05   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-05, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.0752089   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836478   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                      -0.0488719   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                              99   \n",
       "split0_train_score                                   -0.0462415   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455011   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483198   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                            35   \\\n",
       "mean_fit_time                                         0.0112264   \n",
       "std_fit_time                                        0.000684137   \n",
       "mean_score_time                                       0.0024384   \n",
       "std_score_time                                      0.000494879   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-05   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-05, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.0752089   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836478   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                      -0.0488719   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                              99   \n",
       "split0_train_score                                   -0.0462415   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455011   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483198   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                              104  \\\n",
       "mean_fit_time                                           0.0110484   \n",
       "std_fit_time                                           0.00213602   \n",
       "mean_score_time                                        0.00206017   \n",
       "std_score_time                                        0.000268947   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                 1e-06   \n",
       "param_kernel                                                 poly   \n",
       "params              {'C': 1000, 'gamma': 1e-06, 'kernel': 'poly'}   \n",
       "split0_test_score                                       -0.075209   \n",
       "split1_test_score                                      -0.0234201   \n",
       "split2_test_score                                      -0.0403479   \n",
       "split3_test_score                                      -0.0836479   \n",
       "split4_test_score                                      -0.0217349   \n",
       "mean_test_score                                         -0.048872   \n",
       "std_test_score                                          0.0259225   \n",
       "rank_test_score                                               101   \n",
       "split0_train_score                                     -0.0462416   \n",
       "split1_train_score                                     -0.0384141   \n",
       "split2_train_score                                     -0.0455012   \n",
       "split3_train_score                                     -0.0381683   \n",
       "split4_train_score                                     -0.0483199   \n",
       "mean_train_score                                        -0.043329   \n",
       "std_train_score                                         0.0042166   \n",
       "\n",
       "                                                           11   \\\n",
       "mean_fit_time                                        0.0101967   \n",
       "std_fit_time                                        0.00217883   \n",
       "mean_score_time                                     0.00230145   \n",
       "std_score_time                                     0.000592842   \n",
       "param_C                                                      1   \n",
       "param_gamma                                              1e-05   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 1, 'gamma': 1e-05, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.075209   \n",
       "split1_test_score                                   -0.0234201   \n",
       "split2_test_score                                   -0.0403479   \n",
       "split3_test_score                                   -0.0836479   \n",
       "split4_test_score                                   -0.0217349   \n",
       "mean_test_score                                      -0.048872   \n",
       "std_test_score                                       0.0259225   \n",
       "rank_test_score                                            101   \n",
       "split0_train_score                                  -0.0462416   \n",
       "split1_train_score                                  -0.0384141   \n",
       "split2_train_score                                  -0.0455012   \n",
       "split3_train_score                                  -0.0381683   \n",
       "split4_train_score                                  -0.0483199   \n",
       "mean_train_score                                     -0.043329   \n",
       "std_train_score                                      0.0042166   \n",
       "\n",
       "                                                             80   \\\n",
       "mean_fit_time                                         0.00857086   \n",
       "std_fit_time                                         0.000165773   \n",
       "mean_score_time                                       0.00188346   \n",
       "std_score_time                                       0.000140314   \n",
       "param_C                                                      100   \n",
       "param_gamma                                                1e-06   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 100, 'gamma': 1e-06, 'kernel': 'poly'}   \n",
       "split0_test_score                                      -0.075209   \n",
       "split1_test_score                                     -0.0234201   \n",
       "split2_test_score                                     -0.0403479   \n",
       "split3_test_score                                     -0.0836479   \n",
       "split4_test_score                                     -0.0217349   \n",
       "mean_test_score                                        -0.048872   \n",
       "std_test_score                                         0.0259225   \n",
       "rank_test_score                                              103   \n",
       "split0_train_score                                    -0.0462416   \n",
       "split1_train_score                                    -0.0384141   \n",
       "split2_train_score                                    -0.0455012   \n",
       "split3_train_score                                    -0.0381683   \n",
       "split4_train_score                                    -0.0483199   \n",
       "mean_train_score                                       -0.043329   \n",
       "std_train_score                                        0.0042166   \n",
       "\n",
       "                                                            32   \\\n",
       "mean_fit_time                                         0.0108459   \n",
       "std_fit_time                                        0.000330153   \n",
       "mean_score_time                                      0.00207701   \n",
       "std_score_time                                      2.88944e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-06   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-06, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.075209   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836479   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                       -0.048872   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                             104   \n",
       "split0_train_score                                   -0.0462416   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455012   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483199   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                            56   \\\n",
       "mean_fit_time                                        0.00839977   \n",
       "std_fit_time                                        0.000168023   \n",
       "mean_score_time                                      0.00159464   \n",
       "std_score_time                                      1.54863e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-06   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-06, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.075209   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836479   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                       -0.048872   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                             104   \n",
       "split0_train_score                                   -0.0462416   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455012   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483199   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                              101  \\\n",
       "mean_fit_time                                           0.0118126   \n",
       "std_fit_time                                           0.00334896   \n",
       "mean_score_time                                        0.00196414   \n",
       "std_score_time                                        0.000484639   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                 1e-07   \n",
       "param_kernel                                                 poly   \n",
       "params              {'C': 1000, 'gamma': 1e-07, 'kernel': 'poly'}   \n",
       "split0_test_score                                       -0.075209   \n",
       "split1_test_score                                      -0.0234201   \n",
       "split2_test_score                                      -0.0403479   \n",
       "split3_test_score                                      -0.0836479   \n",
       "split4_test_score                                      -0.0217349   \n",
       "mean_test_score                                         -0.048872   \n",
       "std_test_score                                          0.0259225   \n",
       "rank_test_score                                               106   \n",
       "split0_train_score                                     -0.0462416   \n",
       "split1_train_score                                     -0.0384141   \n",
       "split2_train_score                                     -0.0455012   \n",
       "split3_train_score                                     -0.0381683   \n",
       "split4_train_score                                     -0.0483199   \n",
       "mean_train_score                                        -0.043329   \n",
       "std_train_score                                         0.0042166   \n",
       "\n",
       "                                                           8    \\\n",
       "mean_fit_time                                       0.00886354   \n",
       "std_fit_time                                       0.000395659   \n",
       "mean_score_time                                      0.0016973   \n",
       "std_score_time                                     7.18644e-05   \n",
       "param_C                                                      1   \n",
       "param_gamma                                              1e-06   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 1, 'gamma': 1e-06, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.075209   \n",
       "split1_test_score                                   -0.0234201   \n",
       "split2_test_score                                   -0.0403479   \n",
       "split3_test_score                                   -0.0836479   \n",
       "split4_test_score                                   -0.0217349   \n",
       "mean_test_score                                      -0.048872   \n",
       "std_test_score                                       0.0259225   \n",
       "rank_test_score                                            106   \n",
       "split0_train_score                                  -0.0462416   \n",
       "split1_train_score                                  -0.0384141   \n",
       "split2_train_score                                  -0.0455012   \n",
       "split3_train_score                                  -0.0381683   \n",
       "split4_train_score                                  -0.0483199   \n",
       "mean_train_score                                     -0.043329   \n",
       "std_train_score                                      0.0042166   \n",
       "\n",
       "                                                             77   \\\n",
       "mean_fit_time                                         0.00835123   \n",
       "std_fit_time                                         8.77985e-05   \n",
       "mean_score_time                                       0.00159059   \n",
       "std_score_time                                       2.69126e-05   \n",
       "param_C                                                      100   \n",
       "param_gamma                                                1e-07   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 100, 'gamma': 1e-07, 'kernel': 'poly'}   \n",
       "split0_test_score                                      -0.075209   \n",
       "split1_test_score                                     -0.0234201   \n",
       "split2_test_score                                     -0.0403479   \n",
       "split3_test_score                                     -0.0836479   \n",
       "split4_test_score                                     -0.0217349   \n",
       "mean_test_score                                        -0.048872   \n",
       "std_test_score                                         0.0259225   \n",
       "rank_test_score                                              108   \n",
       "split0_train_score                                    -0.0462416   \n",
       "split1_train_score                                    -0.0384141   \n",
       "split2_train_score                                    -0.0455012   \n",
       "split3_train_score                                    -0.0381683   \n",
       "split4_train_score                                    -0.0483199   \n",
       "mean_train_score                                       -0.043329   \n",
       "std_train_score                                        0.0042166   \n",
       "\n",
       "                                                            53   \\\n",
       "mean_fit_time                                         0.0128046   \n",
       "std_fit_time                                          0.0020431   \n",
       "mean_score_time                                      0.00334668   \n",
       "std_score_time                                       0.00138545   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-07   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-07, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.075209   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836479   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                       -0.048872   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                             109   \n",
       "split0_train_score                                   -0.0462416   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455012   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483199   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                            29   \\\n",
       "mean_fit_time                                         0.0105841   \n",
       "std_fit_time                                         0.00132833   \n",
       "mean_score_time                                      0.00223112   \n",
       "std_score_time                                      0.000390192   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-07   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-07, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.075209   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836479   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                       -0.048872   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                             109   \n",
       "split0_train_score                                   -0.0462416   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455012   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483199   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                           5    \\\n",
       "mean_fit_time                                       0.00911298   \n",
       "std_fit_time                                         0.0004131   \n",
       "mean_score_time                                     0.00195694   \n",
       "std_score_time                                     0.000271321   \n",
       "param_C                                                      1   \n",
       "param_gamma                                              1e-07   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 1, 'gamma': 1e-07, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.075209   \n",
       "split1_test_score                                   -0.0234201   \n",
       "split2_test_score                                   -0.0403479   \n",
       "split3_test_score                                   -0.0836479   \n",
       "split4_test_score                                   -0.0217349   \n",
       "mean_test_score                                      -0.048872   \n",
       "std_test_score                                       0.0259225   \n",
       "rank_test_score                                            111   \n",
       "split0_train_score                                  -0.0462416   \n",
       "split1_train_score                                  -0.0384141   \n",
       "split2_train_score                                  -0.0455012   \n",
       "split3_train_score                                  -0.0381683   \n",
       "split4_train_score                                  -0.0483199   \n",
       "mean_train_score                                     -0.043329   \n",
       "std_train_score                                      0.0042166   \n",
       "\n",
       "                                                              98   \\\n",
       "mean_fit_time                                           0.0085598   \n",
       "std_fit_time                                          0.000127599   \n",
       "mean_score_time                                        0.00181146   \n",
       "std_score_time                                        0.000109793   \n",
       "param_C                                                      1000   \n",
       "param_gamma                                                 1e-08   \n",
       "param_kernel                                                 poly   \n",
       "params              {'C': 1000, 'gamma': 1e-08, 'kernel': 'poly'}   \n",
       "split0_test_score                                       -0.075209   \n",
       "split1_test_score                                      -0.0234201   \n",
       "split2_test_score                                      -0.0403479   \n",
       "split3_test_score                                      -0.0836479   \n",
       "split4_test_score                                      -0.0217349   \n",
       "mean_test_score                                         -0.048872   \n",
       "std_test_score                                          0.0259225   \n",
       "rank_test_score                                               111   \n",
       "split0_train_score                                     -0.0462416   \n",
       "split1_train_score                                     -0.0384141   \n",
       "split2_train_score                                     -0.0455012   \n",
       "split3_train_score                                     -0.0381683   \n",
       "split4_train_score                                     -0.0483199   \n",
       "mean_train_score                                        -0.043329   \n",
       "std_train_score                                         0.0042166   \n",
       "\n",
       "                                                             74   \\\n",
       "mean_fit_time                                         0.00839963   \n",
       "std_fit_time                                         0.000141278   \n",
       "mean_score_time                                       0.00161595   \n",
       "std_score_time                                       4.13576e-05   \n",
       "param_C                                                      100   \n",
       "param_gamma                                                1e-08   \n",
       "param_kernel                                                poly   \n",
       "params              {'C': 100, 'gamma': 1e-08, 'kernel': 'poly'}   \n",
       "split0_test_score                                      -0.075209   \n",
       "split1_test_score                                     -0.0234201   \n",
       "split2_test_score                                     -0.0403479   \n",
       "split3_test_score                                     -0.0836479   \n",
       "split4_test_score                                     -0.0217349   \n",
       "mean_test_score                                        -0.048872   \n",
       "std_test_score                                         0.0259225   \n",
       "rank_test_score                                              113   \n",
       "split0_train_score                                    -0.0462416   \n",
       "split1_train_score                                    -0.0384141   \n",
       "split2_train_score                                    -0.0455012   \n",
       "split3_train_score                                    -0.0381683   \n",
       "split4_train_score                                    -0.0483199   \n",
       "mean_train_score                                       -0.043329   \n",
       "std_train_score                                        0.0042166   \n",
       "\n",
       "                                                           2    \\\n",
       "mean_fit_time                                       0.00909395   \n",
       "std_fit_time                                       0.000576284   \n",
       "mean_score_time                                     0.00198531   \n",
       "std_score_time                                     0.000522479   \n",
       "param_C                                                      1   \n",
       "param_gamma                                              1e-08   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 1, 'gamma': 1e-08, 'kernel': 'poly'}   \n",
       "split0_test_score                                    -0.075209   \n",
       "split1_test_score                                   -0.0234201   \n",
       "split2_test_score                                   -0.0403479   \n",
       "split3_test_score                                   -0.0836479   \n",
       "split4_test_score                                   -0.0217349   \n",
       "mean_test_score                                      -0.048872   \n",
       "std_test_score                                       0.0259225   \n",
       "rank_test_score                                            114   \n",
       "split0_train_score                                  -0.0462416   \n",
       "split1_train_score                                  -0.0384141   \n",
       "split2_train_score                                  -0.0455012   \n",
       "split3_train_score                                  -0.0381683   \n",
       "split4_train_score                                  -0.0483199   \n",
       "mean_train_score                                     -0.043329   \n",
       "std_train_score                                      0.0042166   \n",
       "\n",
       "                                                            50   \\\n",
       "mean_fit_time                                         0.0168963   \n",
       "std_fit_time                                         0.00259944   \n",
       "mean_score_time                                      0.00298128   \n",
       "std_score_time                                      0.000623668   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-08   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-08, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.075209   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836479   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                       -0.048872   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                             114   \n",
       "split0_train_score                                   -0.0462416   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455012   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483199   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                            26   \\\n",
       "mean_fit_time                                        0.00849075   \n",
       "std_fit_time                                        0.000311575   \n",
       "mean_score_time                                      0.00160985   \n",
       "std_score_time                                      6.21038e-05   \n",
       "param_C                                                      10   \n",
       "param_gamma                                               1e-08   \n",
       "param_kernel                                               poly   \n",
       "params              {'C': 10, 'gamma': 1e-08, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -0.075209   \n",
       "split1_test_score                                    -0.0234201   \n",
       "split2_test_score                                    -0.0403479   \n",
       "split3_test_score                                    -0.0836479   \n",
       "split4_test_score                                    -0.0217349   \n",
       "mean_test_score                                       -0.048872   \n",
       "std_test_score                                        0.0259225   \n",
       "rank_test_score                                             114   \n",
       "split0_train_score                                   -0.0462416   \n",
       "split1_train_score                                   -0.0384141   \n",
       "split2_train_score                                   -0.0455012   \n",
       "split3_train_score                                   -0.0381683   \n",
       "split4_train_score                                   -0.0483199   \n",
       "mean_train_score                                      -0.043329   \n",
       "std_train_score                                       0.0042166   \n",
       "\n",
       "                                                          47   \\\n",
       "mean_fit_time                                        0.143621   \n",
       "std_fit_time                                        0.0207257   \n",
       "mean_score_time                                    0.00168018   \n",
       "std_score_time                                     7.4256e-05   \n",
       "param_C                                                    10   \n",
       "param_gamma                                               0.1   \n",
       "param_kernel                                             poly   \n",
       "params              {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "split0_test_score                                   -0.626207   \n",
       "split1_test_score                                   -0.497896   \n",
       "split2_test_score                                    -8.22031   \n",
       "split3_test_score                                   -0.412972   \n",
       "split4_test_score                                     -4.3544   \n",
       "mean_test_score                                      -2.82236   \n",
       "std_test_score                                        3.08274   \n",
       "rank_test_score                                           117   \n",
       "split0_train_score                                   0.971642   \n",
       "split1_train_score                                   0.981128   \n",
       "split2_train_score                                   0.983774   \n",
       "split3_train_score                                    0.97268   \n",
       "split4_train_score                                   0.980873   \n",
       "mean_train_score                                     0.978019   \n",
       "std_train_score                                    0.00490101   \n",
       "\n",
       "                                                          71   \\\n",
       "mean_fit_time                                        0.141371   \n",
       "std_fit_time                                        0.0258662   \n",
       "mean_score_time                                    0.00156803   \n",
       "std_score_time                                    0.000104581   \n",
       "param_C                                                    10   \n",
       "param_gamma                                               0.1   \n",
       "param_kernel                                             poly   \n",
       "params              {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "split0_test_score                                   -0.626207   \n",
       "split1_test_score                                   -0.497896   \n",
       "split2_test_score                                    -8.22031   \n",
       "split3_test_score                                   -0.412972   \n",
       "split4_test_score                                     -4.3544   \n",
       "mean_test_score                                      -2.82236   \n",
       "std_test_score                                        3.08274   \n",
       "rank_test_score                                           117   \n",
       "split0_train_score                                   0.971642   \n",
       "split1_train_score                                   0.981128   \n",
       "split2_train_score                                   0.983774   \n",
       "split3_train_score                                    0.97268   \n",
       "split4_train_score                                   0.980873   \n",
       "mean_train_score                                     0.978019   \n",
       "std_train_score                                    0.00490101   \n",
       "\n",
       "                                                           95   \\\n",
       "mean_fit_time                                         0.364592   \n",
       "std_fit_time                                          0.118821   \n",
       "mean_score_time                                     0.00166545   \n",
       "std_score_time                                     7.56543e-05   \n",
       "param_C                                                    100   \n",
       "param_gamma                                                0.1   \n",
       "param_kernel                                              poly   \n",
       "params              {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}   \n",
       "split0_test_score                                     -5.51296   \n",
       "split1_test_score                                     -2.51479   \n",
       "split2_test_score                                     -6.71273   \n",
       "split3_test_score                                     -2.72908   \n",
       "split4_test_score                                     -3.62766   \n",
       "mean_test_score                                       -4.21945   \n",
       "std_test_score                                         1.63505   \n",
       "rank_test_score                                            119   \n",
       "split0_train_score                                    0.988171   \n",
       "split1_train_score                                    0.990888   \n",
       "split2_train_score                                    0.991283   \n",
       "split3_train_score                                      0.9903   \n",
       "split4_train_score                                    0.988829   \n",
       "mean_train_score                                      0.989894   \n",
       "std_train_score                                     0.00119878   \n",
       "\n",
       "                                                            119  \n",
       "mean_fit_time                                          0.706352  \n",
       "std_fit_time                                            0.17158  \n",
       "mean_score_time                                      0.00214963  \n",
       "std_score_time                                      0.000474724  \n",
       "param_C                                                    1000  \n",
       "param_gamma                                                 0.1  \n",
       "param_kernel                                               poly  \n",
       "params              {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'}  \n",
       "split0_test_score                                      -9.85748  \n",
       "split1_test_score                                      -3.24265  \n",
       "split2_test_score                                      -27.8004  \n",
       "split3_test_score                                      -4.68435  \n",
       "split4_test_score                                      -11.7236  \n",
       "mean_test_score                                        -11.4617  \n",
       "std_test_score                                          8.75307  \n",
       "rank_test_score                                             120  \n",
       "split0_train_score                                     0.990006  \n",
       "split1_train_score                                     0.991679  \n",
       "split2_train_score                                      0.99167  \n",
       "split3_train_score                                     0.991217  \n",
       "split4_train_score                                     0.989049  \n",
       "mean_train_score                                       0.990724  \n",
       "std_train_score                                      0.00103631  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_cv.cv_results_ ).sort_values('mean_test_score', ascending = False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
